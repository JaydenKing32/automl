2020-10-10 13:49:22.480357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
I1010 13:49:24.302961 140378078709632 main.py:228] {'name': 'efficientdet-d0', 'act_type': 'swish', 'image_size': (512, 512), 'target_size': None, 'input_rand_hflip': True, 'jitter_min': 0.1, 'jitter_max': 2.0, 'autoaugment_policy': None, 'use_augmix': False, 'augmix_params': [3, -1, 1], 'sample_image': None, 'num_classes': 20, 'seg_num_classes': 3, 'heads': ['object_detection'], 'skip_crowd_during_training': True, 'label_map': None, 'max_instances_per_image': 100, 'regenerate_source_id': False, 'min_level': 3, 'max_level': 7, 'num_scales': 3, 'aspect_ratios': [1.0, 2.0, 0.5], 'anchor_scale': 4.0, 'is_training_bn': True, 'momentum': 0.9, 'optimizer': 'sgd', 'learning_rate': 0.08, 'lr_warmup_init': 0.008, 'lr_warmup_epoch': 1.0, 'first_lr_drop_epoch': 200.0, 'second_lr_drop_epoch': 250.0, 'poly_lr_power': 0.9, 'clip_gradients_norm': 10.0, 'num_epochs': 1, 'data_format': 'channels_last', 'label_smoothing': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'delta': 0.1, 'box_loss_weight': 50.0, 'iou_loss_type': None, 'iou_loss_weight': 1.0, 'weight_decay': 4e-05, 'strategy': None, 'mixed_precision': True, 'box_class_repeats': 3, 'fpn_cell_repeats': 3, 'fpn_num_filters': 64, 'separable_conv': True, 'apply_bn_for_resampling': True, 'conv_after_downsample': False, 'conv_bn_act_pattern': False, 'drop_remainder': True, 'nms_configs': {'method': 'gaussian', 'iou_thresh': None, 'score_thresh': None, 'sigma': None, 'max_nms_inputs': 0, 'max_output_size': 100}, 'fpn_name': None, 'fpn_weight_method': None, 'fpn_config': None, 'survival_prob': None, 'img_summary_steps': None, 'lr_decay_method': 'cosine', 'moving_average_decay': 0, 'ckpt_var_scope': None, 'skip_mismatch': True, 'backbone_name': 'efficientnet-b0', 'backbone_config': None, 'var_freeze_expr': None, 'use_keras_model': True, 'dataset_type': None, 'positives_momentum': None, 'device': {'grad_ckpting': False, 'grad_ckpting_list': ['Add_', 'AddN'], 'nvgpu_logging': False}, 'model_name': 'efficientdet-d0', 'iterations_per_loop': 100, 'model_dir': '/tmp/model_dir/efficientdet-d0-finetune', 'num_shards': 8, 'num_examples_per_epoch': 5696, 'backbone_ckpt': '', 'ckpt': 'efficientdet-d0', 'val_json_file': None, 'testdev_dir': None, 'profile': False, 'mode': 'train_and_eval'}
INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1010 13:49:24.391798 140378078709632 estimator.py:191] Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1010 13:49:24.392879 140378078709632 estimator.py:191] Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1010 13:49:24.393416 140378078709632 main.py:336] Folder /tmp/model_dir/efficientdet-d0-finetune has no ckpt with valid step.

   =====> Starting training, epoch: 1.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 13:49:24.420931 140378078709632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 13:49:24.439956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 13:49:24.507080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:24.507777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 13:49:24.507827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 13:49:24.744346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 13:49:24.865185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 13:49:24.918956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 13:49:25.166010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 13:49:25.224655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 13:49:25.733329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 13:49:25.733537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:25.734302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:25.734896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 13:49:26.053691 140378078709632 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 13:49:26.461674 140378078709632 estimator.py:1162] Calling model_fn.
I1010 13:49:26.462033 140378078709632 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 13:49:26.467088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 13:49:26.467931 140378078709632 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 13:49:26.477025 140378078709632 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fac09b74488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 13:49:26.737425 140378078709632 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 13:49:26.738364 140378078709632 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 13:49:26.739188 140378078709632 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 13:49:26.740007 140378078709632 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 13:49:26.740804 140378078709632 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 13:49:26.741584 140378078709632 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 13:49:26.742438 140378078709632 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 13:49:26.743206 140378078709632 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 13:49:26.745164 140378078709632 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 13:49:26.746489 140378078709632 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 13:49:26.747711 140378078709632 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 13:49:26.749509 140378078709632 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 13:49:26.750810 140378078709632 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 13:49:26.751998 140378078709632 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 13:49:26.752923 140378078709632 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 13:49:26.754055 140378078709632 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 13:49:26.755803 140378078709632 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 13:49:26.757075 140378078709632 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 13:49:26.758436 140378078709632 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 13:49:26.759476 140378078709632 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 13:49:26.760371 140378078709632 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 13:49:26.761235 140378078709632 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 13:49:26.762102 140378078709632 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 13:49:26.762974 140378078709632 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 13:49:26.862833 140378078709632 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 13:49:26.863376 140378078709632 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 13:49:26.892469 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 13:49:26.917279 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 13:49:26.947834 140378078709632 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 13:49:26.948764 140378078709632 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 13:49:26.978873 140378078709632 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 13:49:27.009327 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 13:49:27.145511 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 13:49:27.174714 140378078709632 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 13:49:27.175324 140378078709632 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 13:49:27.208677 140378078709632 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 13:49:27.243387 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 13:49:27.271320 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 13:49:27.302386 140378078709632 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 13:49:27.303373 140378078709632 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 13:49:27.337175 140378078709632 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 13:49:27.366484 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 13:49:27.390671 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 13:49:27.418481 140378078709632 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 13:49:27.419082 140378078709632 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 13:49:27.446891 140378078709632 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 13:49:27.477013 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 13:49:27.501874 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 13:49:27.529825 140378078709632 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 13:49:27.530621 140378078709632 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 13:49:27.564183 140378078709632 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 13:49:27.596858 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 13:49:27.622322 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 13:49:27.649618 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 13:49:27.650193 140378078709632 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 13:49:27.681506 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 13:49:27.711018 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 13:49:27.735837 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 13:49:27.763624 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 13:49:27.764237 140378078709632 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 13:49:27.792973 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 13:49:27.823321 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 13:49:27.849115 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 13:49:27.879323 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 13:49:27.879904 140378078709632 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 13:49:27.908199 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 13:49:27.937838 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 13:49:27.962287 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 13:49:27.990361 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 13:49:27.990963 140378078709632 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 13:49:28.020393 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 13:49:28.050330 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 13:49:28.074692 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 13:49:28.105180 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 13:49:28.105871 140378078709632 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 13:49:28.136327 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 13:49:28.168257 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 13:49:28.193035 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 13:49:28.227973 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 13:49:28.228632 140378078709632 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 13:49:28.262339 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 13:49:28.292047 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 13:49:28.317859 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 13:49:28.346747 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:49:28.347357 140378078709632 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 13:49:28.385121 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:49:28.420206 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:49:28.446451 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:49:28.474245 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:49:28.474839 140378078709632 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 13:49:28.507837 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:49:28.540982 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:49:28.565719 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:49:28.593314 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:49:28.593936 140378078709632 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 13:49:28.626722 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:49:28.662993 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:49:28.694417 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:49:28.726943 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:49:28.727534 140378078709632 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 13:49:28.762838 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:49:28.796128 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:49:28.822152 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:49:28.850466 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 13:49:31.901241 140378078709632 utils.py:585] use mixed precision policy name float32
I1010 13:49:31.901545 140378078709632 det_model_fn.py:76] LR schedule method: cosine
I1010 13:49:32.156998 140378078709632 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 13:49:32.158820 140378078709632 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 13:49:32.160370 140378078709632 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 13:49:32.161903 140378078709632 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 13:49:32.163435 140378078709632 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 13:49:32.164957 140378078709632 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 13:49:32.167915 140378078709632 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 13:49:32.170177 140378078709632 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 13:49:40.264826 140378078709632 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 13:49:42.271214 140378078709632 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 13:49:42.271396 140378078709632 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 13:49:42.281430 140378078709632 utils.py:142] Init global_step from ckpt var global_step
I1010 13:49:42.281577 140378078709632 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 13:49:42.281674 140378078709632 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 13:49:42.281770 140378078709632 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 13:49:42.281846 140378078709632 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 13:49:42.286930 140378078709632 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 13:49:42.287058 140378078709632 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 13:49:43.890523 140378078709632 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 13:49:43.891625 140378078709632 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 13:49:48.210109 140378078709632 monitored_session.py:246] Graph was finalized.
2020-10-10 13:49:48.222344: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 13:49:48.222565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16c7800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 13:49:48.222595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 13:49:48.349497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:48.350238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16c7640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 13:49:48.350267: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 13:49:48.350924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:48.351468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 13:49:48.351513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 13:49:48.351570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 13:49:48.351593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 13:49:48.351616: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 13:49:48.351668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 13:49:48.351690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 13:49:48.351707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 13:49:48.351789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:48.352601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:48.353363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 13:49:48.355751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 13:49:52.135073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 13:49:52.135142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 13:49:52.135162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 13:49:52.135477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:52.136339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:49:52.136915: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 13:49:52.136958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I1010 13:49:56.450848 140378078709632 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 13:49:56.611362 140378078709632 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
I1010 13:50:08.053918 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 0...
INFO:tensorflow:Saving checkpoints for 0 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:50:08.054702 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 0 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
I1010 13:50:10.760008 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 0...
2020-10-10 13:50:13.894340: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-10 13:50:14.348126: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-10 13:50:14.846743: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-10 13:50:15.262868: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-10 13:50:16.527050: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-10 13:50:21.083234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 13:50:26.122999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 9.871951, step = 0
I1010 13:50:28.200355 140378078709632 basic_session_run_hooks.py:262] loss = 9.871951, step = 0
INFO:tensorflow:box_loss = 0.0028716072, cls_loss = 9.6328125, det_loss = 9.776393, step = 0
I1010 13:50:28.200964 140378078709632 basic_session_run_hooks.py:262] box_loss = 0.0028716072, cls_loss = 9.6328125, det_loss = 9.776393, step = 0
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...
I1010 13:51:05.254337 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 100...
INFO:tensorflow:Saving checkpoints for 100 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:51:05.254681 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 100 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...
I1010 13:51:07.066536 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 100...
INFO:tensorflow:global_step/sec: 2.55171
I1010 13:51:07.388784 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 2.55171
INFO:tensorflow:loss = 1.3068206, step = 100 (39.190 sec)
I1010 13:51:07.389895 140378078709632 basic_session_run_hooks.py:260] loss = 1.3068206, step = 100 (39.190 sec)
INFO:tensorflow:box_loss = 0.004748804, cls_loss = 0.973938, det_loss = 1.2113782, step = 100 (39.189 sec)
I1010 13:51:07.390249 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.004748804, cls_loss = 0.973938, det_loss = 1.2113782, step = 100 (39.189 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200...
I1010 13:51:36.294707 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 200...
INFO:tensorflow:Saving checkpoints for 200 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:51:36.294924 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 200 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200...
I1010 13:51:38.059680 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 200...
INFO:tensorflow:global_step/sec: 3.21962
I1010 13:51:38.448334 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 3.21962
INFO:tensorflow:loss = 0.8909755, step = 200 (31.060 sec)
I1010 13:51:38.449410 140378078709632 basic_session_run_hooks.py:260] loss = 0.8909755, step = 200 (31.060 sec)
INFO:tensorflow:box_loss = 0.0033278994, cls_loss = 0.6291199, det_loss = 0.7955148, step = 200 (31.059 sec)
I1010 13:51:38.449612 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.0033278994, cls_loss = 0.6291199, det_loss = 0.7955148, step = 200 (31.059 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 300...
I1010 13:52:07.565467 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 300...
INFO:tensorflow:Saving checkpoints for 300 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:52:07.565717 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 300 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 300...
I1010 13:52:09.356386 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 300...
INFO:tensorflow:global_step/sec: 3.20474
I1010 13:52:09.652098 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 3.20474
INFO:tensorflow:loss = 1.128512, step = 300 (31.204 sec)
I1010 13:52:09.653132 140378078709632 basic_session_run_hooks.py:260] loss = 1.128512, step = 300 (31.204 sec)
INFO:tensorflow:box_loss = 0.00504098, cls_loss = 0.78097916, det_loss = 1.0330281, step = 300 (31.204 sec)
I1010 13:52:09.653335 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.00504098, cls_loss = 0.78097916, det_loss = 1.0330281, step = 300 (31.204 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 400...
I1010 13:52:38.885288 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 400...
INFO:tensorflow:Saving checkpoints for 400 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:52:38.885534 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 400 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 400...
I1010 13:52:40.686074 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 400...
INFO:tensorflow:global_step/sec: 3.18403
I1010 13:52:41.058840 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 3.18403
INFO:tensorflow:loss = 1.0768865, step = 400 (31.407 sec)
I1010 13:52:41.059852 140378078709632 basic_session_run_hooks.py:260] loss = 1.0768865, step = 400 (31.407 sec)
INFO:tensorflow:box_loss = 0.0050180433, cls_loss = 0.73046875, det_loss = 0.9813709, step = 400 (31.407 sec)
I1010 13:52:41.060051 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.0050180433, cls_loss = 0.73046875, det_loss = 0.9813709, step = 400 (31.407 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...
I1010 13:53:10.320016 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 500...
INFO:tensorflow:Saving checkpoints for 500 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:53:10.320238 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 500 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 13:53:10.386663 140378078709632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...
I1010 13:53:12.129769 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 500...
INFO:tensorflow:global_step/sec: 3.18988
I1010 13:53:12.407978 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 3.18988
INFO:tensorflow:loss = 0.81573594, step = 500 (31.349 sec)
I1010 13:53:12.409112 140378078709632 basic_session_run_hooks.py:260] loss = 0.81573594, step = 500 (31.349 sec)
INFO:tensorflow:box_loss = 0.0030017088, cls_loss = 0.5701046, det_loss = 0.72019005, step = 500 (31.349 sec)
I1010 13:53:12.409409 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.0030017088, cls_loss = 0.5701046, det_loss = 0.72019005, step = 500 (31.349 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 600...
I1010 13:53:41.601605 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 600...
INFO:tensorflow:Saving checkpoints for 600 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:53:41.601844 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 600 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 600...
I1010 13:53:43.414772 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 600...
INFO:tensorflow:global_step/sec: 3.18862
I1010 13:53:43.769481 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 3.18862
INFO:tensorflow:loss = 0.8257532, step = 600 (31.361 sec)
I1010 13:53:43.770372 140378078709632 basic_session_run_hooks.py:260] loss = 0.8257532, step = 600 (31.361 sec)
INFO:tensorflow:box_loss = 0.0032838078, cls_loss = 0.56596375, det_loss = 0.73015416, step = 600 (31.361 sec)
I1010 13:53:43.770581 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.0032838078, cls_loss = 0.56596375, det_loss = 0.73015416, step = 600 (31.361 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 700...
I1010 13:54:12.945802 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 700...
INFO:tensorflow:Saving checkpoints for 700 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:54:12.946039 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 700 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 700...
I1010 13:54:14.785801 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 700...
INFO:tensorflow:global_step/sec: 3.18737
I1010 13:54:15.143369 140378078709632 basic_session_run_hooks.py:702] global_step/sec: 3.18737
INFO:tensorflow:loss = 0.75159144, step = 700 (31.374 sec)
I1010 13:54:15.144479 140378078709632 basic_session_run_hooks.py:260] loss = 0.75159144, step = 700 (31.374 sec)
INFO:tensorflow:box_loss = 0.003730008, cls_loss = 0.4694214, det_loss = 0.6559218, step = 700 (31.374 sec)
I1010 13:54:15.144710 140378078709632 basic_session_run_hooks.py:260] box_loss = 0.003730008, cls_loss = 0.4694214, det_loss = 0.6559218, step = 700 (31.374 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 712...
I1010 13:54:18.406874 140378078709632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 712...
INFO:tensorflow:Saving checkpoints for 712 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 13:54:18.407104 140378078709632 basic_session_run_hooks.py:618] Saving checkpoints for 712 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 712...
I1010 13:54:20.199581 140378078709632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 712...
INFO:tensorflow:Loss for final step: 1.0555834.
I1010 13:54:20.584406 140378078709632 estimator.py:350] Loss for final step: 1.0555834.

   =====> Starting evaluation, epoch: 1.
INFO:tensorflow:Calling model_fn.
I1010 13:54:21.075494 140378078709632 estimator.py:1162] Calling model_fn.
I1010 13:54:21.075799 140378078709632 utils.py:585] use mixed precision policy name mixed_float16
I1010 13:54:21.079453 140378078709632 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fac09b74488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 13:54:21.329872 140378078709632 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 13:54:21.330792 140378078709632 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 13:54:21.331595 140378078709632 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 13:54:21.332438 140378078709632 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 13:54:21.333288 140378078709632 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 13:54:21.334212 140378078709632 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 13:54:21.335038 140378078709632 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 13:54:21.335809 140378078709632 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 13:54:21.337013 140378078709632 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 13:54:21.337822 140378078709632 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 13:54:21.338550 140378078709632 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 13:54:21.339493 140378078709632 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 13:54:21.340324 140378078709632 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 13:54:21.341230 140378078709632 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 13:54:21.342071 140378078709632 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 13:54:21.342914 140378078709632 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 13:54:21.344172 140378078709632 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 13:54:21.345019 140378078709632 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 13:54:21.345818 140378078709632 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 13:54:21.346619 140378078709632 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 13:54:21.347384 140378078709632 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 13:54:21.348129 140378078709632 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 13:54:21.348858 140378078709632 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 13:54:21.349692 140378078709632 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 13:54:21.637859 140378078709632 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 13:54:21.638365 140378078709632 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 13:54:21.668129 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 13:54:21.697481 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 13:54:21.727368 140378078709632 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 13:54:21.728107 140378078709632 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 13:54:21.753547 140378078709632 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 13:54:21.775950 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 13:54:21.798981 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 13:54:21.818529 140378078709632 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 13:54:21.819082 140378078709632 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 13:54:21.839239 140378078709632 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 13:54:21.860556 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 13:54:21.883671 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 13:54:21.903897 140378078709632 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 13:54:21.904495 140378078709632 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 13:54:21.927320 140378078709632 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 13:54:21.949889 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 13:54:21.972552 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 13:54:21.992749 140378078709632 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 13:54:21.993267 140378078709632 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 13:54:22.015062 140378078709632 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 13:54:22.039995 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 13:54:22.063487 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 13:54:22.084285 140378078709632 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 13:54:22.084925 140378078709632 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 13:54:22.105675 140378078709632 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 13:54:22.127441 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 13:54:22.150423 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 13:54:22.170755 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 13:54:22.171331 140378078709632 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 13:54:22.193004 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 13:54:22.215512 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 13:54:22.244215 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 13:54:22.265332 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 13:54:22.265902 140378078709632 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 13:54:22.287327 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 13:54:22.310822 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 13:54:22.335283 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 13:54:22.357335 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 13:54:22.357902 140378078709632 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 13:54:22.379310 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 13:54:22.401292 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 13:54:22.424319 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 13:54:22.443863 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 13:54:22.444379 140378078709632 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 13:54:22.465300 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 13:54:22.489380 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 13:54:22.513062 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 13:54:22.537911 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 13:54:22.538436 140378078709632 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 13:54:22.559655 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 13:54:22.581192 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 13:54:22.604272 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 13:54:22.624823 140378078709632 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 13:54:22.625493 140378078709632 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 13:54:22.646488 140378078709632 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 13:54:22.673384 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 13:54:22.702536 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 13:54:22.722888 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:54:22.723451 140378078709632 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 13:54:22.750905 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:54:22.776321 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:54:22.800679 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:54:22.823113 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:54:22.823666 140378078709632 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 13:54:22.851085 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:54:22.877123 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:54:22.901852 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:54:22.922421 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:54:22.922967 140378078709632 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 13:54:22.949292 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:54:22.975093 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:54:23.000120 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:54:23.021698 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 13:54:23.022257 140378078709632 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 13:54:23.053440 140378078709632 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 13:54:23.080321 140378078709632 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 13:54:23.105218 140378078709632 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 13:54:23.126470 140378078709632 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 13:54:25.538839 140378078709632 utils.py:585] use mixed precision policy name float32
I1010 13:54:25.539117 140378078709632 det_model_fn.py:76] LR schedule method: cosine
I1010 13:54:25.828160 140378078709632 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 13:54:25.986395 140378078709632 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 13:54:26.027366 140378078709632 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T13:54:26Z
I1010 13:54:26.043224 140378078709632 evaluation.py:255] Starting evaluation at 2020-10-10T13:54:26Z
INFO:tensorflow:Graph was finalized.
I1010 13:54:26.938154 140378078709632 monitored_session.py:246] Graph was finalized.
2020-10-10 13:54:26.938843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:54:26.939414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 13:54:26.939493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 13:54:26.939543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 13:54:26.939564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 13:54:26.939585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 13:54:26.939606: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 13:54:26.939626: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 13:54:26.939665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 13:54:26.939751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:54:26.940295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:54:26.940737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 13:54:26.940796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 13:54:26.940810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 13:54:26.940820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 13:54:26.940928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:54:26.941405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 13:54:26.941850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712
I1010 13:54:26.942787 140378078709632 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712
INFO:tensorflow:Running local_init_op.
I1010 13:54:28.171248 140378078709632 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 13:54:28.238407 140378078709632 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 13:56:52.185730 140378078709632 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 13:59:13.596238 140378078709632 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 14:01:37.189491 140378078709632 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 14:03:57.951236 140378078709632 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 14:06:15.717290 140378078709632 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 14:08:36.344374 140378078709632 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 14:10:55.969130 140378078709632 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 14:13:11.870686 140378078709632 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 14:15:29.972993 140378078709632 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 14:17:46.817502 140378078709632 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 14:17:50.971026 140378078709632 evaluation.py:167] Evaluation [712/712]
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.97s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=45.01s).
Accumulating evaluation results...
DONE (t=10.93s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.211
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
INFO:tensorflow:Inference Time : 1466.81042s
I1010 14:18:52.853825 140378078709632 evaluation.py:273] Inference Time : 1466.81042s
INFO:tensorflow:Finished evaluation at 2020-10-10-14:18:52
I1010 14:18:52.854059 140378078709632 evaluation.py:276] Finished evaluation at 2020-10-10-14:18:52
INFO:tensorflow:Saving dict for global step 712: AP = 0.14191498, AP50 = 0.21145359, AP75 = 0.15967306, APl = 0.17972372, APm = 0.12680857, APs = 0.017813494, ARl = 0.65420127, ARm = 0.3753814, ARmax1 = 0.3598028, ARmax10 = 0.51455164, ARmax100 = 0.53356785, ARs = 0.07447071, box_loss = 0.00340943, cls_loss = 0.55018103, global_step = 712, loss = 0.8163315
I1010 14:18:52.854234 140378078709632 estimator.py:2063] Saving dict for global step 712: AP = 0.14191498, AP50 = 0.21145359, AP75 = 0.15967306, APl = 0.17972372, APm = 0.12680857, APs = 0.017813494, ARl = 0.65420127, ARm = 0.3753814, ARmax1 = 0.3598028, ARmax10 = 0.51455164, ARmax100 = 0.53356785, ARs = 0.07447071, box_loss = 0.00340943, cls_loss = 0.55018103, global_step = 712, loss = 0.8163315
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 712: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712
I1010 14:18:53.885250 140378078709632 estimator.py:2124] Saving 'checkpoint_path' summary for global step 712: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-712 is not in all_model_checkpoint_paths. Manually adding it.
I1010 14:18:53.928192 140378078709632 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-712 is not in all_model_checkpoint_paths. Manually adding it.
I1010 14:18:53.928774 140378078709632 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712 to /tmp/model_dir/efficientdet-d0-finetune/archive


2020-10-10 14:43:04.609126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
I1010 14:43:06.444743 140455904991104 main.py:228] {'name': 'efficientdet-d0', 'act_type': 'swish', 'image_size': (512, 512), 'target_size': None, 'input_rand_hflip': True, 'jitter_min': 0.1, 'jitter_max': 2.0, 'autoaugment_policy': None, 'use_augmix': False, 'augmix_params': [3, -1, 1], 'sample_image': None, 'num_classes': 20, 'seg_num_classes': 3, 'heads': ['object_detection'], 'skip_crowd_during_training': True, 'label_map': None, 'max_instances_per_image': 100, 'regenerate_source_id': False, 'min_level': 3, 'max_level': 7, 'num_scales': 3, 'aspect_ratios': [1.0, 2.0, 0.5], 'anchor_scale': 4.0, 'is_training_bn': True, 'momentum': 0.9, 'optimizer': 'sgd', 'learning_rate': 0.08, 'lr_warmup_init': 0.008, 'lr_warmup_epoch': 1.0, 'first_lr_drop_epoch': 200.0, 'second_lr_drop_epoch': 250.0, 'poly_lr_power': 0.9, 'clip_gradients_norm': 10.0, 'num_epochs': 10, 'data_format': 'channels_last', 'label_smoothing': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'delta': 0.1, 'box_loss_weight': 50.0, 'iou_loss_type': None, 'iou_loss_weight': 1.0, 'weight_decay': 4e-05, 'strategy': None, 'mixed_precision': True, 'box_class_repeats': 3, 'fpn_cell_repeats': 3, 'fpn_num_filters': 64, 'separable_conv': True, 'apply_bn_for_resampling': True, 'conv_after_downsample': False, 'conv_bn_act_pattern': False, 'drop_remainder': True, 'nms_configs': {'method': 'gaussian', 'iou_thresh': None, 'score_thresh': None, 'sigma': None, 'max_nms_inputs': 0, 'max_output_size': 100}, 'fpn_name': None, 'fpn_weight_method': None, 'fpn_config': None, 'survival_prob': None, 'img_summary_steps': None, 'lr_decay_method': 'cosine', 'moving_average_decay': 0, 'ckpt_var_scope': None, 'skip_mismatch': True, 'backbone_name': 'efficientnet-b0', 'backbone_config': None, 'var_freeze_expr': None, 'use_keras_model': True, 'dataset_type': None, 'positives_momentum': None, 'device': {'grad_ckpting': False, 'grad_ckpting_list': ['Add_', 'AddN'], 'nvgpu_logging': False}, 'model_name': 'efficientdet-d0', 'iterations_per_loop': 100, 'model_dir': '/tmp/model_dir/efficientdet-d0-finetune', 'num_shards': 8, 'num_examples_per_epoch': 5696, 'backbone_ckpt': '', 'ckpt': 'efficientdet-d0', 'val_json_file': None, 'testdev_dir': None, 'profile': False, 'mode': 'train_and_eval'}
INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1010 14:43:06.486864 140455904991104 estimator.py:191] Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1010 14:43:06.488250 140455904991104 estimator.py:191] Using config: {'_model_dir': '/tmp/model_dir/efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1010 14:43:06.490613 140455904991104 main.py:334] found ckpt at step 712 (epoch 1)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 14:43:06.516388 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 14:43:06.530566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 14:43:06.568319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:06.568998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 14:43:06.569049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 14:43:06.573632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 14:43:06.576774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 14:43:06.577206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 14:43:06.581440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 14:43:06.583127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 14:43:06.590255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 14:43:06.590399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:06.591062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:06.591706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 14:43:06.886049 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 14:43:07.292622 140455904991104 estimator.py:1162] Calling model_fn.
I1010 14:43:07.292959 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 14:43:07.298231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 14:43:07.298964 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 14:43:07.308271 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 14:43:07.578210 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 14:43:07.579235 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 14:43:07.580115 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 14:43:07.580987 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 14:43:07.581895 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 14:43:07.582751 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 14:43:07.583549 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 14:43:07.584384 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 14:43:07.585685 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 14:43:07.586455 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 14:43:07.587279 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 14:43:07.588164 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 14:43:07.589005 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 14:43:07.590077 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 14:43:07.590992 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 14:43:07.591989 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 14:43:07.593409 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 14:43:07.595369 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 14:43:07.596262 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 14:43:07.597194 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 14:43:07.598088 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 14:43:07.598973 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 14:43:07.599918 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 14:43:07.600773 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 14:43:07.702292 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 14:43:07.702858 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 14:43:07.736960 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 14:43:07.761286 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 14:43:07.789407 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 14:43:07.790014 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 14:43:07.817998 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 14:43:07.847787 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 14:43:07.988042 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 14:43:08.016565 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 14:43:08.017219 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 14:43:08.049433 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 14:43:08.081820 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 14:43:08.106074 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 14:43:08.134611 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 14:43:08.135303 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 14:43:08.163970 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 14:43:08.194164 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 14:43:08.218415 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 14:43:08.246954 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 14:43:08.247556 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 14:43:08.279132 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 14:43:08.311007 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 14:43:08.338164 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 14:43:08.371412 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 14:43:08.372179 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 14:43:08.406208 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 14:43:08.437095 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 14:43:08.461403 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 14:43:08.490161 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 14:43:08.490775 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 14:43:08.519402 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 14:43:08.548540 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 14:43:08.572805 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 14:43:08.604205 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 14:43:08.604813 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 14:43:08.635575 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 14:43:08.666866 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 14:43:08.691768 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 14:43:08.720376 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 14:43:08.720988 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 14:43:08.750047 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 14:43:08.782530 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 14:43:08.806592 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 14:43:08.835126 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 14:43:08.835706 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 14:43:08.864987 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 14:43:08.901265 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 14:43:08.928843 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 14:43:08.957672 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 14:43:08.958264 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 14:43:08.987929 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 14:43:09.017525 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 14:43:09.042428 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 14:43:09.070511 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 14:43:09.071431 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 14:43:09.103353 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 14:43:09.132846 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 14:43:09.159012 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 14:43:09.188590 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:43:09.189211 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 14:43:09.223914 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:43:09.260287 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:43:09.286006 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:43:09.316873 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:43:09.317505 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 14:43:09.351572 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:43:09.386471 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:43:09.412220 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:43:09.440665 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:43:09.441223 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 14:43:09.476137 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:43:09.512467 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:43:09.538950 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:43:09.566437 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:43:09.567015 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 14:43:09.602658 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:43:09.637170 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:43:09.663771 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:43:09.692775 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 14:43:12.727090 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 14:43:12.727429 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 14:43:12.991457 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 14:43:12.993129 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 14:43:12.994728 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 14:43:12.996285 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 14:43:12.997887 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 14:43:12.999764 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 14:43:13.004397 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 14:43:13.006591 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 14:43:21.215667 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 14:43:23.273803 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 14:43:23.273983 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 14:43:23.280309 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 14:43:23.280442 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 14:43:23.280540 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 14:43:23.280671 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 14:43:23.280769 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 14:43:23.286047 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 14:43:23.286192 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 14:43:24.911439 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 14:43:24.912531 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 14:43:29.345157 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 14:43:29.351995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 14:43:29.352223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 14:43:29.352251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 14:43:29.460128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:29.460826: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 14:43:29.460857: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 14:43:29.461086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:29.461725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 14:43:29.461784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 14:43:29.461848: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 14:43:29.461882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 14:43:29.461914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 14:43:29.461963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 14:43:29.461995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 14:43:29.462019: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 14:43:29.462135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:29.462793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:29.463380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 14:43:29.463527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 14:43:30.065917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 14:43:30.065975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 14:43:30.065988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 14:43:30.066233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:30.066955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:43:30.067520: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 14:43:30.067566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712
I1010 14:43:30.069885 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-712
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 14:43:31.840621 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 14:43:32.748595 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 14:43:32.905171 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 712...
I1010 14:43:44.401221 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 712...
INFO:tensorflow:Saving checkpoints for 712 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:43:44.415699 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 712 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 712...
I1010 14:43:47.162847 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 712...
2020-10-10 14:43:57.149455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 14:43:59.292277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.7687202, step = 712
I1010 14:44:00.281344 140455904991104 basic_session_run_hooks.py:262] loss = 0.7687202, step = 712
INFO:tensorflow:box_loss = 0.0041570053, cls_loss = 0.4651909, det_loss = 0.67304116, step = 712
I1010 14:44:00.282165 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0041570053, cls_loss = 0.4651909, det_loss = 0.67304116, step = 712
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 812...
I1010 14:44:37.945943 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 812...
INFO:tensorflow:Saving checkpoints for 812 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:44:37.946234 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 812 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 14:44:38.011547 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 812...
I1010 14:44:39.830972 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 812...
INFO:tensorflow:global_step/sec: 2.50691
I1010 14:44:40.170062 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.50691
INFO:tensorflow:loss = 0.8488211, step = 812 (39.890 sec)
I1010 14:44:40.171144 140455904991104 basic_session_run_hooks.py:260] loss = 0.8488211, step = 812 (39.890 sec)
INFO:tensorflow:box_loss = 0.004229946, cls_loss = 0.5415802, det_loss = 0.7530775, step = 812 (39.889 sec)
I1010 14:44:40.171371 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.004229946, cls_loss = 0.5415802, det_loss = 0.7530775, step = 812 (39.889 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 912...
I1010 14:45:09.400348 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 912...
INFO:tensorflow:Saving checkpoints for 912 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:45:09.400625 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 912 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 912...
I1010 14:45:11.248101 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 912...
INFO:tensorflow:global_step/sec: 3.18092
I1010 14:45:11.607459 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.18092
INFO:tensorflow:loss = 0.68756956, step = 912 (31.438 sec)
I1010 14:45:11.608671 140455904991104 basic_session_run_hooks.py:260] loss = 0.68756956, step = 912 (31.438 sec)
INFO:tensorflow:box_loss = 0.0030660937, cls_loss = 0.4384613, det_loss = 0.591766, step = 912 (31.438 sec)
I1010 14:45:11.608896 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0030660937, cls_loss = 0.4384613, det_loss = 0.591766, step = 912 (31.438 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1012...
I1010 14:45:41.020681 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1012...
INFO:tensorflow:Saving checkpoints for 1012 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:45:41.021026 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1012 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1012...
I1010 14:45:42.867650 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1012...
INFO:tensorflow:global_step/sec: 3.1632
I1010 14:45:43.221079 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.1632
INFO:tensorflow:loss = 0.8353903, step = 1012 (31.614 sec)
I1010 14:45:43.222204 140455904991104 basic_session_run_hooks.py:260] loss = 0.8353903, step = 1012 (31.614 sec)
INFO:tensorflow:box_loss = 0.0039620777, cls_loss = 0.54141235, det_loss = 0.73951626, step = 1012 (31.614 sec)
I1010 14:45:43.222559 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0039620777, cls_loss = 0.54141235, det_loss = 0.73951626, step = 1012 (31.614 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1112...
I1010 14:46:13.018561 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1112...
INFO:tensorflow:Saving checkpoints for 1112 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:46:13.018934 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1112 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1112...
I1010 14:46:14.869088 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1112...
INFO:tensorflow:global_step/sec: 3.12921
I1010 14:46:15.177980 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.12921
INFO:tensorflow:loss = 0.5823707, step = 1112 (31.957 sec)
I1010 14:46:15.179075 140455904991104 basic_session_run_hooks.py:260] loss = 0.5823707, step = 1112 (31.957 sec)
INFO:tensorflow:box_loss = 0.0026877916, cls_loss = 0.3520279, det_loss = 0.48641747, step = 1112 (31.957 sec)
I1010 14:46:15.179283 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0026877916, cls_loss = 0.3520279, det_loss = 0.48641747, step = 1112 (31.957 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1212...
I1010 14:46:44.789004 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1212...
INFO:tensorflow:Saving checkpoints for 1212 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:46:44.789229 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1212 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1212...
I1010 14:46:46.639620 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1212...
INFO:tensorflow:global_step/sec: 3.14553
I1010 14:46:46.969159 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.14553
INFO:tensorflow:loss = 1.0369022, step = 1212 (31.791 sec)
I1010 14:46:46.970256 140455904991104 basic_session_run_hooks.py:260] loss = 1.0369022, step = 1212 (31.791 sec)
INFO:tensorflow:box_loss = 0.0058134776, cls_loss = 0.6502075, det_loss = 0.9408814, step = 1212 (31.791 sec)
I1010 14:46:46.970463 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0058134776, cls_loss = 0.6502075, det_loss = 0.9408814, step = 1212 (31.791 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1312...
I1010 14:47:16.583752 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1312...
INFO:tensorflow:Saving checkpoints for 1312 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:47:16.584026 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1312 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1312...
I1010 14:47:18.424834 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1312...
INFO:tensorflow:global_step/sec: 3.14101
I1010 14:47:18.806087 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.14101
INFO:tensorflow:loss = 0.86845136, step = 1312 (31.837 sec)
I1010 14:47:18.807214 140455904991104 basic_session_run_hooks.py:260] loss = 0.86845136, step = 1312 (31.837 sec)
INFO:tensorflow:box_loss = 0.005958155, cls_loss = 0.4744377, det_loss = 0.7723454, step = 1312 (31.837 sec)
I1010 14:47:18.807426 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.005958155, cls_loss = 0.4744377, det_loss = 0.7723454, step = 1312 (31.837 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1412...
I1010 14:47:48.403994 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1412...
INFO:tensorflow:Saving checkpoints for 1412 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:47:48.404225 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1412 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1412...
I1010 14:47:50.226080 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1412...
INFO:tensorflow:global_step/sec: 3.14505
I1010 14:47:50.602069 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.14505
INFO:tensorflow:loss = 0.7542469, step = 1412 (31.796 sec)
I1010 14:47:50.603195 140455904991104 basic_session_run_hooks.py:260] loss = 0.7542469, step = 1412 (31.796 sec)
INFO:tensorflow:box_loss = 0.0033118834, cls_loss = 0.49246216, det_loss = 0.6580564, step = 1412 (31.796 sec)
I1010 14:47:50.603490 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0033118834, cls_loss = 0.49246216, det_loss = 0.6580564, step = 1412 (31.796 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1424...
I1010 14:47:53.905177 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1424...
INFO:tensorflow:Saving checkpoints for 1424 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 14:47:53.905409 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1424 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1424...
I1010 14:47:55.747966 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1424...
INFO:tensorflow:Loss for final step: 0.72476774.
I1010 14:47:56.127189 140455904991104 estimator.py:350] Loss for final step: 0.72476774.
INFO:tensorflow:Calling model_fn.
I1010 14:47:56.643156 140455904991104 estimator.py:1162] Calling model_fn.
I1010 14:47:56.643467 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 14:47:56.647241 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 14:47:56.902337 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 14:47:56.903263 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 14:47:56.904076 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 14:47:56.904889 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 14:47:56.905685 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 14:47:56.906584 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 14:47:56.907433 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 14:47:56.908240 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 14:47:56.909527 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 14:47:56.910394 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 14:47:56.911201 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 14:47:56.912111 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 14:47:56.912953 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 14:47:56.913789 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 14:47:56.914618 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 14:47:56.915466 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 14:47:56.916840 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 14:47:56.917753 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 14:47:56.918574 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 14:47:56.919395 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 14:47:56.920268 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 14:47:56.921108 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 14:47:56.921988 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 14:47:56.922951 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 14:47:57.234341 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 14:47:57.235106 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 14:47:57.260297 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 14:47:57.285106 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 14:47:57.306822 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 14:47:57.307472 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 14:47:57.329454 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 14:47:57.352322 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 14:47:57.376137 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 14:47:57.397058 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 14:47:57.397618 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 14:47:57.419389 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 14:47:57.442374 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 14:47:57.468345 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 14:47:57.489816 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 14:47:57.490473 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 14:47:57.513990 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 14:47:57.542253 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 14:47:57.574548 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 14:47:57.595553 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 14:47:57.596113 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 14:47:57.617845 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 14:47:57.640534 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 14:47:57.664810 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 14:47:57.685963 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 14:47:57.686553 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 14:47:57.708538 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 14:47:57.730878 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 14:47:57.754918 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 14:47:57.778344 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 14:47:57.778961 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 14:47:57.801065 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 14:47:57.825116 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 14:47:57.851755 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 14:47:57.873679 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 14:47:57.874483 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 14:47:57.897365 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 14:47:57.919921 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 14:47:57.944003 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 14:47:57.966412 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 14:47:57.967296 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 14:47:57.990031 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 14:47:58.013670 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 14:47:58.038051 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 14:47:58.059012 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 14:47:58.059589 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 14:47:58.082122 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 14:47:58.104049 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 14:47:58.127861 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 14:47:58.151105 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 14:47:58.151712 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 14:47:58.176765 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 14:47:58.200381 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 14:47:58.224889 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 14:47:58.247479 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 14:47:58.248139 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 14:47:58.270768 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 14:47:58.294075 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 14:47:58.318621 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 14:47:58.339932 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:47:58.340482 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 14:47:58.367191 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:47:58.394928 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:47:58.420295 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:47:58.442527 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:47:58.443131 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 14:47:58.470911 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:47:58.500132 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:47:58.525656 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:47:58.551965 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:47:58.552676 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 14:47:58.593552 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:47:58.622931 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:47:58.648699 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:47:58.670995 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 14:47:58.671828 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 14:47:58.700141 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 14:47:58.728121 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 14:47:58.754023 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 14:47:58.775259 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 14:48:01.274096 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 14:48:01.274377 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 14:48:01.565359 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 14:48:01.741476 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 14:48:01.787572 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T14:48:01Z
I1010 14:48:01.804276 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T14:48:01Z
INFO:tensorflow:Graph was finalized.
I1010 14:48:02.725198 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 14:48:02.725916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:48:02.726441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 14:48:02.726507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 14:48:02.726582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 14:48:02.726607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 14:48:02.726626: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 14:48:02.726664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 14:48:02.726692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 14:48:02.726717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 14:48:02.726801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:48:02.727286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:48:02.727735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 14:48:02.727788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 14:48:02.727805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 14:48:02.727814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 14:48:02.727918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:48:02.728413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 14:48:02.728911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424
I1010 14:48:02.729960 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424
INFO:tensorflow:Running local_init_op.
I1010 14:48:03.977882 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 14:48:04.043236 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 14:50:41.683679 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 14:53:12.599927 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 14:55:46.968681 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 14:58:18.265144 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 15:00:44.976989 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 15:03:11.792824 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 15:05:37.773750 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 15:07:59.673246 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 15:10:26.271817 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 15:12:50.192222 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 15:12:54.545768 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1553.16985s
I1010 15:13:54.974318 140455904991104 evaluation.py:273] Inference Time : 1553.16985s
INFO:tensorflow:Finished evaluation at 2020-10-10-15:13:54
I1010 15:13:54.974568 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-15:13:54
INFO:tensorflow:Saving dict for global step 1424: AP = 0.23543902, AP50 = 0.34348235, AP75 = 0.26889572, APl = 0.29900318, APm = 0.23652339, APs = 0.049171392, ARl = 0.6919594, ARm = 0.43067402, ARmax1 = 0.39102158, ARmax10 = 0.54513055, ARmax100 = 0.5774126, ARs = 0.13973857, box_loss = 0.0033446702, cls_loss = 0.42879164, global_step = 1424, loss = 0.6922267
I1010 15:13:54.974772 140455904991104 estimator.py:2063] Saving dict for global step 1424: AP = 0.23543902, AP50 = 0.34348235, AP75 = 0.26889572, APl = 0.29900318, APm = 0.23652339, APs = 0.049171392, ARl = 0.6919594, ARm = 0.43067402, ARmax1 = 0.39102158, ARmax10 = 0.54513055, ARmax100 = 0.5774126, ARs = 0.13973857, box_loss = 0.0033446702, cls_loss = 0.42879164, global_step = 1424, loss = 0.6922267
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1424: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424
I1010 15:13:55.968907 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 1424: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424
I1010 15:13:55.972233 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-1424 is not in all_model_checkpoint_paths. Manually adding it.
I1010 15:13:56.011353 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-1424 is not in all_model_checkpoint_paths. Manually adding it.
I1010 15:13:56.011978 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 2.

   =====> Starting evaluation, epoch: 2.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.99s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=45.00s).
Accumulating evaluation results...
DONE (t=9.61s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 15:13:56.212699 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 15:13:56.224964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 15:13:56.257210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:13:56.257813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 15:13:56.257865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:13:56.261199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 15:13:56.263886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 15:13:56.264257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 15:13:56.267494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 15:13:56.268813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 15:13:56.273667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:13:56.273820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:13:56.274428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:13:56.274985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 15:13:56.545488 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 15:13:56.917559 140455904991104 estimator.py:1162] Calling model_fn.
I1010 15:13:56.917939 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 15:13:56.923140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 15:13:56.923846 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 15:13:56.932667 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 15:13:57.193073 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:13:57.194056 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:13:57.194884 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:13:57.195698 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:13:57.196508 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:13:57.197320 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:13:57.198143 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:13:57.198953 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:13:57.200261 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:13:57.201098 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:13:57.201930 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:13:57.202705 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:13:57.203475 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:13:57.204318 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:13:57.205109 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:13:57.205907 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:13:57.207094 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:13:57.207929 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:13:57.208694 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:13:57.209477 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:13:57.210240 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:13:57.211006 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:13:57.211775 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:13:57.212625 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:13:57.311057 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 15:13:57.311629 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 15:13:57.341177 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 15:13:57.366508 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 15:13:57.396365 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 15:13:57.397023 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 15:13:57.425193 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 15:13:57.457767 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 15:13:57.589757 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 15:13:57.616780 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:13:57.617376 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 15:13:57.644627 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:13:57.672531 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 15:13:57.695123 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:13:57.724127 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:13:57.724796 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 15:13:57.753161 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:13:57.780756 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 15:13:57.803115 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:13:57.828565 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:13:57.829150 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 15:13:57.855569 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:13:57.884167 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 15:13:57.911272 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:13:57.941397 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:13:57.942019 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 15:13:57.969879 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:13:57.997605 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 15:13:58.020527 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:13:58.048854 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:13:58.049685 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 15:13:58.083679 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:13:58.113433 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:13:58.136832 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:13:58.163429 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:13:58.163969 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 15:13:58.191270 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:13:58.219777 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:13:58.242546 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:13:58.270120 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:13:58.270699 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 15:13:58.299814 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:13:58.327476 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:13:58.349937 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:13:58.375963 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:13:58.376514 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 15:13:58.403951 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:13:58.433324 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:13:58.456577 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:13:58.483309 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:13:58.483852 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 15:13:58.511107 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:13:58.539869 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:13:58.562810 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:13:58.590704 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:13:58.591287 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 15:13:58.620238 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:13:58.649525 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 15:13:58.671677 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:13:58.698085 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:13:58.698618 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 15:13:58.731237 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:13:58.763992 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:13:58.787398 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:13:58.815040 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:13:58.815596 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 15:13:58.846229 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:13:58.877031 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:13:58.900910 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:13:58.928239 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:13:58.928814 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 15:13:58.961164 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:13:58.992597 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:13:59.018544 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:13:59.044526 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:13:59.045069 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 15:13:59.080324 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:13:59.116384 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:13:59.140023 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:13:59.165454 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 15:14:02.012460 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 15:14:02.012807 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 15:14:02.261985 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 15:14:02.264012 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 15:14:02.265467 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 15:14:02.267022 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 15:14:02.268499 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 15:14:02.270039 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 15:14:02.273186 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 15:14:02.274776 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 15:14:09.982717 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 15:14:11.914508 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 15:14:11.914700 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 15:14:11.920296 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 15:14:11.920433 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 15:14:11.920525 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 15:14:11.920632 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 15:14:11.920759 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 15:14:11.925406 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 15:14:11.925517 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 15:14:13.454055 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 15:14:13.455179 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 15:14:17.564044 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 15:14:17.571611: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 15:14:17.571850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 15:14:17.571879: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 15:14:17.676390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:14:17.677075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 15:14:17.677104: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 15:14:17.677311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:14:17.677860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 15:14:17.677920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:14:17.677975: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 15:14:17.678005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 15:14:17.678032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 15:14:17.678058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 15:14:17.678083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 15:14:17.678109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:14:17.678192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:14:17.678778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:14:17.679268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 15:14:17.679367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:14:18.245475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 15:14:18.245530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 15:14:18.245541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 15:14:18.245796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:14:18.246395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:14:18.246928: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 15:14:18.246981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424
I1010 15:14:18.249214 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-1424
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 15:14:19.916845 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 15:14:20.779896 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 15:14:20.933321 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1424...
I1010 15:14:31.604066 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1424...
INFO:tensorflow:Saving checkpoints for 1424 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:14:31.617551 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1424 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1424...
I1010 15:14:34.203141 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1424...
2020-10-10 15:14:43.740125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:14:45.762814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.6013853, step = 1424
I1010 15:14:46.793045 140455904991104 basic_session_run_hooks.py:262] loss = 0.6013853, step = 1424
INFO:tensorflow:box_loss = 0.0020986078, cls_loss = 0.4002533, det_loss = 0.5051837, step = 1424
I1010 15:14:46.793815 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0020986078, cls_loss = 0.4002533, det_loss = 0.5051837, step = 1424
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1524...
I1010 15:15:24.262130 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1524...
INFO:tensorflow:Saving checkpoints for 1524 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:15:24.262506 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1524 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 15:15:24.327692 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1524...
I1010 15:15:26.035881 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1524...
INFO:tensorflow:global_step/sec: 2.52518
I1010 15:15:26.393293 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.52518
INFO:tensorflow:loss = 0.69334984, step = 1524 (39.603 sec)
I1010 15:15:26.396171 140455904991104 basic_session_run_hooks.py:260] loss = 0.69334984, step = 1524 (39.603 sec)
INFO:tensorflow:box_loss = 0.0029958275, cls_loss = 0.44726562, det_loss = 0.597057, step = 1524 (39.603 sec)
I1010 15:15:26.396357 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0029958275, cls_loss = 0.44726562, det_loss = 0.597057, step = 1524 (39.603 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1624...
I1010 15:15:55.042738 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1624...
INFO:tensorflow:Saving checkpoints for 1624 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:15:55.042979 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1624 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1624...
I1010 15:15:56.776210 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1624...
INFO:tensorflow:global_step/sec: 3.25373
I1010 15:15:57.127218 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25373
INFO:tensorflow:loss = 0.8241811, step = 1624 (30.732 sec)
I1010 15:15:57.128104 140455904991104 basic_session_run_hooks.py:260] loss = 0.8241811, step = 1624 (30.732 sec)
INFO:tensorflow:box_loss = 0.0056078946, cls_loss = 0.44743156, det_loss = 0.7278263, step = 1624 (30.732 sec)
I1010 15:15:57.128385 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0056078946, cls_loss = 0.44743156, det_loss = 0.7278263, step = 1624 (30.732 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1724...
I1010 15:16:25.965047 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1724...
INFO:tensorflow:Saving checkpoints for 1724 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:16:25.965322 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1724 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1724...
I1010 15:16:27.717427 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1724...
INFO:tensorflow:global_step/sec: 3.23842
I1010 15:16:28.006495 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.23842
INFO:tensorflow:loss = 0.60220945, step = 1724 (30.879 sec)
I1010 15:16:28.007388 140455904991104 basic_session_run_hooks.py:260] loss = 0.60220945, step = 1724 (30.879 sec)
INFO:tensorflow:box_loss = 0.0022878265, cls_loss = 0.39139557, det_loss = 0.5057869, step = 1724 (30.879 sec)
I1010 15:16:28.007577 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0022878265, cls_loss = 0.39139557, det_loss = 0.5057869, step = 1724 (30.879 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1824...
I1010 15:16:57.111344 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1824...
INFO:tensorflow:Saving checkpoints for 1824 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:16:57.111586 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1824 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1824...
I1010 15:16:58.847773 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1824...
INFO:tensorflow:global_step/sec: 3.2138
I1010 15:16:59.122339 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.2138
INFO:tensorflow:loss = 0.6408595, step = 1824 (31.116 sec)
I1010 15:16:59.123265 140455904991104 basic_session_run_hooks.py:260] loss = 0.6408595, step = 1824 (31.116 sec)
INFO:tensorflow:box_loss = 0.002928017, cls_loss = 0.39797974, det_loss = 0.5443806, step = 1824 (31.116 sec)
I1010 15:16:59.123484 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.002928017, cls_loss = 0.39797974, det_loss = 0.5443806, step = 1824 (31.116 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1924...
I1010 15:17:27.935759 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 1924...
INFO:tensorflow:Saving checkpoints for 1924 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:17:27.936004 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 1924 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1924...
I1010 15:17:29.651512 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 1924...
INFO:tensorflow:global_step/sec: 3.24473
I1010 15:17:29.941548 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24473
INFO:tensorflow:loss = 0.6426134, step = 1924 (30.819 sec)
I1010 15:17:29.942441 140455904991104 basic_session_run_hooks.py:260] loss = 0.6426134, step = 1924 (30.819 sec)
INFO:tensorflow:box_loss = 0.0033695805, cls_loss = 0.377594, det_loss = 0.546073, step = 1924 (30.819 sec)
I1010 15:17:29.942626 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0033695805, cls_loss = 0.377594, det_loss = 0.546073, step = 1924 (30.819 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2024...
I1010 15:17:59.068028 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2024...
INFO:tensorflow:Saving checkpoints for 2024 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:17:59.068251 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2024 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2024...
I1010 15:18:00.790692 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2024...
INFO:tensorflow:global_step/sec: 3.21327
I1010 15:18:01.062589 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.21327
INFO:tensorflow:loss = 0.7286018, step = 2024 (31.121 sec)
I1010 15:18:01.063818 140455904991104 basic_session_run_hooks.py:260] loss = 0.7286018, step = 2024 (31.121 sec)
INFO:tensorflow:box_loss = 0.0045345123, cls_loss = 0.40527725, det_loss = 0.63200283, step = 2024 (31.122 sec)
I1010 15:18:01.064162 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0045345123, cls_loss = 0.40527725, det_loss = 0.63200283, step = 2024 (31.122 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2124...
I1010 15:18:29.836459 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2124...
INFO:tensorflow:Saving checkpoints for 2124 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:18:29.836733 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2124 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2124...
I1010 15:18:31.578753 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2124...
INFO:tensorflow:global_step/sec: 3.24228
I1010 15:18:31.904996 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24228
INFO:tensorflow:loss = 0.9728697, step = 2124 (30.842 sec)
I1010 15:18:31.905972 140455904991104 basic_session_run_hooks.py:260] loss = 0.9728697, step = 2124 (30.842 sec)
INFO:tensorflow:box_loss = 0.0057173413, cls_loss = 0.5903473, det_loss = 0.8762144, step = 2124 (30.842 sec)
I1010 15:18:31.906179 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0057173413, cls_loss = 0.5903473, det_loss = 0.8762144, step = 2124 (30.842 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2136...
I1010 15:18:35.133163 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2136...
INFO:tensorflow:Saving checkpoints for 2136 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:18:35.133378 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2136 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2136...
I1010 15:18:36.858949 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2136...
INFO:tensorflow:Loss for final step: 0.6448556.
I1010 15:18:37.222475 140455904991104 estimator.py:350] Loss for final step: 0.6448556.
INFO:tensorflow:Calling model_fn.
I1010 15:18:37.715264 140455904991104 estimator.py:1162] Calling model_fn.
I1010 15:18:37.715583 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 15:18:37.719165 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 15:18:37.947802 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:18:37.948617 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:18:37.949399 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:18:37.950168 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:18:37.950917 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:18:37.951734 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:18:37.952491 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:18:37.953280 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:18:37.954411 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:18:37.955134 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:18:37.955898 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:18:37.956780 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:18:37.957626 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:18:37.958396 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:18:37.959132 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:18:37.959878 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:18:37.961080 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:18:37.961826 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:18:37.962586 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:18:37.963326 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:18:37.964062 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:18:37.964813 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:18:37.965548 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:18:37.966345 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:18:38.255735 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 15:18:38.256319 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 15:18:38.277897 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 15:18:38.300913 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 15:18:38.321034 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 15:18:38.321689 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 15:18:38.344098 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 15:18:38.365600 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 15:18:38.388828 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 15:18:38.414601 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:18:38.415375 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 15:18:38.442326 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:18:38.464168 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 15:18:38.487540 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:18:38.510681 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:18:38.511287 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 15:18:38.532218 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:18:38.553240 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 15:18:38.574700 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:18:38.594680 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:18:38.595223 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 15:18:38.616012 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:18:38.636888 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 15:18:38.660300 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:18:38.682111 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:18:38.682695 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 15:18:38.705520 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:18:38.734500 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 15:18:38.757962 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:18:38.777752 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:18:38.778303 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 15:18:38.799208 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:18:38.820558 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:18:38.844434 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:18:38.865114 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:18:38.865712 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 15:18:38.886425 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:18:38.908016 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:18:38.931370 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:18:38.952008 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:18:38.952554 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 15:18:38.973025 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:18:38.994328 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:18:39.019117 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:18:39.039492 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:18:39.040082 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 15:18:39.061270 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:18:39.082392 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:18:39.106338 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:18:39.127384 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:18:39.127957 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 15:18:39.150578 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:18:39.172664 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:18:39.196105 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:18:39.217193 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:18:39.217801 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 15:18:39.241085 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:18:39.266853 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 15:18:39.291533 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:18:39.314437 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:18:39.315052 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 15:18:39.340723 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:18:39.365761 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:18:39.388954 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:18:39.415353 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:18:39.416116 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 15:18:39.451384 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:18:39.482263 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:18:39.508876 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:18:39.528543 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:18:39.529141 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 15:18:39.553477 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:18:39.578778 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:18:39.604366 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:18:39.629275 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:18:39.629861 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 15:18:39.658283 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:18:39.687594 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:18:39.711847 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:18:39.732546 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 15:18:42.103888 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 15:18:42.104158 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 15:18:42.377264 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 15:18:42.544667 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 15:18:42.583730 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T15:18:42Z
I1010 15:18:42.599168 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T15:18:42Z
INFO:tensorflow:Graph was finalized.
I1010 15:18:43.472738 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 15:18:43.473429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:18:43.473988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 15:18:43.474054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:18:43.474118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 15:18:43.474143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 15:18:43.474169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 15:18:43.474192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 15:18:43.474213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 15:18:43.474236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:18:43.474321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:18:43.474835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:18:43.475287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 15:18:43.475345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 15:18:43.475360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 15:18:43.475370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 15:18:43.475466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:18:43.476014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:18:43.476529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136
I1010 15:18:43.477525 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136
INFO:tensorflow:Running local_init_op.
I1010 15:18:44.719788 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 15:18:44.784380 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 15:21:07.798982 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 15:23:29.629389 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 15:25:57.833217 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 15:28:22.528963 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 15:30:44.440864 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 15:33:09.057305 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 15:35:33.412152 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 15:37:54.309345 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 15:40:16.513912 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 15:42:37.377306 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 15:42:41.521307 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1499.74707s
I1010 15:43:42.346455 140455904991104 evaluation.py:273] Inference Time : 1499.74707s
INFO:tensorflow:Finished evaluation at 2020-10-10-15:43:42
I1010 15:43:42.346719 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-15:43:42
INFO:tensorflow:Saving dict for global step 2136: AP = 0.28196448, AP50 = 0.41377237, AP75 = 0.3177586, APl = 0.34091988, APm = 0.32793722, APs = 0.07634371, ARl = 0.7203471, ARm = 0.520906, ARmax1 = 0.4060753, ARmax10 = 0.57909185, ARmax100 = 0.61692584, ARs = 0.18825032, box_loss = 0.003116418, cls_loss = 0.3743604, global_step = 2136, loss = 0.62684125
I1010 15:43:42.346893 140455904991104 estimator.py:2063] Saving dict for global step 2136: AP = 0.28196448, AP50 = 0.41377237, AP75 = 0.3177586, APl = 0.34091988, APm = 0.32793722, APs = 0.07634371, ARl = 0.7203471, ARm = 0.520906, ARmax1 = 0.4060753, ARmax10 = 0.57909185, ARmax100 = 0.61692584, ARs = 0.18825032, box_loss = 0.003116418, cls_loss = 0.3743604, global_step = 2136, loss = 0.62684125
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2136: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136
I1010 15:43:43.356096 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 2136: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136
I1010 15:43:43.363502 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-2136 is not in all_model_checkpoint_paths. Manually adding it.
I1010 15:43:43.400125 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-2136 is not in all_model_checkpoint_paths. Manually adding it.
I1010 15:43:43.400690 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 3.

   =====> Starting evaluation, epoch: 3.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.93s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=45.68s).
Accumulating evaluation results...
DONE (t=9.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.406
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 15:43:43.592383 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 15:43:43.605184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 15:43:43.638513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:43:43.639137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 15:43:43.639185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:43:43.642899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 15:43:43.645773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 15:43:43.646175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 15:43:43.649223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 15:43:43.650457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 15:43:43.655371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:43:43.655516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:43:43.656091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:43:43.656595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 15:43:43.921796 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 15:43:44.292059 140455904991104 estimator.py:1162] Calling model_fn.
I1010 15:43:44.292390 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 15:43:44.297362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 15:43:44.298055 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 15:43:44.306736 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 15:43:44.549433 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:43:44.550374 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:43:44.551182 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:43:44.551972 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:43:44.552786 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:43:44.553622 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:43:44.554434 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:43:44.555179 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:43:44.556442 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:43:44.557175 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:43:44.557913 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:43:44.558627 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:43:44.559354 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:43:44.560143 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:43:44.560898 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:43:44.561696 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:43:44.562832 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:43:44.563563 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:43:44.564368 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:43:44.565207 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:43:44.566020 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:43:44.566794 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:43:44.567521 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:43:44.568389 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:43:44.664672 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 15:43:44.665219 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 15:43:44.692125 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 15:43:44.714076 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 15:43:44.739859 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 15:43:44.740434 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 15:43:44.766214 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 15:43:44.797799 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 15:43:44.944259 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 15:43:44.969843 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:43:44.970413 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 15:43:44.996420 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:43:45.023878 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 15:43:45.046594 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:43:45.072332 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:43:45.072983 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 15:43:45.103104 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:43:45.131534 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 15:43:45.154201 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:43:45.180055 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:43:45.180691 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 15:43:45.207893 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:43:45.236887 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 15:43:45.259340 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:43:45.290355 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:43:45.291063 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 15:43:45.318756 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:43:45.348049 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 15:43:45.370415 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:43:45.399242 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:43:45.399823 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 15:43:45.427026 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:43:45.455200 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:43:45.477415 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:43:45.503873 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:43:45.504475 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 15:43:45.532074 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:43:45.559697 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:43:45.581836 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:43:45.614067 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:43:45.614617 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 15:43:45.645592 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:43:45.677803 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:43:45.701773 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:43:45.727513 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:43:45.728108 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 15:43:45.754599 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:43:45.782231 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:43:45.804518 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:43:45.832027 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:43:45.832559 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 15:43:45.858795 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:43:45.892225 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:43:45.916964 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:43:45.942742 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:43:45.943359 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 15:43:45.969801 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:43:45.997198 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 15:43:46.022859 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:43:46.050952 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:43:46.051505 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 15:43:46.082953 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:43:46.115381 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:43:46.138346 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:43:46.163171 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:43:46.163716 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 15:43:46.194540 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:43:46.229056 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:43:46.253090 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:43:46.279502 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:43:46.280086 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 15:43:46.317363 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:43:46.349629 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:43:46.373870 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:43:46.400415 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:43:46.401021 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 15:43:46.430938 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:43:46.461364 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:43:46.484538 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:43:46.512782 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 15:43:49.297530 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 15:43:49.297895 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 15:43:49.537326 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 15:43:49.539068 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 15:43:49.540627 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 15:43:49.542264 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 15:43:49.543875 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 15:43:49.545484 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 15:43:49.548659 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 15:43:49.550196 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 15:43:57.178264 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 15:43:59.141224 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 15:43:59.141398 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 15:43:59.146971 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 15:43:59.147105 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 15:43:59.147193 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 15:43:59.147299 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 15:43:59.147376 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 15:43:59.152092 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 15:43:59.152205 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 15:44:00.687741 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 15:44:00.688834 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 15:44:04.731186 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 15:44:04.737769: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 15:44:04.737989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 15:44:04.738018: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 15:44:04.836181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:44:04.836878: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 15:44:04.836909: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 15:44:04.837128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:44:04.837657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 15:44:04.837707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:44:04.837757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 15:44:04.837779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 15:44:04.837796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 15:44:04.837813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 15:44:04.837850: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 15:44:04.837872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:44:04.837954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:44:04.838512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:44:04.839009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 15:44:04.839104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:44:05.402447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 15:44:05.402506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 15:44:05.402518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 15:44:05.402795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:44:05.403666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:44:05.404207: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 15:44:05.404253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136
I1010 15:44:05.406623 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2136
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 15:44:07.097526 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 15:44:07.970025 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 15:44:08.128313 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2136...
I1010 15:44:18.902829 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2136...
INFO:tensorflow:Saving checkpoints for 2136 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:44:18.918599 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2136 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2136...
I1010 15:44:21.731064 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2136...
2020-10-10 15:44:31.764451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:44:33.793293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.6832155, step = 2136
I1010 15:44:34.741066 140455904991104 basic_session_run_hooks.py:262] loss = 0.6832155, step = 2136
INFO:tensorflow:box_loss = 0.00393204, cls_loss = 0.3899536, det_loss = 0.5865556, step = 2136
I1010 15:44:34.741873 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.00393204, cls_loss = 0.3899536, det_loss = 0.5865556, step = 2136
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2236...
I1010 15:45:11.819511 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2236...
INFO:tensorflow:Saving checkpoints for 2236 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:45:11.819789 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2236 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 15:45:11.880600 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2236...
I1010 15:45:13.565705 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2236...
INFO:tensorflow:global_step/sec: 2.55403
I1010 15:45:13.894015 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.55403
INFO:tensorflow:loss = 0.5098969, step = 2236 (39.154 sec)
I1010 15:45:13.894967 140455904991104 basic_session_run_hooks.py:260] loss = 0.5098969, step = 2236 (39.154 sec)
INFO:tensorflow:box_loss = 0.0016060333, cls_loss = 0.33289337, det_loss = 0.41319504, step = 2236 (39.153 sec)
I1010 15:45:13.895161 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0016060333, cls_loss = 0.33289337, det_loss = 0.41319504, step = 2236 (39.153 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2336...
I1010 15:45:42.671819 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2336...
INFO:tensorflow:Saving checkpoints for 2336 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:45:42.672054 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2336 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2336...
I1010 15:45:44.420030 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2336...
INFO:tensorflow:global_step/sec: 3.24367
I1010 15:45:44.723270 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24367
INFO:tensorflow:loss = 0.7431993, step = 2336 (30.830 sec)
I1010 15:45:44.725043 140455904991104 basic_session_run_hooks.py:260] loss = 0.7431993, step = 2336 (30.830 sec)
INFO:tensorflow:box_loss = 0.004142525, cls_loss = 0.4393158, det_loss = 0.64644206, step = 2336 (30.830 sec)
I1010 15:45:44.725333 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.004142525, cls_loss = 0.4393158, det_loss = 0.64644206, step = 2336 (30.830 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2436...
I1010 15:46:13.467758 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2436...
INFO:tensorflow:Saving checkpoints for 2436 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:46:13.468048 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2436 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2436...
I1010 15:46:15.234719 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2436...
INFO:tensorflow:global_step/sec: 3.24262
I1010 15:46:15.562487 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24262
INFO:tensorflow:loss = 0.61247325, step = 2436 (30.839 sec)
I1010 15:46:15.563570 140455904991104 basic_session_run_hooks.py:260] loss = 0.61247325, step = 2436 (30.839 sec)
INFO:tensorflow:box_loss = 0.0028795085, cls_loss = 0.37168884, det_loss = 0.5156643, step = 2436 (30.838 sec)
I1010 15:46:15.563804 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0028795085, cls_loss = 0.37168884, det_loss = 0.5156643, step = 2436 (30.838 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2536...
I1010 15:46:44.313046 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2536...
INFO:tensorflow:Saving checkpoints for 2536 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:46:44.313290 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2536 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2536...
I1010 15:46:46.010332 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2536...
INFO:tensorflow:global_step/sec: 3.25152
I1010 15:46:46.317381 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25152
INFO:tensorflow:loss = 0.5777077, step = 2536 (30.755 sec)
I1010 15:46:46.318512 140455904991104 basic_session_run_hooks.py:260] loss = 0.5777077, step = 2536 (30.755 sec)
INFO:tensorflow:box_loss = 0.0030210458, cls_loss = 0.32980347, det_loss = 0.48085576, step = 2536 (30.755 sec)
I1010 15:46:46.318768 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0030210458, cls_loss = 0.32980347, det_loss = 0.48085576, step = 2536 (30.755 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2636...
I1010 15:47:15.118947 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2636...
INFO:tensorflow:Saving checkpoints for 2636 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:47:15.119307 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2636 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2636...
I1010 15:47:16.843503 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2636...
INFO:tensorflow:global_step/sec: 3.24538
I1010 15:47:17.130489 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24538
INFO:tensorflow:loss = 0.6304165, step = 2636 (30.813 sec)
I1010 15:47:17.131880 140455904991104 basic_session_run_hooks.py:260] loss = 0.6304165, step = 2636 (30.813 sec)
INFO:tensorflow:box_loss = 0.0032617792, cls_loss = 0.37043762, det_loss = 0.53352654, step = 2636 (30.813 sec)
I1010 15:47:17.132086 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0032617792, cls_loss = 0.37043762, det_loss = 0.53352654, step = 2636 (30.813 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2736...
I1010 15:47:45.783109 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2736...
INFO:tensorflow:Saving checkpoints for 2736 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:47:45.783347 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2736 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2736...
I1010 15:47:47.505860 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2736...
INFO:tensorflow:global_step/sec: 3.26319
I1010 15:47:47.775282 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.26319
INFO:tensorflow:loss = 0.7452961, step = 2736 (30.644 sec)
I1010 15:47:47.776208 140455904991104 basic_session_run_hooks.py:260] loss = 0.7452961, step = 2736 (30.644 sec)
INFO:tensorflow:box_loss = 0.0045490717, cls_loss = 0.42092705, det_loss = 0.64838064, step = 2736 (30.644 sec)
I1010 15:47:47.776533 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0045490717, cls_loss = 0.42092705, det_loss = 0.64838064, step = 2736 (30.644 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2807 vs previous value: 2807. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1010 15:48:08.425480 140455904991104 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2807 vs previous value: 2807. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2836...
I1010 15:48:16.589571 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2836...
INFO:tensorflow:Saving checkpoints for 2836 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:48:16.589857 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2836 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2836...
I1010 15:48:18.308092 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2836...
INFO:tensorflow:global_step/sec: 3.24113
I1010 15:48:18.628760 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24113
INFO:tensorflow:loss = 0.72525764, step = 2836 (30.854 sec)
I1010 15:48:18.629838 140455904991104 basic_session_run_hooks.py:260] loss = 0.72525764, step = 2836 (30.854 sec)
INFO:tensorflow:box_loss = 0.0033933125, cls_loss = 0.45865083, det_loss = 0.62831646, step = 2836 (30.854 sec)
I1010 15:48:18.630037 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0033933125, cls_loss = 0.45865083, det_loss = 0.62831646, step = 2836 (30.854 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2848...
I1010 15:48:21.978501 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2848...
INFO:tensorflow:Saving checkpoints for 2848 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 15:48:21.978741 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2848 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2848...
I1010 15:48:23.722251 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2848...
INFO:tensorflow:Loss for final step: 0.5695781.
I1010 15:48:24.109690 140455904991104 estimator.py:350] Loss for final step: 0.5695781.
INFO:tensorflow:Calling model_fn.
I1010 15:48:24.581160 140455904991104 estimator.py:1162] Calling model_fn.
I1010 15:48:24.581501 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 15:48:24.585266 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 15:48:24.829678 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:48:24.830516 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:48:24.831281 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:48:24.832056 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:48:24.832814 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:48:24.833618 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:48:24.834382 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:48:24.835231 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:48:24.836549 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:48:24.837399 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:48:24.838439 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:48:24.839333 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:48:24.840137 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:48:24.840926 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:48:24.841677 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:48:24.842420 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:48:24.843630 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 15:48:24.844380 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 15:48:24.845136 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 15:48:24.845880 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 15:48:24.846670 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 15:48:24.847413 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 15:48:24.848183 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 15:48:24.848988 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 15:48:25.158374 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 15:48:25.159002 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 15:48:25.184282 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 15:48:25.210997 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 15:48:25.234708 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 15:48:25.235438 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 15:48:25.255826 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 15:48:25.280437 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 15:48:25.306327 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 15:48:25.328202 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:48:25.328801 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 15:48:25.349683 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:48:25.370899 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 15:48:25.396111 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:48:25.416047 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 15:48:25.416631 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 15:48:25.437482 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 15:48:25.458190 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 15:48:25.480040 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 15:48:25.501558 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:48:25.502192 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 15:48:25.522629 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:48:25.548553 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 15:48:25.574281 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:48:25.597193 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 15:48:25.597826 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 15:48:25.618630 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 15:48:25.647821 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 15:48:25.671078 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 15:48:25.692852 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:48:25.693559 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 15:48:25.714719 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:48:25.735791 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:48:25.758684 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:48:25.778500 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:48:25.779198 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 15:48:25.801192 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:48:25.822743 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:48:25.847378 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:48:25.867826 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 15:48:25.868414 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 15:48:25.889123 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 15:48:25.911661 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 15:48:25.934696 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 15:48:25.954377 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:48:25.955012 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 15:48:25.975603 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:48:25.999500 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:48:26.022611 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:48:26.048296 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:48:26.048922 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 15:48:26.070336 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:48:26.092755 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 15:48:26.117206 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:48:26.139083 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 15:48:26.139721 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 15:48:26.160605 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 15:48:26.182515 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 15:48:26.209362 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 15:48:26.232487 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:48:26.233074 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 15:48:26.260802 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:48:26.287365 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:48:26.311554 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:48:26.332235 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:48:26.332792 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 15:48:26.357266 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:48:26.381986 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:48:26.405535 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:48:26.425461 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:48:26.426073 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 15:48:26.453581 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:48:26.478979 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:48:26.505207 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:48:26.525078 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 15:48:26.525658 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 15:48:26.550453 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 15:48:26.576254 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 15:48:26.600310 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 15:48:26.619826 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 15:48:28.957609 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 15:48:28.957896 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 15:48:29.232735 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 15:48:29.399511 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 15:48:29.439329 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T15:48:29Z
I1010 15:48:29.454009 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T15:48:29Z
INFO:tensorflow:Graph was finalized.
I1010 15:48:30.298371 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 15:48:30.299091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:48:30.299587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 15:48:30.299668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 15:48:30.299730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 15:48:30.299756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 15:48:30.299773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 15:48:30.299796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 15:48:30.299816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 15:48:30.299839: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 15:48:30.299928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:48:30.300501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:48:30.300978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 15:48:30.301040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 15:48:30.301078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 15:48:30.301089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 15:48:30.301202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:48:30.301753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 15:48:30.302233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848
I1010 15:48:30.303176 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848
INFO:tensorflow:Running local_init_op.
I1010 15:48:31.503611 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 15:48:31.569420 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 15:51:10.405010 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 15:53:45.317113 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 15:56:26.948369 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 15:59:05.834362 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 16:01:41.728745 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 16:04:16.131917 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 16:06:52.861703 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 16:09:26.719041 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 16:12:03.401554 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 16:14:39.926914 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 16:14:44.518137 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1635.95266s
I1010 16:15:45.406836 140455904991104 evaluation.py:273] Inference Time : 1635.95266s
INFO:tensorflow:Finished evaluation at 2020-10-10-16:15:45
I1010 16:15:45.407077 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-16:15:45
INFO:tensorflow:Saving dict for global step 2848: AP = 0.3046164, AP50 = 0.4396982, AP75 = 0.34774622, APl = 0.37037638, APm = 0.3556012, APs = 0.09426783, ARl = 0.73243606, ARm = 0.53772986, ARmax1 = 0.41327786, ARmax10 = 0.59193546, ARmax100 = 0.63267434, ARs = 0.20686059, box_loss = 0.0030035202, cls_loss = 0.3516661, global_step = 2848, loss = 0.5987863
I1010 16:15:45.407252 140455904991104 estimator.py:2063] Saving dict for global step 2848: AP = 0.3046164, AP50 = 0.4396982, AP75 = 0.34774622, APl = 0.37037638, APm = 0.3556012, APs = 0.09426783, ARl = 0.73243606, ARm = 0.53772986, ARmax1 = 0.41327786, ARmax10 = 0.59193546, ARmax100 = 0.63267434, ARs = 0.20686059, box_loss = 0.0030035202, cls_loss = 0.3516661, global_step = 2848, loss = 0.5987863
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2848: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848
I1010 16:15:46.456285 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 2848: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848
I1010 16:15:46.464054 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-2848 is not in all_model_checkpoint_paths. Manually adding it.
I1010 16:15:46.504952 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-2848 is not in all_model_checkpoint_paths. Manually adding it.
I1010 16:15:46.505540 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 4.

   =====> Starting evaluation, epoch: 4.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.98s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=46.21s).
Accumulating evaluation results...
DONE (t=8.90s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.413
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 16:15:46.696167 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 16:15:46.708502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 16:15:46.741588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:15:46.742214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 16:15:46.742269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:15:46.749961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 16:15:46.753252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 16:15:46.753878: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 16:15:46.757874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 16:15:46.759221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 16:15:46.764618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:15:46.764766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:15:46.765415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:15:46.766016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 16:15:47.046409 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 16:15:47.413783 140455904991104 estimator.py:1162] Calling model_fn.
I1010 16:15:47.414110 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 16:15:47.419188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 16:15:47.419921 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 16:15:47.428653 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 16:15:47.683530 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:15:47.684490 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:15:47.685379 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:15:47.686186 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:15:47.687014 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:15:47.687873 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:15:47.688811 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:15:47.689719 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:15:47.691290 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:15:47.692117 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:15:47.692968 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:15:47.693813 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:15:47.694621 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:15:47.695509 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:15:47.696324 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:15:47.697435 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:15:47.698889 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:15:47.699884 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:15:47.700841 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:15:47.701803 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:15:47.702734 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:15:47.703612 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:15:47.704552 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:15:47.705446 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:15:47.802006 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 16:15:47.802607 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 16:15:47.832103 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 16:15:47.855966 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 16:15:47.882968 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 16:15:47.883611 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 16:15:47.911013 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 16:15:47.940856 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 16:15:48.091360 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 16:15:48.119224 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:15:48.119923 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 16:15:48.149830 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:15:48.178808 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 16:15:48.201808 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:15:48.230287 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:15:48.231017 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 16:15:48.257977 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:15:48.286446 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 16:15:48.309891 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:15:48.336956 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:15:48.337547 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 16:15:48.367689 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:15:48.396053 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 16:15:48.421145 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:15:48.450278 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:15:48.451043 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 16:15:48.478967 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:15:48.507762 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 16:15:48.536167 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:15:48.563068 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:15:48.563675 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 16:15:48.590216 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:15:48.618326 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:15:48.641701 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:15:48.672417 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:15:48.673078 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 16:15:48.704104 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:15:48.736295 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:15:48.762974 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:15:48.792071 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:15:48.792664 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 16:15:48.821048 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:15:48.850857 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:15:48.874485 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:15:48.901939 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:15:48.902559 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 16:15:48.930280 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:15:48.960976 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:15:48.985592 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:15:49.018928 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:15:49.019739 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 16:15:49.048664 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:15:49.078008 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:15:49.101818 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:15:49.128476 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:15:49.129171 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 16:15:49.157494 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:15:49.185991 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 16:15:49.208611 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:15:49.236324 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:15:49.236921 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 16:15:49.271616 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:15:49.304000 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:15:49.327261 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:15:49.354171 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:15:49.354802 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 16:15:49.386359 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:15:49.417466 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:15:49.441795 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:15:49.467993 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:15:49.468577 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 16:15:49.498810 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:15:49.529750 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:15:49.557653 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:15:49.589045 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:15:49.589699 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 16:15:49.624660 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:15:49.658054 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:15:49.682983 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:15:49.709201 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 16:15:52.598446 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 16:15:52.598789 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 16:15:52.836524 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 16:15:52.838132 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 16:15:52.839703 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 16:15:52.841221 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 16:15:52.842662 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 16:15:52.844077 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 16:15:52.846882 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 16:15:52.848348 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 16:16:00.499783 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 16:16:02.416701 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 16:16:02.416874 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 16:16:02.422885 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 16:16:02.423022 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 16:16:02.423112 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 16:16:02.423216 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 16:16:02.423295 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 16:16:02.428237 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 16:16:02.428354 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 16:16:03.924507 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 16:16:03.925594 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 16:16:08.081306 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 16:16:08.088660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 16:16:08.088913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 16:16:08.088940: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 16:16:08.189788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:16:08.190438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 16:16:08.190471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 16:16:08.190715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:16:08.191226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 16:16:08.191272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:16:08.191323: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 16:16:08.191344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 16:16:08.191362: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 16:16:08.191381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 16:16:08.191401: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 16:16:08.191421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:16:08.191497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:16:08.192092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:16:08.192570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 16:16:08.192685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:16:08.759241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 16:16:08.759300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 16:16:08.759312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 16:16:08.759545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:16:08.760178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:16:08.760692: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 16:16:08.760737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848
I1010 16:16:08.762809 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-2848
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 16:16:10.552294 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 16:16:11.474738 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 16:16:11.633758 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2848...
I1010 16:16:22.507270 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2848...
INFO:tensorflow:Saving checkpoints for 2848 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:16:22.521368 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2848 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2848...
I1010 16:16:25.218742 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2848...
2020-10-10 16:16:35.421688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:16:37.456124: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.506087, step = 2848
I1010 16:16:38.432341 140455904991104 basic_session_run_hooks.py:262] loss = 0.506087, step = 2848
INFO:tensorflow:box_loss = 0.0023161545, cls_loss = 0.29333496, det_loss = 0.40914267, step = 2848
I1010 16:16:38.432931 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0023161545, cls_loss = 0.29333496, det_loss = 0.40914267, step = 2848
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2948...
I1010 16:17:15.788335 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2948...
INFO:tensorflow:Saving checkpoints for 2948 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:17:15.788620 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 2948 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 16:17:15.853378 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2948...
I1010 16:17:17.609524 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2948...
INFO:tensorflow:global_step/sec: 2.52997
I1010 16:17:17.957688 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.52997
INFO:tensorflow:loss = 0.8528302, step = 2948 (39.527 sec)
I1010 16:17:17.958853 140455904991104 basic_session_run_hooks.py:260] loss = 0.8528302, step = 2948 (39.527 sec)
INFO:tensorflow:box_loss = 0.005478371, cls_loss = 0.4819417, det_loss = 0.7558602, step = 2948 (39.526 sec)
I1010 16:17:17.959084 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.005478371, cls_loss = 0.4819417, det_loss = 0.7558602, step = 2948 (39.526 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3048...
I1010 16:17:46.857510 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3048...
INFO:tensorflow:Saving checkpoints for 3048 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:17:46.857784 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3048 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3048...
I1010 16:17:48.581291 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3048...
INFO:tensorflow:global_step/sec: 3.22775
I1010 16:17:48.938914 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.22775
INFO:tensorflow:loss = 0.5822239, step = 3048 (30.981 sec)
I1010 16:17:48.939897 140455904991104 basic_session_run_hooks.py:260] loss = 0.5822239, step = 3048 (30.981 sec)
INFO:tensorflow:box_loss = 0.0029032438, cls_loss = 0.34007263, det_loss = 0.48523483, step = 3048 (30.981 sec)
I1010 16:17:48.940093 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0029032438, cls_loss = 0.34007263, det_loss = 0.48523483, step = 3048 (30.981 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3148...
I1010 16:18:17.623728 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3148...
INFO:tensorflow:Saving checkpoints for 3148 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:18:17.623975 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3148 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3148...
I1010 16:18:19.351265 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3148...
INFO:tensorflow:global_step/sec: 3.25054
I1010 16:18:19.702999 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25054
INFO:tensorflow:loss = 0.7488479, step = 3148 (30.764 sec)
I1010 16:18:19.703872 140455904991104 basic_session_run_hooks.py:260] loss = 0.7488479, step = 3148 (30.764 sec)
INFO:tensorflow:box_loss = 0.0041386555, cls_loss = 0.44491577, det_loss = 0.65184855, step = 3148 (30.764 sec)
I1010 16:18:19.704072 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0041386555, cls_loss = 0.44491577, det_loss = 0.65184855, step = 3148 (30.764 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3248...
I1010 16:18:48.211940 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3248...
INFO:tensorflow:Saving checkpoints for 3248 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:18:48.212270 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3248 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3248...
I1010 16:18:49.945837 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3248...
INFO:tensorflow:global_step/sec: 3.27129
I1010 16:18:50.271966 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.27129
INFO:tensorflow:loss = 0.60712993, step = 3248 (30.569 sec)
I1010 16:18:50.272970 140455904991104 basic_session_run_hooks.py:260] loss = 0.60712993, step = 3248 (30.569 sec)
INFO:tensorflow:box_loss = 0.0026448101, cls_loss = 0.3778839, det_loss = 0.51012444, step = 3248 (30.569 sec)
I1010 16:18:50.273156 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0026448101, cls_loss = 0.3778839, det_loss = 0.51012444, step = 3248 (30.569 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3348...
I1010 16:19:19.216552 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3348...
INFO:tensorflow:Saving checkpoints for 3348 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:19:19.216805 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3348 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3348...
I1010 16:19:20.994744 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3348...
INFO:tensorflow:global_step/sec: 3.2231
I1010 16:19:21.297970 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.2231
INFO:tensorflow:loss = 0.56661373, step = 3348 (31.026 sec)
I1010 16:19:21.298868 140455904991104 basic_session_run_hooks.py:260] loss = 0.56661373, step = 3348 (31.026 sec)
INFO:tensorflow:box_loss = 0.0021716356, cls_loss = 0.36101532, det_loss = 0.4695971, step = 3348 (31.026 sec)
I1010 16:19:21.299057 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0021716356, cls_loss = 0.36101532, det_loss = 0.4695971, step = 3348 (31.026 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3448...
I1010 16:19:50.185514 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3448...
INFO:tensorflow:Saving checkpoints for 3448 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:19:50.185798 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3448 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3448...
I1010 16:19:51.940361 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3448...
INFO:tensorflow:global_step/sec: 3.23023
I1010 16:19:52.255547 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.23023
INFO:tensorflow:loss = 0.65627134, step = 3448 (30.958 sec)
I1010 16:19:52.256428 140455904991104 basic_session_run_hooks.py:260] loss = 0.65627134, step = 3448 (30.958 sec)
INFO:tensorflow:box_loss = 0.0032164557, cls_loss = 0.39842606, det_loss = 0.5592488, step = 3448 (30.958 sec)
I1010 16:19:52.256616 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0032164557, cls_loss = 0.39842606, det_loss = 0.5592488, step = 3448 (30.958 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3548...
I1010 16:20:21.210007 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3548...
INFO:tensorflow:Saving checkpoints for 3548 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:20:21.210260 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3548 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3548...
I1010 16:20:23.014518 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3548...
INFO:tensorflow:global_step/sec: 3.21291
I1010 16:20:23.380017 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.21291
INFO:tensorflow:loss = 0.47656658, step = 3548 (31.125 sec)
I1010 16:20:23.380962 140455904991104 basic_session_run_hooks.py:260] loss = 0.47656658, step = 3548 (31.125 sec)
INFO:tensorflow:box_loss = 0.0022657614, cls_loss = 0.2662506, det_loss = 0.37953869, step = 3548 (31.125 sec)
I1010 16:20:23.381243 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0022657614, cls_loss = 0.2662506, det_loss = 0.37953869, step = 3548 (31.125 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3560...
I1010 16:20:26.699331 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3560...
INFO:tensorflow:Saving checkpoints for 3560 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:20:26.699739 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3560 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3560...
I1010 16:20:28.457506 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3560...
INFO:tensorflow:Loss for final step: 0.72420377.
I1010 16:20:28.838749 140455904991104 estimator.py:350] Loss for final step: 0.72420377.
INFO:tensorflow:Calling model_fn.
I1010 16:20:29.315916 140455904991104 estimator.py:1162] Calling model_fn.
I1010 16:20:29.316252 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 16:20:29.319883 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 16:20:29.557962 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:20:29.558798 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:20:29.559555 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:20:29.560319 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:20:29.561080 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:20:29.561971 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:20:29.562737 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:20:29.563475 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:20:29.564661 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:20:29.565383 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:20:29.566144 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:20:29.566997 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:20:29.567775 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:20:29.568514 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:20:29.569257 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:20:29.569995 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:20:29.571181 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:20:29.571908 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:20:29.572627 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:20:29.573441 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:20:29.574222 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:20:29.574974 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:20:29.575795 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:20:29.576651 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:20:29.885620 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 16:20:29.886195 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 16:20:29.908086 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 16:20:29.930879 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 16:20:29.954261 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 16:20:29.954915 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 16:20:29.977514 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 16:20:30.001429 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 16:20:30.024020 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 16:20:30.044576 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:20:30.045189 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 16:20:30.065977 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:20:30.086977 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 16:20:30.112301 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:20:30.132603 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:20:30.133215 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 16:20:30.153609 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:20:30.175014 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 16:20:30.197850 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:20:30.218075 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:20:30.218675 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 16:20:30.239209 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:20:30.260358 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 16:20:30.283106 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:20:30.305495 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:20:30.306432 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 16:20:30.327929 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:20:30.351310 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 16:20:30.373610 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:20:30.393631 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:20:30.394367 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 16:20:30.419772 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:20:30.443663 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:20:30.469370 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:20:30.489717 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:20:30.490324 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 16:20:30.510613 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:20:30.531967 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:20:30.557972 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:20:30.580121 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:20:30.580744 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 16:20:30.601496 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:20:30.622835 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:20:30.645717 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:20:30.665116 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:20:30.665743 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 16:20:30.687434 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:20:30.711742 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:20:30.735913 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:20:30.756340 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:20:30.756955 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 16:20:30.777456 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:20:30.798856 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:20:30.821655 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:20:30.842197 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:20:30.842868 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 16:20:30.869071 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:20:30.890671 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 16:20:30.913477 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:20:30.933554 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:20:30.934112 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 16:20:30.957901 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:20:30.982992 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:20:31.008934 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:20:31.029746 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:20:31.030319 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 16:20:31.054532 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:20:31.079699 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:20:31.105847 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:20:31.127199 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:20:31.127924 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 16:20:31.156158 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:20:31.182735 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:20:31.208207 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:20:31.229385 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:20:31.230019 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 16:20:31.255517 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:20:31.281871 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:20:31.310132 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:20:31.331272 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 16:20:33.714843 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 16:20:33.715098 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 16:20:33.984545 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 16:20:34.150763 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 16:20:34.193090 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T16:20:34Z
I1010 16:20:34.210710 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T16:20:34Z
INFO:tensorflow:Graph was finalized.
I1010 16:20:35.101696 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 16:20:35.102400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:20:35.102982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 16:20:35.103048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:20:35.103114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 16:20:35.103138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 16:20:35.103170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 16:20:35.103193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 16:20:35.103212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 16:20:35.103235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:20:35.103329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:20:35.103972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:20:35.104415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 16:20:35.104471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 16:20:35.104488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 16:20:35.104497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 16:20:35.104619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:20:35.105152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:20:35.105603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560
I1010 16:20:35.106565 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560
INFO:tensorflow:Running local_init_op.
I1010 16:20:36.358044 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 16:20:36.425000 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 16:23:15.584977 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 16:25:47.876137 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 16:28:31.724040 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 16:31:12.063520 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 16:33:49.380195 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 16:36:35.791869 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 16:39:22.282244 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 16:42:05.289454 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 16:44:44.222347 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 16:47:18.648883 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 16:47:23.552282 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1669.79336s
I1010 16:48:24.004286 140455904991104 evaluation.py:273] Inference Time : 1669.79336s
INFO:tensorflow:Finished evaluation at 2020-10-10-16:48:24
I1010 16:48:24.004533 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-16:48:24
INFO:tensorflow:Saving dict for global step 3560: AP = 0.33416688, AP50 = 0.44803447, AP75 = 0.3835842, APl = 0.404173, APm = 0.4142366, APs = 0.103778325, ARl = 0.7860309, ARm = 0.5728276, ARmax1 = 0.46075332, ARmax10 = 0.6397715, ARmax100 = 0.6791887, ARs = 0.23395379, box_loss = 0.0025543126, cls_loss = 0.29988602, global_step = 3560, loss = 0.5246283
I1010 16:48:24.004741 140455904991104 estimator.py:2063] Saving dict for global step 3560: AP = 0.33416688, AP50 = 0.44803447, AP75 = 0.3835842, APl = 0.404173, APm = 0.4142366, APs = 0.103778325, ARl = 0.7860309, ARm = 0.5728276, ARmax1 = 0.46075332, ARmax10 = 0.6397715, ARmax100 = 0.6791887, ARs = 0.23395379, box_loss = 0.0025543126, cls_loss = 0.29988602, global_step = 3560, loss = 0.5246283
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3560: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560
I1010 16:48:25.056812 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 3560: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560
I1010 16:48:25.065103 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-3560 is not in all_model_checkpoint_paths. Manually adding it.
I1010 16:48:25.104061 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-3560 is not in all_model_checkpoint_paths. Manually adding it.
I1010 16:48:25.104706 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 5.

   =====> Starting evaluation, epoch: 5.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.95s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=45.57s).
Accumulating evaluation results...
DONE (t=9.14s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.461
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 16:48:25.308423 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 16:48:25.322268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 16:48:25.358067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:25.358713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 16:48:25.358764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:48:25.362355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 16:48:25.365036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 16:48:25.365427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 16:48:25.368503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 16:48:25.369770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 16:48:25.374890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:48:25.375024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:25.375595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:25.376116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 16:48:25.651110 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 16:48:26.044976 140455904991104 estimator.py:1162] Calling model_fn.
I1010 16:48:26.045313 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 16:48:26.051387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 16:48:26.052239 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 16:48:26.061206 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 16:48:26.315179 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:48:26.316090 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:48:26.316911 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:48:26.317674 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:48:26.318434 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:48:26.319204 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:48:26.320412 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:48:26.321791 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:48:26.323801 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:48:26.325087 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:48:26.326249 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:48:26.327389 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:48:26.328660 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:48:26.329976 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:48:26.331269 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:48:26.332431 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:48:26.334301 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:48:26.335564 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:48:26.336860 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:48:26.338192 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:48:26.339437 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:48:26.340911 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:48:26.342158 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:48:26.343155 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:48:26.439496 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 16:48:26.440165 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 16:48:26.468333 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 16:48:26.492053 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 16:48:26.518490 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 16:48:26.519186 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 16:48:26.547734 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 16:48:26.575531 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 16:48:26.715506 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 16:48:26.744004 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:48:26.744659 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 16:48:26.771650 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:48:26.805517 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 16:48:26.832843 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:48:26.865239 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:48:26.866067 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 16:48:26.897756 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:48:26.930167 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 16:48:26.952951 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:48:26.978666 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:48:26.979228 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 16:48:27.008002 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:48:27.041879 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 16:48:27.069975 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:48:27.103487 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:48:27.104459 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 16:48:27.138082 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:48:27.175354 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 16:48:27.201292 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:48:27.228100 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:48:27.228733 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 16:48:27.256329 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:48:27.284955 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:48:27.309788 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:48:27.337592 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:48:27.338240 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 16:48:27.366256 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:48:27.394683 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:48:27.418835 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:48:27.445770 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:48:27.446354 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 16:48:27.473036 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:48:27.501014 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:48:27.523494 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:48:27.549397 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:48:27.549979 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 16:48:27.576281 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:48:27.604542 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:48:27.626575 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:48:27.652187 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:48:27.652813 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 16:48:27.681733 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:48:27.712971 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:48:27.736234 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:48:27.762808 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:48:27.763484 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 16:48:27.791052 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:48:27.819494 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 16:48:27.842913 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:48:27.869065 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:48:27.869735 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 16:48:27.901699 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:48:27.934168 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:48:27.958018 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:48:27.984811 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:48:27.985429 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 16:48:28.021893 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:48:28.053860 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:48:28.086785 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:48:28.119941 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:48:28.120696 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 16:48:28.157593 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:48:28.195453 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:48:28.223998 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:48:28.251705 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:48:28.252314 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 16:48:28.284039 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:48:28.317188 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:48:28.342368 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:48:28.368626 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 16:48:31.224805 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 16:48:31.225107 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 16:48:31.460132 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 16:48:31.461794 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 16:48:31.463304 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 16:48:31.464759 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 16:48:31.466122 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 16:48:31.467459 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 16:48:31.470294 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 16:48:31.471767 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 16:48:39.119956 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 16:48:41.068665 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 16:48:41.068831 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 16:48:41.074567 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 16:48:41.074727 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 16:48:41.074812 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 16:48:41.074908 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 16:48:41.074986 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 16:48:41.079885 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 16:48:41.080004 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 16:48:42.588690 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 16:48:42.589772 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 16:48:46.736698 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 16:48:46.743538: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 16:48:46.743775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 16:48:46.743804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 16:48:46.844652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:46.845304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 16:48:46.845337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 16:48:46.845576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:46.846123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 16:48:46.846172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:48:46.846225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 16:48:46.846247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 16:48:46.846264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 16:48:46.846285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 16:48:46.846304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 16:48:46.846324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:48:46.846407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:46.846980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:46.847470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 16:48:46.847567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:48:47.418431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 16:48:47.418488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 16:48:47.418499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 16:48:47.418782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:47.419422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:48:47.419978: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 16:48:47.420025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560
I1010 16:48:47.422143 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-3560
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 16:48:49.134102 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 16:48:50.023970 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 16:48:50.191233 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3560...
I1010 16:49:00.889962 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3560...
INFO:tensorflow:Saving checkpoints for 3560 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:49:00.903406 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3560 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3560...
I1010 16:49:03.553018 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3560...
2020-10-10 16:49:13.439888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:49:15.424416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.40854225, step = 3560
I1010 16:49:16.424084 140455904991104 basic_session_run_hooks.py:262] loss = 0.40854225, step = 3560
INFO:tensorflow:box_loss = 0.0014679193, cls_loss = 0.23811913, det_loss = 0.3115151, step = 3560
I1010 16:49:16.424578 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0014679193, cls_loss = 0.23811913, det_loss = 0.3115151, step = 3560
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3660...
I1010 16:49:54.106890 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3660...
INFO:tensorflow:Saving checkpoints for 3660 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:49:54.107152 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3660 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 16:49:54.169766 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3660...
I1010 16:49:55.897984 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3660...
INFO:tensorflow:global_step/sec: 2.51137
I1010 16:49:56.241940 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.51137
INFO:tensorflow:loss = 0.49448055, step = 3660 (39.819 sec)
I1010 16:49:56.242949 140455904991104 basic_session_run_hooks.py:260] loss = 0.49448055, step = 3660 (39.819 sec)
INFO:tensorflow:box_loss = 0.0023859015, cls_loss = 0.2781582, det_loss = 0.39745325, step = 3660 (39.819 sec)
I1010 16:49:56.243165 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0023859015, cls_loss = 0.2781582, det_loss = 0.39745325, step = 3660 (39.819 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3760...
I1010 16:50:25.195918 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3760...
INFO:tensorflow:Saving checkpoints for 3760 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:50:25.196189 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3760 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3760...
I1010 16:50:27.001969 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3760...
INFO:tensorflow:global_step/sec: 3.21851
I1010 16:50:27.312222 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.21851
INFO:tensorflow:loss = 0.63486403, step = 3760 (31.070 sec)
I1010 16:50:27.313245 140455904991104 basic_session_run_hooks.py:260] loss = 0.63486403, step = 3760 (31.070 sec)
INFO:tensorflow:box_loss = 0.0043236855, cls_loss = 0.32165337, det_loss = 0.5378377, step = 3760 (31.070 sec)
I1010 16:50:27.313457 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0043236855, cls_loss = 0.32165337, det_loss = 0.5378377, step = 3760 (31.070 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3860...
I1010 16:50:56.388506 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3860...
INFO:tensorflow:Saving checkpoints for 3860 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:50:56.388738 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3860 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3860...
I1010 16:50:58.158188 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3860...
INFO:tensorflow:global_step/sec: 3.20357
I1010 16:50:58.527354 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.20357
INFO:tensorflow:loss = 0.52768445, step = 3860 (31.215 sec)
I1010 16:50:58.528290 140455904991104 basic_session_run_hooks.py:260] loss = 0.52768445, step = 3860 (31.215 sec)
INFO:tensorflow:box_loss = 0.0018739215, cls_loss = 0.33695984, det_loss = 0.4306559, step = 3860 (31.215 sec)
I1010 16:50:58.528582 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0018739215, cls_loss = 0.33695984, det_loss = 0.4306559, step = 3860 (31.215 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3960...
I1010 16:51:27.599405 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 3960...
INFO:tensorflow:Saving checkpoints for 3960 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:51:27.599677 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 3960 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3960...
I1010 16:51:29.316292 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 3960...
INFO:tensorflow:global_step/sec: 3.21576
I1010 16:51:29.624243 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.21576
INFO:tensorflow:loss = 0.62035185, step = 3960 (31.097 sec)
I1010 16:51:29.625260 140455904991104 basic_session_run_hooks.py:260] loss = 0.62035185, step = 3960 (31.097 sec)
INFO:tensorflow:box_loss = 0.0036344202, cls_loss = 0.34160614, det_loss = 0.5233271, step = 3960 (31.097 sec)
I1010 16:51:29.625449 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0036344202, cls_loss = 0.34160614, det_loss = 0.5233271, step = 3960 (31.097 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4060...
I1010 16:51:58.452371 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4060...
INFO:tensorflow:Saving checkpoints for 4060 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:51:58.452598 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4060 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4060...
I1010 16:52:00.187814 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4060...
INFO:tensorflow:global_step/sec: 3.23973
I1010 16:52:00.491038 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.23973
INFO:tensorflow:loss = 0.6296171, step = 4060 (30.867 sec)
I1010 16:52:00.491913 140455904991104 basic_session_run_hooks.py:260] loss = 0.6296171, step = 4060 (30.867 sec)
INFO:tensorflow:box_loss = 0.0041225334, cls_loss = 0.32646942, det_loss = 0.5325961, step = 4060 (30.867 sec)
I1010 16:52:00.492255 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0041225334, cls_loss = 0.32646942, det_loss = 0.5325961, step = 4060 (30.867 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4097 vs previous value: 4097. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1010 16:52:11.209102 140455904991104 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4097 vs previous value: 4097. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4160...
I1010 16:52:29.456562 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4160...
INFO:tensorflow:Saving checkpoints for 4160 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:52:29.456831 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4160 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4160...
I1010 16:52:31.204268 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4160...
INFO:tensorflow:global_step/sec: 3.22035
I1010 16:52:31.543552 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.22035
INFO:tensorflow:loss = 0.48628542, step = 4160 (31.053 sec)
I1010 16:52:31.544597 140455904991104 basic_session_run_hooks.py:260] loss = 0.48628542, step = 4160 (31.053 sec)
INFO:tensorflow:box_loss = 0.002348811, cls_loss = 0.2718277, det_loss = 0.38926822, step = 4160 (31.053 sec)
I1010 16:52:31.544812 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.002348811, cls_loss = 0.2718277, det_loss = 0.38926822, step = 4160 (31.053 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4260...
I1010 16:53:00.312889 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4260...
INFO:tensorflow:Saving checkpoints for 4260 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:53:00.313102 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4260 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4260...
I1010 16:53:02.046219 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4260...
INFO:tensorflow:global_step/sec: 3.23892
I1010 16:53:02.418046 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.23892
INFO:tensorflow:loss = 0.34112626, step = 4260 (30.874 sec)
I1010 16:53:02.419069 140455904991104 basic_session_run_hooks.py:260] loss = 0.34112626, step = 4260 (30.874 sec)
INFO:tensorflow:box_loss = 0.0008059238, cls_loss = 0.20381927, det_loss = 0.24411547, step = 4260 (30.875 sec)
I1010 16:53:02.419352 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0008059238, cls_loss = 0.20381927, det_loss = 0.24411547, step = 4260 (30.875 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4272...
I1010 16:53:05.706915 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4272...
INFO:tensorflow:Saving checkpoints for 4272 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 16:53:05.707163 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4272 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4272...
I1010 16:53:07.445953 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4272...
INFO:tensorflow:Loss for final step: 0.5328071.
I1010 16:53:07.817127 140455904991104 estimator.py:350] Loss for final step: 0.5328071.
INFO:tensorflow:Calling model_fn.
I1010 16:53:08.295101 140455904991104 estimator.py:1162] Calling model_fn.
I1010 16:53:08.295407 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 16:53:08.298781 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 16:53:08.537395 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:53:08.538295 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:53:08.539196 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:53:08.540052 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:53:08.540845 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:53:08.541777 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:53:08.542532 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:53:08.543389 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:53:08.544572 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:53:08.545306 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:53:08.546080 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:53:08.546984 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:53:08.547740 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:53:08.548474 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:53:08.549255 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:53:08.550010 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:53:08.551311 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 16:53:08.552094 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 16:53:08.552937 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 16:53:08.553714 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 16:53:08.554442 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 16:53:08.555191 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 16:53:08.555950 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 16:53:08.556761 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 16:53:08.867247 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 16:53:08.867808 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 16:53:08.889208 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 16:53:08.911856 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 16:53:08.932190 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 16:53:08.932776 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 16:53:08.953289 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 16:53:08.974190 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 16:53:08.997310 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 16:53:09.017283 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:53:09.017847 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 16:53:09.039284 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:53:09.060408 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 16:53:09.083309 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:53:09.111562 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 16:53:09.112287 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 16:53:09.138754 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 16:53:09.163844 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 16:53:09.187450 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 16:53:09.208220 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:53:09.208779 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 16:53:09.230183 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:53:09.251600 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 16:53:09.274900 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:53:09.295522 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 16:53:09.296173 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 16:53:09.317228 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 16:53:09.338770 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 16:53:09.361392 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 16:53:09.381422 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:53:09.381994 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 16:53:09.406461 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:53:09.427482 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:53:09.452960 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:53:09.478537 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:53:09.479121 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 16:53:09.500294 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:53:09.521864 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:53:09.544944 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:53:09.564622 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 16:53:09.565217 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 16:53:09.586000 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 16:53:09.607747 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 16:53:09.631927 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 16:53:09.654886 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:53:09.655755 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 16:53:09.680086 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:53:09.708273 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:53:09.736049 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:53:09.757175 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:53:09.757765 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 16:53:09.780209 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:53:09.802806 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 16:53:09.825514 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:53:09.852997 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 16:53:09.853724 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 16:53:09.875618 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 16:53:09.900014 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 16:53:09.923390 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 16:53:09.944267 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:53:09.944868 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 16:53:09.970311 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:53:09.996267 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:53:10.021145 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:53:10.042080 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:53:10.042633 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 16:53:10.067152 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:53:10.092999 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:53:10.123268 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:53:10.148150 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:53:10.148897 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 16:53:10.177708 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:53:10.204170 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:53:10.229367 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:53:10.250842 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 16:53:10.251420 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 16:53:10.277247 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 16:53:10.304580 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 16:53:10.329222 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 16:53:10.349396 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 16:53:12.720051 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 16:53:12.720315 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 16:53:12.997520 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 16:53:13.164880 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 16:53:13.204782 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T16:53:13Z
I1010 16:53:13.221262 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T16:53:13Z
INFO:tensorflow:Graph was finalized.
I1010 16:53:14.136960 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 16:53:14.137689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:53:14.138211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 16:53:14.138276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 16:53:14.138335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 16:53:14.138364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 16:53:14.138386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 16:53:14.138410: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 16:53:14.138434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 16:53:14.138460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 16:53:14.138555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:53:14.139125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:53:14.139526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 16:53:14.139606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 16:53:14.139623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 16:53:14.139632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 16:53:14.139750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:53:14.140218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 16:53:14.140655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272
I1010 16:53:14.141831 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272
INFO:tensorflow:Running local_init_op.
I1010 16:53:15.396073 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 16:53:15.460577 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 16:56:01.000359 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 16:58:41.130930 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 17:01:26.712513 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 17:04:07.196249 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 17:06:42.853916 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 17:09:19.225577 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 17:11:55.913570 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 17:14:31.570193 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 17:17:08.216443 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 17:19:42.704090 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 17:19:47.505964 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1654.76675s
I1010 17:20:47.988214 140455904991104 evaluation.py:273] Inference Time : 1654.76675s
INFO:tensorflow:Finished evaluation at 2020-10-10-17:20:47
I1010 17:20:47.988440 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-17:20:47
INFO:tensorflow:Saving dict for global step 4272: AP = 0.36082676, AP50 = 0.47525904, AP75 = 0.41320953, APl = 0.43924052, APm = 0.44448784, APs = 0.11641234, ARl = 0.79765576, ARm = 0.59559256, ARmax1 = 0.47340283, ARmax10 = 0.65587515, ARmax100 = 0.6938537, ARs = 0.24625657, box_loss = 0.002350629, cls_loss = 0.27578008, global_step = 4272, loss = 0.49032202
I1010 17:20:47.988605 140455904991104 estimator.py:2063] Saving dict for global step 4272: AP = 0.36082676, AP50 = 0.47525904, AP75 = 0.41320953, APl = 0.43924052, APm = 0.44448784, APs = 0.11641234, ARl = 0.79765576, ARm = 0.59559256, ARmax1 = 0.47340283, ARmax10 = 0.65587515, ARmax100 = 0.6938537, ARs = 0.24625657, box_loss = 0.002350629, cls_loss = 0.27578008, global_step = 4272, loss = 0.49032202
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4272: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272
I1010 17:20:48.951550 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 4272: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272
I1010 17:20:48.959727 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-4272 is not in all_model_checkpoint_paths. Manually adding it.
I1010 17:20:48.996868 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-4272 is not in all_model_checkpoint_paths. Manually adding it.
I1010 17:20:48.997376 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 6.

   =====> Starting evaluation, epoch: 6.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.84s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=46.16s).
Accumulating evaluation results...
DONE (t=8.73s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.439
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.473
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.246
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 17:20:49.188181 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 17:20:49.200565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 17:20:49.238290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:20:49.238864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 17:20:49.238913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:20:49.242799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 17:20:49.245577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 17:20:49.245971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 17:20:49.249033: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 17:20:49.250296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 17:20:49.255124: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:20:49.255249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:20:49.255830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:20:49.256334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 17:20:49.525366 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 17:20:49.887364 140455904991104 estimator.py:1162] Calling model_fn.
I1010 17:20:49.887694 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 17:20:49.892403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 17:20:49.893086 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 17:20:49.901892 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 17:20:50.137392 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:20:50.138231 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:20:50.138995 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:20:50.139746 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:20:50.140496 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:20:50.141315 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:20:50.142083 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:20:50.142849 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:20:50.144076 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:20:50.144832 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:20:50.145562 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:20:50.146282 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:20:50.147025 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:20:50.147829 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:20:50.148585 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:20:50.149335 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:20:50.150460 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:20:50.151204 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:20:50.151956 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:20:50.152748 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:20:50.153497 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:20:50.154260 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:20:50.155019 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:20:50.155772 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:20:50.253715 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 17:20:50.254264 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 17:20:50.282374 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 17:20:50.305047 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 17:20:50.331619 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 17:20:50.332191 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 17:20:50.359525 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 17:20:50.387013 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 17:20:50.520931 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 17:20:50.547449 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:20:50.548027 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 17:20:50.577605 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:20:50.605583 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 17:20:50.628437 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:20:50.655957 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:20:50.656563 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 17:20:50.683582 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:20:50.711729 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 17:20:50.737079 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:20:50.765987 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:20:50.766546 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 17:20:50.793183 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:20:50.821757 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 17:20:50.844212 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:20:50.869832 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:20:50.870403 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 17:20:50.896748 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:20:50.923834 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 17:20:50.953623 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:20:50.982787 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:20:50.983330 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 17:20:51.010024 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:20:51.041101 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:20:51.063245 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:20:51.088865 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:20:51.089384 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 17:20:51.116455 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:20:51.144520 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:20:51.167661 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:20:51.197789 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:20:51.198590 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 17:20:51.230116 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:20:51.264943 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:20:51.289993 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:20:51.318173 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:20:51.318713 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 17:20:51.350034 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:20:51.380990 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:20:51.406109 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:20:51.435530 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:20:51.436153 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 17:20:51.469387 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:20:51.501276 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:20:51.526623 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:20:51.553458 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:20:51.554113 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 17:20:51.580598 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:20:51.607810 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 17:20:51.633209 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:20:51.661192 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:20:51.661798 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 17:20:51.693735 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:20:51.725897 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:20:51.749688 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:20:51.776717 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:20:51.777319 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 17:20:51.809140 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:20:51.840667 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:20:51.863700 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:20:51.892225 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:20:51.892773 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 17:20:51.923527 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:20:51.959798 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:20:51.984123 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:20:52.010327 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:20:52.010917 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 17:20:52.041946 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:20:52.075675 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:20:52.099601 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:20:52.125376 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 17:20:54.894595 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 17:20:54.894928 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 17:20:55.120150 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 17:20:55.121670 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 17:20:55.123064 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 17:20:55.124402 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 17:20:55.125770 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 17:20:55.127104 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 17:20:55.129986 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 17:20:55.131380 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 17:21:02.658914 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 17:21:04.521676 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 17:21:04.521849 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 17:21:04.527234 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 17:21:04.527362 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 17:21:04.527449 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 17:21:04.527541 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 17:21:04.527615 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 17:21:04.532191 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 17:21:04.532303 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 17:21:06.043678 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 17:21:06.044721 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 17:21:10.073410 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 17:21:10.080792: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 17:21:10.081040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 17:21:10.081067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 17:21:10.178731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:21:10.179485: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 17:21:10.179528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 17:21:10.179754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:21:10.180314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 17:21:10.180368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:21:10.180419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 17:21:10.180443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 17:21:10.180461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 17:21:10.180485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 17:21:10.180506: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 17:21:10.180527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:21:10.180606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:21:10.181202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:21:10.181723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 17:21:10.181829: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:21:10.752781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 17:21:10.752855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 17:21:10.752868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 17:21:10.753104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:21:10.753725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:21:10.754230: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 17:21:10.754274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272
I1010 17:21:10.756351 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4272
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 17:21:12.407082 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 17:21:13.230764 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 17:21:13.379171 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4272...
I1010 17:21:23.827359 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4272...
INFO:tensorflow:Saving checkpoints for 4272 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:21:23.840854 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4272 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4272...
I1010 17:21:26.415429 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4272...
2020-10-10 17:21:35.677856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:21:37.638599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.47349447, step = 4272
I1010 17:21:38.627018 140455904991104 basic_session_run_hooks.py:262] loss = 0.47349447, step = 4272
INFO:tensorflow:box_loss = 0.0023116355, cls_loss = 0.2609024, det_loss = 0.3764842, step = 4272
I1010 17:21:38.627534 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0023116355, cls_loss = 0.2609024, det_loss = 0.3764842, step = 4272
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4372...
I1010 17:22:15.178930 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4372...
INFO:tensorflow:Saving checkpoints for 4372 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:22:15.179218 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4372 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 17:22:15.243403 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4372...
I1010 17:22:16.894947 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4372...
INFO:tensorflow:global_step/sec: 2.59222
I1010 17:22:17.203146 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.59222
INFO:tensorflow:loss = 0.62189984, step = 4372 (38.577 sec)
I1010 17:22:17.204156 140455904991104 basic_session_run_hooks.py:260] loss = 0.62189984, step = 4372 (38.577 sec)
INFO:tensorflow:box_loss = 0.0033330563, cls_loss = 0.35824108, det_loss = 0.5248939, step = 4372 (38.577 sec)
I1010 17:22:17.204447 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0033330563, cls_loss = 0.35824108, det_loss = 0.5248939, step = 4372 (38.577 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4472...
I1010 17:22:45.606076 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4472...
INFO:tensorflow:Saving checkpoints for 4472 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:22:45.606328 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4472 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4472...
I1010 17:22:47.350963 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4472...
INFO:tensorflow:global_step/sec: 3.28612
I1010 17:22:47.634161 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.28612
INFO:tensorflow:loss = 0.41483116, step = 4472 (30.431 sec)
I1010 17:22:47.635073 140455904991104 basic_session_run_hooks.py:260] loss = 0.41483116, step = 4472 (30.431 sec)
INFO:tensorflow:box_loss = 0.0020676046, cls_loss = 0.21445274, det_loss = 0.31783295, step = 4472 (30.431 sec)
I1010 17:22:47.635261 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0020676046, cls_loss = 0.21445274, det_loss = 0.31783295, step = 4472 (30.431 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4572...
I1010 17:23:16.303666 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4572...
INFO:tensorflow:Saving checkpoints for 4572 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:23:16.303970 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4572 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4572...
I1010 17:23:18.047200 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4572...
INFO:tensorflow:global_step/sec: 3.25068
I1010 17:23:18.396924 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25068
INFO:tensorflow:loss = 0.40816787, step = 4572 (30.763 sec)
I1010 17:23:18.397913 140455904991104 basic_session_run_hooks.py:260] loss = 0.40816787, step = 4572 (30.763 sec)
INFO:tensorflow:box_loss = 0.0015560611, cls_loss = 0.23337364, det_loss = 0.3111767, step = 4572 (30.763 sec)
I1010 17:23:18.398133 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0015560611, cls_loss = 0.23337364, det_loss = 0.3111767, step = 4572 (30.763 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4672...
I1010 17:23:46.950004 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4672...
INFO:tensorflow:Saving checkpoints for 4672 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:23:46.950214 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4672 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4672...
I1010 17:23:48.663914 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4672...
INFO:tensorflow:global_step/sec: 3.27004
I1010 17:23:48.977625 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.27004
INFO:tensorflow:loss = 0.44830307, step = 4672 (30.581 sec)
I1010 17:23:48.978497 140455904991104 basic_session_run_hooks.py:260] loss = 0.44830307, step = 4672 (30.581 sec)
INFO:tensorflow:box_loss = 0.0021121423, cls_loss = 0.24571228, det_loss = 0.3513194, step = 4672 (30.581 sec)
I1010 17:23:48.978804 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0021121423, cls_loss = 0.24571228, det_loss = 0.3513194, step = 4672 (30.581 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4772...
I1010 17:24:17.530271 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4772...
INFO:tensorflow:Saving checkpoints for 4772 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:24:17.530515 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4772 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4772...
I1010 17:24:19.295119 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4772...
INFO:tensorflow:global_step/sec: 3.27013
I1010 17:24:19.557453 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.27013
INFO:tensorflow:loss = 0.60842794, step = 4772 (30.580 sec)
I1010 17:24:19.558495 140455904991104 basic_session_run_hooks.py:260] loss = 0.60842794, step = 4772 (30.580 sec)
INFO:tensorflow:box_loss = 0.003130943, cls_loss = 0.35490417, det_loss = 0.51145136, step = 4772 (30.580 sec)
I1010 17:24:19.558712 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.003130943, cls_loss = 0.35490417, det_loss = 0.51145136, step = 4772 (30.580 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4872...
I1010 17:24:48.090898 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4872...
INFO:tensorflow:Saving checkpoints for 4872 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:24:48.091154 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4872 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4872...
I1010 17:24:49.782323 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4872...
INFO:tensorflow:global_step/sec: 3.27456
I1010 17:24:50.095871 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.27456
INFO:tensorflow:loss = 0.3782215, step = 4872 (30.538 sec)
I1010 17:24:50.096938 140455904991104 basic_session_run_hooks.py:260] loss = 0.3782215, step = 4872 (30.538 sec)
INFO:tensorflow:box_loss = 0.0013940721, cls_loss = 0.21154785, det_loss = 0.28125146, step = 4872 (30.539 sec)
I1010 17:24:50.097283 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0013940721, cls_loss = 0.21154785, det_loss = 0.28125146, step = 4872 (30.539 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4972...
I1010 17:25:18.464443 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4972...
INFO:tensorflow:Saving checkpoints for 4972 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:25:18.464682 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4972 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4972...
I1010 17:25:20.144465 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4972...
INFO:tensorflow:global_step/sec: 3.28735
I1010 17:25:20.515551 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.28735
INFO:tensorflow:loss = 0.4321556, step = 4972 (30.420 sec)
I1010 17:25:20.516513 140455904991104 basic_session_run_hooks.py:260] loss = 0.4321556, step = 4972 (30.420 sec)
INFO:tensorflow:box_loss = 0.0013992541, cls_loss = 0.26522827, det_loss = 0.33519095, step = 4972 (30.419 sec)
I1010 17:25:20.516719 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0013992541, cls_loss = 0.26522827, det_loss = 0.33519095, step = 4972 (30.419 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4984...
I1010 17:25:23.713634 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4984...
INFO:tensorflow:Saving checkpoints for 4984 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:25:23.713899 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4984 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4984...
I1010 17:25:25.409896 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4984...
INFO:tensorflow:Loss for final step: 0.65108156.
I1010 17:25:25.779444 140455904991104 estimator.py:350] Loss for final step: 0.65108156.
INFO:tensorflow:Calling model_fn.
I1010 17:25:26.253247 140455904991104 estimator.py:1162] Calling model_fn.
I1010 17:25:26.253530 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 17:25:26.256925 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 17:25:26.493730 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:25:26.494567 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:25:26.495358 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:25:26.496121 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:25:26.496992 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:25:26.497859 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:25:26.498610 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:25:26.499383 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:25:26.500526 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:25:26.501267 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:25:26.502018 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:25:26.502845 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:25:26.503581 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:25:26.504332 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:25:26.505111 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:25:26.505891 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:25:26.507085 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:25:26.507836 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:25:26.508579 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:25:26.509325 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:25:26.510080 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:25:26.510836 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:25:26.511577 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:25:26.512393 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:25:26.800154 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 17:25:26.800760 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 17:25:26.824748 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 17:25:26.854348 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 17:25:26.877753 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 17:25:26.878394 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 17:25:26.899514 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 17:25:26.920584 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 17:25:26.943035 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 17:25:26.963249 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:25:26.963790 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 17:25:26.984145 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:25:27.012933 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 17:25:27.036870 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:25:27.056901 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:25:27.057563 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 17:25:27.077743 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:25:27.101573 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 17:25:27.123581 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:25:27.143337 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:25:27.143902 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 17:25:27.165111 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:25:27.186094 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 17:25:27.208753 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:25:27.230120 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:25:27.230791 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 17:25:27.251989 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:25:27.273125 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 17:25:27.300708 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:25:27.323709 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:25:27.324261 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 17:25:27.345849 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:25:27.367130 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:25:27.394616 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:25:27.414690 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:25:27.415297 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 17:25:27.435787 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:25:27.456429 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:25:27.478256 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:25:27.498055 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:25:27.498582 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 17:25:27.521787 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:25:27.544323 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:25:27.566935 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:25:27.587122 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:25:27.587866 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 17:25:27.608983 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:25:27.630144 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:25:27.652042 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:25:27.672398 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:25:27.672934 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 17:25:27.694577 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:25:27.715771 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:25:27.738523 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:25:27.758009 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:25:27.758659 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 17:25:27.779077 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:25:27.800501 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 17:25:27.823771 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:25:27.843191 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:25:27.843735 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 17:25:27.867428 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:25:27.897303 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:25:27.923429 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:25:27.946655 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:25:27.947270 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 17:25:27.971692 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:25:27.996874 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:25:28.024614 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:25:28.047610 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:25:28.048148 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 17:25:28.072698 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:25:28.098535 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:25:28.122025 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:25:28.142185 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:25:28.142759 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 17:25:28.166888 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:25:28.194824 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:25:28.219454 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:25:28.239679 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 17:25:30.533631 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 17:25:30.533912 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 17:25:30.811186 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 17:25:30.969599 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 17:25:31.009961 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T17:25:31Z
I1010 17:25:31.027259 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T17:25:31Z
INFO:tensorflow:Graph was finalized.
I1010 17:25:31.919923 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 17:25:31.920573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:25:31.921084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 17:25:31.921144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:25:31.921216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 17:25:31.921242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 17:25:31.921263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 17:25:31.921289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 17:25:31.921311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 17:25:31.921332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:25:31.921418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:25:31.921898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:25:31.922305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 17:25:31.922355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 17:25:31.922371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 17:25:31.922380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 17:25:31.922475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:25:31.922946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:25:31.923368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984
I1010 17:25:31.924308 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984
INFO:tensorflow:Running local_init_op.
I1010 17:25:33.073222 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 17:25:33.140609 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 17:28:12.405840 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 17:30:46.702265 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 17:33:27.330917 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 17:36:04.361513 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 17:38:43.924870 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 17:41:28.215088 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 17:44:16.052322 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 17:46:57.127453 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 17:49:36.118048 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 17:52:12.777771 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 17:52:17.824668 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1666.89601s
I1010 17:53:17.923438 140455904991104 evaluation.py:273] Inference Time : 1666.89601s
INFO:tensorflow:Finished evaluation at 2020-10-10-17:53:17
I1010 17:53:17.923690 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-17:53:17
INFO:tensorflow:Saving dict for global step 4984: AP = 0.37816557, AP50 = 0.49125218, AP75 = 0.43416852, APl = 0.45284483, APm = 0.4707723, APs = 0.124117434, ARl = 0.81108785, ARm = 0.616034, ARmax1 = 0.48259473, ARmax10 = 0.6696909, ARmax100 = 0.70853716, ARs = 0.27198064, box_loss = 0.0022246768, cls_loss = 0.2612862, global_step = 4984, loss = 0.46948427
I1010 17:53:17.923866 140455904991104 estimator.py:2063] Saving dict for global step 4984: AP = 0.37816557, AP50 = 0.49125218, AP75 = 0.43416852, APl = 0.45284483, APm = 0.4707723, APs = 0.124117434, ARl = 0.81108785, ARm = 0.616034, ARmax1 = 0.48259473, ARmax10 = 0.6696909, ARmax100 = 0.70853716, ARs = 0.27198064, box_loss = 0.0022246768, cls_loss = 0.2612862, global_step = 4984, loss = 0.46948427
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4984: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984
I1010 17:53:18.885562 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 4984: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984
I1010 17:53:18.893214 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-4984 is not in all_model_checkpoint_paths. Manually adding it.
I1010 17:53:18.929124 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-4984 is not in all_model_checkpoint_paths. Manually adding it.
I1010 17:53:18.929668 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 7.

   =====> Starting evaluation, epoch: 7.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.91s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=45.85s).
Accumulating evaluation results...
DONE (t=8.62s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.811
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 17:53:19.111094 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 17:53:19.123173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 17:53:19.157907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:19.158943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 17:53:19.159034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:53:19.165286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 17:53:19.168785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 17:53:19.169310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 17:53:19.173799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 17:53:19.175582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 17:53:19.182918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:53:19.183098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:19.184031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:19.184809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 17:53:19.455437 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 17:53:19.825855 140455904991104 estimator.py:1162] Calling model_fn.
I1010 17:53:19.826160 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 17:53:19.830989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 17:53:19.831574 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 17:53:19.840223 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 17:53:20.081143 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:53:20.082077 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:53:20.082929 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:53:20.083777 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:53:20.084658 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:53:20.085468 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:53:20.086451 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:53:20.087384 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:53:20.089253 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:53:20.090423 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:53:20.091771 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:53:20.092959 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:53:20.094250 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:53:20.095799 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:53:20.097173 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:53:20.098247 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:53:20.099612 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:53:20.100580 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:53:20.101732 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:53:20.102968 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:53:20.104106 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:53:20.106029 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:53:20.106940 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:53:20.107803 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:53:20.218036 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 17:53:20.218565 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 17:53:20.246264 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 17:53:20.268843 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 17:53:20.300245 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 17:53:20.300862 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 17:53:20.327537 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 17:53:20.356134 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 17:53:20.493520 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 17:53:20.519985 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:53:20.520569 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 17:53:20.549109 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:53:20.576575 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 17:53:20.598728 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:53:20.625198 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:53:20.625778 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 17:53:20.651912 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:53:20.679399 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 17:53:20.701264 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:53:20.726691 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:53:20.727220 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 17:53:20.753418 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:53:20.787663 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 17:53:20.811361 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:53:20.839626 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:53:20.840252 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 17:53:20.866622 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:53:20.893974 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 17:53:20.916196 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:53:20.941821 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:53:20.942368 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 17:53:20.968245 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:53:20.997697 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:53:21.019738 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:53:21.045622 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:53:21.046180 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 17:53:21.072404 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:53:21.100237 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:53:21.122622 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:53:21.150242 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:53:21.150786 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 17:53:21.181888 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:53:21.208910 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:53:21.231578 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:53:21.257055 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:53:21.257603 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 17:53:21.287171 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:53:21.323828 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:53:21.345844 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:53:21.372246 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:53:21.372789 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 17:53:21.399858 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:53:21.428066 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:53:21.450780 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:53:21.476776 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:53:21.477358 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 17:53:21.506014 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:53:21.533749 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 17:53:21.556493 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:53:21.582581 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:53:21.583186 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 17:53:21.613406 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:53:21.644802 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:53:21.667556 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:53:21.693632 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:53:21.694168 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 17:53:21.724669 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:53:21.755240 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:53:21.778281 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:53:21.809546 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:53:21.810118 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 17:53:21.843614 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:53:21.874714 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:53:21.899263 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:53:21.925261 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:53:21.925860 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 17:53:21.959712 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:53:21.993056 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:53:22.016452 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:53:22.043841 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 17:53:24.779578 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 17:53:24.779892 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 17:53:25.003373 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 17:53:25.005544 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 17:53:25.007589 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 17:53:25.009800 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 17:53:25.011310 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 17:53:25.012913 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 17:53:25.016027 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 17:53:25.017600 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 17:53:32.484055 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 17:53:34.368670 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 17:53:34.368846 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 17:53:34.375609 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 17:53:34.375861 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 17:53:34.375988 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 17:53:34.376109 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 17:53:34.376215 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 17:53:34.381900 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 17:53:34.382047 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 17:53:35.894324 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 17:53:35.895394 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 17:53:39.924111 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 17:53:39.931142: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 17:53:39.931359: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 17:53:39.931387: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 17:53:40.033218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:40.033874: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 17:53:40.033904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 17:53:40.034110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:40.034664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 17:53:40.034719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:53:40.034775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 17:53:40.034801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 17:53:40.034832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 17:53:40.034856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 17:53:40.034881: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 17:53:40.034906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:53:40.035036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:40.035657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:40.036173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 17:53:40.036286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:53:40.609913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 17:53:40.609990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 17:53:40.610002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 17:53:40.610244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:40.610881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:53:40.611383: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 17:53:40.611427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984
I1010 17:53:40.613416 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-4984
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 17:53:42.286830 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 17:53:43.117294 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 17:53:43.267577 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4984...
I1010 17:53:53.777618 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 4984...
INFO:tensorflow:Saving checkpoints for 4984 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:53:53.790756 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 4984 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4984...
I1010 17:53:56.329006 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 4984...
2020-10-10 17:54:05.438649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:54:07.418542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.49079537, step = 4984
I1010 17:54:08.408889 140455904991104 basic_session_run_hooks.py:262] loss = 0.49079537, step = 4984
INFO:tensorflow:box_loss = 0.0020762288, cls_loss = 0.29002, det_loss = 0.39383143, step = 4984
I1010 17:54:08.409588 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0020762288, cls_loss = 0.29002, det_loss = 0.39383143, step = 4984
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5084...
I1010 17:54:45.045085 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5084...
INFO:tensorflow:Saving checkpoints for 5084 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:54:45.045403 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5084 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 17:54:45.109877 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5084...
I1010 17:54:46.790056 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5084...
INFO:tensorflow:global_step/sec: 2.58213
I1010 17:54:47.135705 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.58213
INFO:tensorflow:loss = 0.64092135, step = 5084 (38.728 sec)
I1010 17:54:47.136572 140455904991104 basic_session_run_hooks.py:260] loss = 0.64092135, step = 5084 (38.728 sec)
INFO:tensorflow:box_loss = 0.0036474671, cls_loss = 0.36158943, det_loss = 0.5439628, step = 5084 (38.727 sec)
I1010 17:54:47.136780 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0036474671, cls_loss = 0.36158943, det_loss = 0.5439628, step = 5084 (38.727 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5184...
I1010 17:55:15.930488 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5184...
INFO:tensorflow:Saving checkpoints for 5184 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:55:15.930824 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5184 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5184...
I1010 17:55:17.655733 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5184...
INFO:tensorflow:global_step/sec: 3.24289
I1010 17:55:17.972599 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24289
INFO:tensorflow:loss = 0.55582654, step = 5184 (30.837 sec)
I1010 17:55:17.973617 140455904991104 basic_session_run_hooks.py:260] loss = 0.55582654, step = 5184 (30.837 sec)
INFO:tensorflow:box_loss = 0.0031729667, cls_loss = 0.3002243, det_loss = 0.45887262, step = 5184 (30.837 sec)
I1010 17:55:17.973810 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0031729667, cls_loss = 0.3002243, det_loss = 0.45887262, step = 5184 (30.837 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5284...
I1010 17:55:46.524246 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5284...
INFO:tensorflow:Saving checkpoints for 5284 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:55:46.524464 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5284 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5284...
I1010 17:55:48.251248 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5284...
INFO:tensorflow:global_step/sec: 3.26865
I1010 17:55:48.566028 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.26865
INFO:tensorflow:loss = 0.46768466, step = 5284 (30.593 sec)
I1010 17:55:48.567075 140455904991104 basic_session_run_hooks.py:260] loss = 0.46768466, step = 5284 (30.593 sec)
INFO:tensorflow:box_loss = 0.0017018251, cls_loss = 0.28564453, det_loss = 0.37073576, step = 5284 (30.593 sec)
I1010 17:55:48.567267 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0017018251, cls_loss = 0.28564453, det_loss = 0.37073576, step = 5284 (30.593 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5384...
I1010 17:56:17.548384 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5384...
INFO:tensorflow:Saving checkpoints for 5384 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:56:17.548661 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5384 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5384...
I1010 17:56:19.271318 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5384...
INFO:tensorflow:global_step/sec: 3.22861
I1010 17:56:19.539078 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.22861
INFO:tensorflow:loss = 0.57448435, step = 5384 (30.973 sec)
I1010 17:56:19.540092 140455904991104 basic_session_run_hooks.py:260] loss = 0.57448435, step = 5384 (30.973 sec)
INFO:tensorflow:box_loss = 0.001943979, cls_loss = 0.38034058, det_loss = 0.4775395, step = 5384 (30.973 sec)
I1010 17:56:19.540296 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.001943979, cls_loss = 0.38034058, det_loss = 0.4775395, step = 5384 (30.973 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5484...
I1010 17:56:48.343942 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5484...
INFO:tensorflow:Saving checkpoints for 5484 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:56:48.344176 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5484 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5484...
I1010 17:56:50.001595 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5484...
INFO:tensorflow:global_step/sec: 3.25344
I1010 17:56:50.275830 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25344
INFO:tensorflow:loss = 0.59276104, step = 5484 (30.737 sec)
I1010 17:56:50.276823 140455904991104 basic_session_run_hooks.py:260] loss = 0.59276104, step = 5484 (30.737 sec)
INFO:tensorflow:box_loss = 0.0036908034, cls_loss = 0.3112793, det_loss = 0.49581945, step = 5484 (30.737 sec)
I1010 17:56:50.277030 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0036908034, cls_loss = 0.3112793, det_loss = 0.49581945, step = 5484 (30.737 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5584...
I1010 17:57:18.718091 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5584...
INFO:tensorflow:Saving checkpoints for 5584 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:57:18.718322 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5584 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5584...
I1010 17:57:20.403961 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5584...
INFO:tensorflow:global_step/sec: 3.28836
I1010 17:57:20.686110 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.28836
INFO:tensorflow:loss = 0.51605856, step = 5584 (30.410 sec)
I1010 17:57:20.687059 140455904991104 basic_session_run_hooks.py:260] loss = 0.51605856, step = 5584 (30.410 sec)
INFO:tensorflow:box_loss = 0.0028451765, cls_loss = 0.2768612, det_loss = 0.41912, step = 5584 (30.410 sec)
I1010 17:57:20.687448 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0028451765, cls_loss = 0.2768612, det_loss = 0.41912, step = 5584 (30.410 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5684...
I1010 17:57:49.414064 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5684...
INFO:tensorflow:Saving checkpoints for 5684 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:57:49.414284 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5684 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5684...
I1010 17:57:51.131901 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5684...
INFO:tensorflow:global_step/sec: 3.25081
I1010 17:57:51.447655 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25081
INFO:tensorflow:loss = 0.5023937, step = 5684 (30.762 sec)
I1010 17:57:51.448701 140455904991104 basic_session_run_hooks.py:260] loss = 0.5023937, step = 5684 (30.762 sec)
INFO:tensorflow:box_loss = 0.0023013435, cls_loss = 0.29039, det_loss = 0.4054572, step = 5684 (30.762 sec)
I1010 17:57:51.449067 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0023013435, cls_loss = 0.29039, det_loss = 0.4054572, step = 5684 (30.762 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5696...
I1010 17:57:54.725476 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5696...
INFO:tensorflow:Saving checkpoints for 5696 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 17:57:54.725713 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5696 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5696...
I1010 17:57:56.450109 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5696...
INFO:tensorflow:Loss for final step: 0.41819212.
I1010 17:57:56.802872 140455904991104 estimator.py:350] Loss for final step: 0.41819212.
INFO:tensorflow:Calling model_fn.
I1010 17:57:57.306264 140455904991104 estimator.py:1162] Calling model_fn.
I1010 17:57:57.306585 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 17:57:57.310087 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 17:57:57.551420 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:57:57.552253 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:57:57.553040 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:57:57.553789 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:57:57.554527 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:57:57.555348 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:57:57.556124 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:57:57.557006 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:57:57.558228 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:57:57.558968 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:57:57.559725 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:57:57.560690 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:57:57.561526 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:57:57.562326 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:57:57.563107 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:57:57.563851 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:57:57.565047 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 17:57:57.565800 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 17:57:57.566530 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 17:57:57.567271 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 17:57:57.568015 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 17:57:57.568767 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 17:57:57.569509 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 17:57:57.570312 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 17:57:57.852823 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 17:57:57.853359 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 17:57:57.875307 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 17:57:57.899170 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 17:57:57.919013 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 17:57:57.919576 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 17:57:57.942180 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 17:57:57.962613 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 17:57:57.984406 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 17:57:58.004141 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:57:58.004908 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 17:57:58.031026 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:57:58.052028 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 17:57:58.077526 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:57:58.105458 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 17:57:58.106091 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 17:57:58.129002 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 17:57:58.150287 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 17:57:58.171798 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 17:57:58.190967 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:57:58.191555 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 17:57:58.212986 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:57:58.235786 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 17:57:58.258802 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:57:58.278010 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 17:57:58.278567 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 17:57:58.298812 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 17:57:58.319490 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 17:57:58.341417 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 17:57:58.360283 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:57:58.360877 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 17:57:58.380465 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:57:58.404982 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:57:58.430396 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:57:58.451017 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:57:58.451551 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 17:57:58.471271 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:57:58.492167 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:57:58.515506 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:57:58.536498 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 17:57:58.537151 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 17:57:58.558125 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 17:57:58.578771 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 17:57:58.600800 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 17:57:58.619433 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:57:58.619995 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 17:57:58.639717 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:57:58.660130 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:57:58.682016 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:57:58.705019 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:57:58.705620 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 17:57:58.726540 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:57:58.748337 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 17:57:58.770301 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:57:58.789929 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 17:57:58.790630 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 17:57:58.811985 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 17:57:58.834323 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 17:57:58.857599 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 17:57:58.877402 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:57:58.878005 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 17:57:58.904178 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:57:58.932827 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:57:58.958549 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:57:58.979891 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:57:58.980558 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 17:57:59.005380 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:57:59.031566 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:57:59.060102 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:57:59.081302 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:57:59.081926 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 17:57:59.114096 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:57:59.140125 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:57:59.163747 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:57:59.183511 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 17:57:59.184067 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 17:57:59.211390 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 17:57:59.236971 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 17:57:59.260454 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 17:57:59.279420 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 17:58:01.568826 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 17:58:01.569087 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 17:58:01.833725 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 17:58:01.983193 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 17:58:02.022437 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T17:58:02Z
I1010 17:58:02.037309 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T17:58:02Z
INFO:tensorflow:Graph was finalized.
I1010 17:58:02.906225 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 17:58:02.906907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:58:02.907399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 17:58:02.907461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 17:58:02.907528: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 17:58:02.907552: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 17:58:02.907571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 17:58:02.907591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 17:58:02.907612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 17:58:02.907649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 17:58:02.907736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:58:02.908216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:58:02.908617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 17:58:02.908681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 17:58:02.908697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 17:58:02.908706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 17:58:02.908807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:58:02.909282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 17:58:02.909717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-5696
I1010 17:58:02.910690 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-5696
INFO:tensorflow:Running local_init_op.
I1010 17:58:04.057952 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 17:58:04.119547 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 18:00:43.254794 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 18:03:16.788944 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 18:05:56.280424 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 18:08:32.746154 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 18:11:06.593455 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 18:13:40.492795 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 18:16:18.705302 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 18:18:56.340517 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 18:21:37.476377 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 18:24:14.944730 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 18:24:20.160442 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1638.82885s
I1010 18:25:20.866327 140455904991104 evaluation.py:273] Inference Time : 1638.82885s
INFO:tensorflow:Finished evaluation at 2020-10-10-18:25:20
I1010 18:25:20.866567 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-18:25:20
INFO:tensorflow:Saving dict for global step 5696: AP = 0.37314594, AP50 = 0.48005292, AP75 = 0.42669594, APl = 0.44762367, APm = 0.48586082, APs = 0.14053056, ARl = 0.8181683, ARm = 0.62724507, ARmax1 = 0.49141523, ARmax10 = 0.6791835, ARmax100 = 0.71782535, ARs = 0.2828491, box_loss = 0.0021368861, cls_loss = 0.25342527, global_step = 5696, loss = 0.45720547
I1010 18:25:20.866811 140455904991104 estimator.py:2063] Saving dict for global step 5696: AP = 0.37314594, AP50 = 0.48005292, AP75 = 0.42669594, APl = 0.44762367, APm = 0.48586082, APs = 0.14053056, ARl = 0.8181683, ARm = 0.62724507, ARmax1 = 0.49141523, ARmax10 = 0.6791835, ARmax100 = 0.71782535, ARs = 0.2828491, box_loss = 0.0021368861, cls_loss = 0.25342527, global_step = 5696, loss = 0.45720547
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5696: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-5696
I1010 18:25:21.876288 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 5696: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-5696
I1010 18:25:21.878731 140455904991104 utils.py:428] Ckpt 0.3731459379196167 is worse than 0.378166

   =====> Starting training, epoch: 8.

   =====> Starting evaluation, epoch: 8.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.90s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=46.29s).
Accumulating evaluation results...
DONE (t=8.76s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 18:25:22.070066 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 18:25:22.085660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 18:25:22.118233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:22.118829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 18:25:22.118884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:25:22.122719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 18:25:22.125518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 18:25:22.126217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 18:25:22.129950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 18:25:22.131548: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 18:25:22.138321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:25:22.138455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:22.139215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:22.139741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 18:25:22.417217 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 18:25:22.787808 140455904991104 estimator.py:1162] Calling model_fn.
I1010 18:25:22.788163 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 18:25:22.793235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 18:25:22.793933 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 18:25:22.802546 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 18:25:23.045625 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:25:23.046489 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:25:23.047268 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:25:23.048008 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:25:23.048750 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:25:23.049482 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:25:23.050241 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:25:23.051054 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:25:23.052279 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:25:23.053057 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:25:23.053807 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:25:23.054528 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:25:23.055276 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:25:23.056080 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:25:23.056851 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:25:23.057583 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:25:23.058762 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:25:23.059536 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:25:23.060346 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:25:23.061148 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:25:23.061922 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:25:23.062728 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:25:23.063461 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:25:23.064215 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:25:23.166530 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 18:25:23.167055 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 18:25:23.194699 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 18:25:23.217099 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 18:25:23.243786 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 18:25:23.244348 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 18:25:23.271211 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 18:25:23.304626 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 18:25:23.438599 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 18:25:23.464874 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 18:25:23.465427 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 18:25:23.494294 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 18:25:23.521654 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 18:25:23.548540 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 18:25:23.575948 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 18:25:23.576579 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 18:25:23.607103 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 18:25:23.637056 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 18:25:23.660321 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 18:25:23.686135 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 18:25:23.686691 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 18:25:23.712551 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 18:25:23.740103 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 18:25:23.762005 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 18:25:23.792385 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 18:25:23.793052 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 18:25:23.823196 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 18:25:23.852929 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 18:25:23.875042 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 18:25:23.901087 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:25:23.901610 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 18:25:23.927553 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:25:23.955503 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:25:23.977577 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:25:24.003551 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:25:24.004082 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 18:25:24.035869 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:25:24.064345 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:25:24.090372 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:25:24.115968 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:25:24.116495 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 18:25:24.144434 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:25:24.173501 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:25:24.196265 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:25:24.222955 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:25:24.223478 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 18:25:24.251521 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:25:24.280204 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 18:25:24.303023 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:25:24.334561 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:25:24.335115 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 18:25:24.364144 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:25:24.399250 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 18:25:24.421603 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:25:24.447721 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:25:24.448343 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 18:25:24.478853 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:25:24.507286 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 18:25:24.530936 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:25:24.557113 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:25:24.557678 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 18:25:24.595202 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:25:24.628485 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:25:24.652399 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:25:24.678123 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:25:24.678915 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 18:25:24.711315 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:25:24.742465 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:25:24.765684 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:25:24.795822 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:25:24.796379 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 18:25:24.827123 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:25:24.860595 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:25:24.884279 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:25:24.910263 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:25:24.910840 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 18:25:24.942074 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:25:24.973171 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:25:25.002319 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:25:25.028237 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 18:25:27.809630 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 18:25:27.809961 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 18:25:28.036108 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 18:25:28.037765 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 18:25:28.039218 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 18:25:28.040599 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 18:25:28.042024 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 18:25:28.043421 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 18:25:28.046185 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 18:25:28.047607 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 18:25:35.617096 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 18:25:37.507489 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 18:25:37.507671 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 18:25:37.513262 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 18:25:37.513386 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 18:25:37.513480 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 18:25:37.513572 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 18:25:37.513664 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 18:25:37.518176 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 18:25:37.518286 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 18:25:39.025272 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 18:25:39.026388 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 18:25:43.120376 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 18:25:43.127770: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 18:25:43.128025: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 18:25:43.128053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 18:25:43.227998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:43.228737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 18:25:43.228771: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 18:25:43.229080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:43.229735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 18:25:43.229790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:25:43.229857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 18:25:43.229888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 18:25:43.230001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 18:25:43.230036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 18:25:43.230053: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 18:25:43.230070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:25:43.230184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:43.230876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:43.231428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 18:25:43.231521: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:25:43.797687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 18:25:43.797742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 18:25:43.797753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 18:25:43.797974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:43.798559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:25:43.799091: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 18:25:43.799135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-5696
I1010 18:25:43.801284 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-5696
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 18:25:45.449153 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 18:25:46.282654 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 18:25:46.430997 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5696...
I1010 18:25:56.875184 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5696...
INFO:tensorflow:Saving checkpoints for 5696 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:25:56.888105 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5696 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5696...
I1010 18:25:59.415465 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5696...
2020-10-10 18:26:08.577380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:26:10.623134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.5455568, step = 5696
I1010 18:26:11.585015 140455904991104 basic_session_run_hooks.py:262] loss = 0.5455568, step = 5696
INFO:tensorflow:box_loss = 0.0029979867, cls_loss = 0.2987213, det_loss = 0.44862065, step = 5696
I1010 18:26:11.585786 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0029979867, cls_loss = 0.2987213, det_loss = 0.44862065, step = 5696
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5796...
I1010 18:26:48.671330 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5796...
INFO:tensorflow:Saving checkpoints for 5796 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:26:48.671631 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5796 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 18:26:48.737440 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5796...
I1010 18:26:50.434084 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5796...
INFO:tensorflow:global_step/sec: 2.55497
I1010 18:26:50.723577 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.55497
INFO:tensorflow:loss = 0.51278055, step = 5796 (39.140 sec)
I1010 18:26:50.725146 140455904991104 basic_session_run_hooks.py:260] loss = 0.51278055, step = 5796 (39.140 sec)
INFO:tensorflow:box_loss = 0.0016579812, cls_loss = 0.33294678, det_loss = 0.41584584, step = 5796 (39.140 sec)
I1010 18:26:50.725484 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0016579812, cls_loss = 0.33294678, det_loss = 0.41584584, step = 5796 (39.140 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5896...
I1010 18:27:19.482215 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5896...
INFO:tensorflow:Saving checkpoints for 5896 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:27:19.482448 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5896 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5896...
I1010 18:27:21.185750 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5896...
INFO:tensorflow:global_step/sec: 3.24788
I1010 18:27:21.512818 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.24788
INFO:tensorflow:loss = 0.39745903, step = 5896 (30.789 sec)
I1010 18:27:21.513708 140455904991104 basic_session_run_hooks.py:260] loss = 0.39745903, step = 5896 (30.789 sec)
INFO:tensorflow:box_loss = 0.0013941946, cls_loss = 0.23081589, det_loss = 0.3005256, step = 5896 (30.789 sec)
I1010 18:27:21.514034 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0013941946, cls_loss = 0.23081589, det_loss = 0.3005256, step = 5896 (30.789 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5996...
I1010 18:27:50.128166 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 5996...
INFO:tensorflow:Saving checkpoints for 5996 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:27:50.128400 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 5996 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5996...
I1010 18:27:51.877500 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 5996...
INFO:tensorflow:global_step/sec: 3.2591
I1010 18:27:52.196188 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.2591
INFO:tensorflow:loss = 0.62414503, step = 5996 (30.683 sec)
I1010 18:27:52.197108 140455904991104 basic_session_run_hooks.py:260] loss = 0.62414503, step = 5996 (30.683 sec)
INFO:tensorflow:box_loss = 0.0031670833, cls_loss = 0.36885834, det_loss = 0.5272125, step = 5996 (30.683 sec)
I1010 18:27:52.197330 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0031670833, cls_loss = 0.36885834, det_loss = 0.5272125, step = 5996 (30.683 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6078 vs previous value: 6078. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1010 18:28:16.067979 140455904991104 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6078 vs previous value: 6078. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6096...
I1010 18:28:21.024022 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6096...
INFO:tensorflow:Saving checkpoints for 6096 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:28:21.024256 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6096 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6096...
I1010 18:28:22.847478 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6096...
INFO:tensorflow:global_step/sec: 3.23033
I1010 18:28:23.152717 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.23033
INFO:tensorflow:loss = 0.577127, step = 6096 (30.957 sec)
I1010 18:28:23.153631 140455904991104 basic_session_run_hooks.py:260] loss = 0.577127, step = 6096 (30.957 sec)
INFO:tensorflow:box_loss = 0.002137241, cls_loss = 0.37333298, det_loss = 0.48019505, step = 6096 (30.957 sec)
I1010 18:28:23.153843 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.002137241, cls_loss = 0.37333298, det_loss = 0.48019505, step = 6096 (30.957 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6196...
I1010 18:28:52.457039 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6196...
INFO:tensorflow:Saving checkpoints for 6196 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:28:52.457283 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6196 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6196...
I1010 18:28:54.245603 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6196...
INFO:tensorflow:global_step/sec: 3.17809
I1010 18:28:54.618152 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.17809
INFO:tensorflow:loss = 0.3447712, step = 6196 (31.465 sec)
I1010 18:28:54.619083 140455904991104 basic_session_run_hooks.py:260] loss = 0.3447712, step = 6196 (31.465 sec)
INFO:tensorflow:box_loss = 0.0011530798, cls_loss = 0.19018555, det_loss = 0.24783954, step = 6196 (31.465 sec)
I1010 18:28:54.619301 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0011530798, cls_loss = 0.19018555, det_loss = 0.24783954, step = 6196 (31.465 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6296...
I1010 18:29:23.943824 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6296...
INFO:tensorflow:Saving checkpoints for 6296 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:29:23.944069 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6296 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6296...
I1010 18:29:25.718355 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6296...
INFO:tensorflow:global_step/sec: 3.18394
I1010 18:29:26.025806 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.18394
INFO:tensorflow:loss = 0.53232497, step = 6296 (31.408 sec)
I1010 18:29:26.026758 140455904991104 basic_session_run_hooks.py:260] loss = 0.53232497, step = 6296 (31.408 sec)
INFO:tensorflow:box_loss = 0.0026420427, cls_loss = 0.30329132, det_loss = 0.43539345, step = 6296 (31.408 sec)
I1010 18:29:26.026956 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0026420427, cls_loss = 0.30329132, det_loss = 0.43539345, step = 6296 (31.408 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6396...
I1010 18:29:55.020735 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6396...
INFO:tensorflow:Saving checkpoints for 6396 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:29:55.020964 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6396 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6396...
I1010 18:29:56.775794 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6396...
INFO:tensorflow:global_step/sec: 3.21604
I1010 18:29:57.119937 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.21604
INFO:tensorflow:loss = 0.4885172, step = 6396 (31.094 sec)
I1010 18:29:57.120995 140455904991104 basic_session_run_hooks.py:260] loss = 0.4885172, step = 6396 (31.094 sec)
INFO:tensorflow:box_loss = 0.0027036925, cls_loss = 0.25640106, det_loss = 0.39158568, step = 6396 (31.094 sec)
I1010 18:29:57.121179 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0027036925, cls_loss = 0.25640106, det_loss = 0.39158568, step = 6396 (31.094 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6408...
I1010 18:30:00.359846 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6408...
INFO:tensorflow:Saving checkpoints for 6408 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:30:00.360060 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6408 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6408...
I1010 18:30:02.138906 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6408...
INFO:tensorflow:Loss for final step: 0.69407105.
I1010 18:30:02.507836 140455904991104 estimator.py:350] Loss for final step: 0.69407105.
INFO:tensorflow:Calling model_fn.
I1010 18:30:02.998019 140455904991104 estimator.py:1162] Calling model_fn.
I1010 18:30:02.998360 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 18:30:03.002174 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 18:30:03.241874 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:30:03.242905 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:30:03.244005 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:30:03.245067 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:30:03.246096 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:30:03.247352 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:30:03.248681 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:30:03.249608 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:30:03.250994 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:30:03.251898 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:30:03.252791 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:30:03.253732 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:30:03.254565 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:30:03.255441 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:30:03.256275 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:30:03.257185 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:30:03.258700 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:30:03.259550 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:30:03.261021 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:30:03.261840 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:30:03.262677 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:30:03.263490 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:30:03.264516 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:30:03.265449 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:30:03.562835 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 18:30:03.563506 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 18:30:03.586125 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 18:30:03.610610 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 18:30:03.632418 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 18:30:03.633069 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 18:30:03.654326 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 18:30:03.675207 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 18:30:03.697739 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 18:30:03.717252 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 18:30:03.717781 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 18:30:03.739256 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 18:30:03.760516 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 18:30:03.783131 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 18:30:03.803738 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 18:30:03.804341 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 18:30:03.825127 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 18:30:03.851515 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 18:30:03.875154 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 18:30:03.896093 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 18:30:03.896718 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 18:30:03.919740 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 18:30:03.944099 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 18:30:03.967041 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 18:30:03.987267 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 18:30:03.987859 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 18:30:04.016547 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 18:30:04.038926 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 18:30:04.062322 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 18:30:04.082654 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:30:04.083226 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 18:30:04.104314 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:30:04.127264 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:30:04.153741 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:30:04.174293 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:30:04.174869 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 18:30:04.196633 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:30:04.220511 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:30:04.247352 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:30:04.268086 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:30:04.268632 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 18:30:04.290193 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:30:04.312447 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:30:04.335504 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:30:04.355494 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:30:04.356097 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 18:30:04.376459 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:30:04.398354 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 18:30:04.422014 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:30:04.446737 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:30:04.447447 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 18:30:04.472731 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:30:04.497800 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 18:30:04.523803 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:30:04.548088 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:30:04.548736 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 18:30:04.575471 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:30:04.601554 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 18:30:04.626394 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:30:04.647400 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:30:04.648012 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 18:30:04.672338 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:30:04.698091 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:30:04.721827 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:30:04.743764 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:30:04.744534 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 18:30:04.769693 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:30:04.795791 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:30:04.820260 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:30:04.841356 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:30:04.841913 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 18:30:04.870862 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:30:04.896938 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:30:04.921968 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:30:04.944673 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:30:04.945466 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 18:30:04.975840 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:30:05.005230 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:30:05.037172 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:30:05.059599 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 18:30:07.418694 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 18:30:07.418952 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 18:30:07.705031 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 18:30:07.866990 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 18:30:07.907934 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T18:30:07Z
I1010 18:30:07.923320 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T18:30:07Z
INFO:tensorflow:Graph was finalized.
I1010 18:30:08.846032 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 18:30:08.846770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:30:08.847301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 18:30:08.847365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:30:08.847432: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 18:30:08.847461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 18:30:08.847482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 18:30:08.847506: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 18:30:08.847531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 18:30:08.847558: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:30:08.847663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:30:08.848181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:30:08.848676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 18:30:08.848728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 18:30:08.848745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 18:30:08.848754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 18:30:08.848880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:30:08.849411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:30:08.849864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-6408
I1010 18:30:08.852158 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-6408
INFO:tensorflow:Running local_init_op.
I1010 18:30:10.052198 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 18:30:10.125956 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 18:32:58.806351 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 18:35:40.468878 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 18:38:27.147288 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 18:41:09.151450 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 18:43:49.084702 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 18:46:29.445477 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 18:49:11.720535 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 18:51:53.146366 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 18:54:33.913860 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 18:57:14.619070 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 18:57:20.061796 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1694.42414s
I1010 18:58:22.347626 140455904991104 evaluation.py:273] Inference Time : 1694.42414s
INFO:tensorflow:Finished evaluation at 2020-10-10-18:58:22
I1010 18:58:22.347923 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-18:58:22
INFO:tensorflow:Saving dict for global step 6408: AP = 0.37766996, AP50 = 0.48502547, AP75 = 0.43259302, APl = 0.45304143, APm = 0.48783696, APs = 0.1440604, ARl = 0.81943566, ARm = 0.62929, ARmax1 = 0.49185264, ARmax10 = 0.679736, ARmax100 = 0.718941, ARs = 0.28579053, box_loss = 0.0021294043, cls_loss = 0.2531066, global_step = 6408, loss = 0.45650843
I1010 18:58:22.348119 140455904991104 estimator.py:2063] Saving dict for global step 6408: AP = 0.37766996, AP50 = 0.48502547, AP75 = 0.43259302, APl = 0.45304143, APm = 0.48783696, APs = 0.1440604, ARl = 0.81943566, ARm = 0.62929, ARmax1 = 0.49185264, ARmax10 = 0.679736, ARmax100 = 0.718941, ARs = 0.28579053, box_loss = 0.0021294043, cls_loss = 0.2531066, global_step = 6408, loss = 0.45650843
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6408: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-6408
I1010 18:58:23.414726 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 6408: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-6408
I1010 18:58:23.418325 140455904991104 utils.py:428] Ckpt 0.37766996026039124 is worse than 0.378166

   =====> Starting training, epoch: 9.

   =====> Starting evaluation, epoch: 9.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.96s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=47.47s).
Accumulating evaluation results...
DONE (t=9.04s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.286
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1010 18:58:23.613536 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-10 18:58:23.626806: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-10 18:58:23.660141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:23.660801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 18:58:23.660856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:58:23.664571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 18:58:23.667474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 18:58:23.667909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 18:58:23.671149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 18:58:23.672487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 18:58:23.677799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:58:23.677937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:23.678743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:23.679820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1010 18:58:23.970751 140455904991104 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1010 18:58:24.357827 140455904991104 estimator.py:1162] Calling model_fn.
I1010 18:58:24.358162 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
2020-10-10 18:58:24.363295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 18:58:24.363961 140455904991104 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1010 18:58:24.372807 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 18:58:24.639278 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:58:24.640260 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:58:24.641146 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:58:24.642055 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:58:24.642897 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:58:24.643681 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:58:24.644487 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:58:24.645296 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:58:24.646482 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:58:24.647219 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:58:24.647976 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:58:24.648707 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:58:24.649429 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:58:24.650259 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:58:24.651081 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:58:24.651906 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:58:24.653056 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 18:58:24.653847 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 18:58:24.654584 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 18:58:24.655429 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 18:58:24.656248 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 18:58:24.657042 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 18:58:24.657786 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 18:58:24.658531 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 18:58:24.762177 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 18:58:24.762797 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 18:58:24.790903 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 18:58:24.813606 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 18:58:24.839589 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 18:58:24.840225 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 18:58:24.866392 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 18:58:24.894231 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 18:58:25.038683 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 18:58:25.066080 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 18:58:25.066694 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 18:58:25.094727 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 18:58:25.123986 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 18:58:25.147412 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 18:58:25.175280 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 18:58:25.175916 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 18:58:25.203974 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 18:58:25.233713 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 18:58:25.256729 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 18:58:25.283449 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 18:58:25.284053 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 18:58:25.311241 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 18:58:25.343891 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 18:58:25.367672 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 18:58:25.394618 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 18:58:25.395284 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 18:58:25.423321 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 18:58:25.458163 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 18:58:25.484402 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 18:58:25.512540 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:58:25.513149 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 18:58:25.542350 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:58:25.571099 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:58:25.594143 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:58:25.623025 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:58:25.623912 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 18:58:25.658294 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:58:25.692061 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:58:25.720763 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:58:25.750069 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 18:58:25.750610 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 18:58:25.779789 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 18:58:25.810128 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 18:58:25.834532 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 18:58:25.862480 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:58:25.863099 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 18:58:25.891557 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:58:25.920517 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 18:58:25.947741 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:58:25.975281 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:58:25.975872 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 18:58:26.004018 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:58:26.032538 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 18:58:26.058606 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:58:26.085797 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 18:58:26.086611 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 18:58:26.114443 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 18:58:26.143903 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 18:58:26.167976 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 18:58:26.195023 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:58:26.195591 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 18:58:26.232666 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:58:26.270658 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:58:26.298089 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:58:26.325132 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:58:26.325726 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 18:58:26.359308 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:58:26.392829 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:58:26.416921 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:58:26.445089 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:58:26.445720 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 18:58:26.484476 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:58:26.517322 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:58:26.545607 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:58:26.572002 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 18:58:26.572574 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 18:58:26.603418 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 18:58:26.635197 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 18:58:26.659705 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 18:58:26.687157 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 18:58:29.589108 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 18:58:29.589428 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 18:58:29.828285 140455904991104 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1010 18:58:29.829989 140455904991104 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1010 18:58:29.831498 140455904991104 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1010 18:58:29.832923 140455904991104 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1010 18:58:29.834424 140455904991104 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1010 18:58:29.835852 140455904991104 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1010 18:58:29.839462 140455904991104 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1010 18:58:29.841710 140455904991104 det_model_fn.py:436] clip gradients norm by 10.000000
I1010 18:58:37.680948 140455904991104 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1010 18:58:39.607522 140455904991104 det_model_fn.py:578] restore variables from efficientdet-d0
I1010 18:58:39.607702 140455904991104 utils.py:99] Init model from checkpoint efficientdet-d0
I1010 18:58:39.613112 140455904991104 utils.py:142] Init global_step from ckpt var global_step
I1010 18:58:39.613228 140455904991104 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1010 18:58:39.613317 140455904991104 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1010 18:58:39.613406 140455904991104 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1010 18:58:39.613482 140455904991104 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1010 18:58:39.618047 140455904991104 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1010 18:58:39.618175 140455904991104 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1010 18:58:41.193418 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1010 18:58:41.194509 140455904991104 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1010 18:58:45.349832 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 18:58:45.356730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-10 18:58:45.356950: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-10 18:58:45.356978: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-10 18:58:45.459511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:45.460215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2fc5800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-10 18:58:45.460249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-10 18:58:45.460467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:45.461089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 18:58:45.461139: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:58:45.461191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 18:58:45.461217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 18:58:45.461236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 18:58:45.461257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 18:58:45.461276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 18:58:45.461296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:58:45.461376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:45.461950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:45.462485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 18:58:45.462574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 18:58:46.055073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 18:58:46.055145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 18:58:46.055157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 18:58:46.055413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:46.056111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 18:58:46.056654: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-10 18:58:46.056698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-6408
I1010 18:58:46.058702 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-6408
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1010 18:58:47.753468 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1010 18:58:48.647785 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 18:58:48.805769 140455904991104 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6408...
I1010 18:58:59.865510 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6408...
INFO:tensorflow:Saving checkpoints for 6408 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:58:59.879692 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6408 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6408...
I1010 18:59:02.562726 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6408...
2020-10-10 18:59:12.548889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 18:59:14.577129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.5009539, step = 6408
I1010 18:59:15.598566 140455904991104 basic_session_run_hooks.py:262] loss = 0.5009539, step = 6408
INFO:tensorflow:box_loss = 0.0029132112, cls_loss = 0.25836182, det_loss = 0.4040224, step = 6408
I1010 18:59:15.599491 140455904991104 basic_session_run_hooks.py:262] box_loss = 0.0029132112, cls_loss = 0.25836182, det_loss = 0.4040224, step = 6408
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6508...
I1010 18:59:52.778778 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6508...
INFO:tensorflow:Saving checkpoints for 6508 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 18:59:52.779087 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6508 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1010 18:59:52.844809 140455904991104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6508...
I1010 18:59:54.588693 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6508...
INFO:tensorflow:global_step/sec: 2.54031
I1010 18:59:54.961940 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 2.54031
INFO:tensorflow:loss = 0.38490444, step = 6508 (39.365 sec)
I1010 18:59:54.963000 140455904991104 basic_session_run_hooks.py:260] loss = 0.38490444, step = 6508 (39.365 sec)
INFO:tensorflow:box_loss = 0.0015339949, cls_loss = 0.2112732, det_loss = 0.28797293, step = 6508 (39.364 sec)
I1010 18:59:54.963182 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0015339949, cls_loss = 0.2112732, det_loss = 0.28797293, step = 6508 (39.364 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6608...
I1010 19:00:24.223756 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6608...
INFO:tensorflow:Saving checkpoints for 6608 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:00:24.224217 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6608 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6608...
I1010 19:00:26.003927 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6608...
INFO:tensorflow:global_step/sec: 3.18682
I1010 19:00:26.341210 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.18682
INFO:tensorflow:loss = 0.6589603, step = 6608 (31.379 sec)
I1010 19:00:26.342251 140455904991104 basic_session_run_hooks.py:260] loss = 0.6589603, step = 6608 (31.379 sec)
INFO:tensorflow:box_loss = 0.0026117323, cls_loss = 0.43144226, det_loss = 0.5620289, step = 6608 (31.379 sec)
I1010 19:00:26.342437 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0026117323, cls_loss = 0.43144226, det_loss = 0.5620289, step = 6608 (31.379 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6708...
I1010 19:00:55.395403 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6708...
INFO:tensorflow:Saving checkpoints for 6708 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:00:55.395653 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6708 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6708...
I1010 19:00:57.103839 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6708...
INFO:tensorflow:global_step/sec: 3.21679
I1010 19:00:57.428095 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.21679
INFO:tensorflow:loss = 0.58068454, step = 6708 (31.087 sec)
I1010 19:00:57.429042 140455904991104 basic_session_run_hooks.py:260] loss = 0.58068454, step = 6708 (31.087 sec)
INFO:tensorflow:box_loss = 0.0029639485, cls_loss = 0.33555603, det_loss = 0.48375344, step = 6708 (31.087 sec)
I1010 19:00:57.429243 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0029639485, cls_loss = 0.33555603, det_loss = 0.48375344, step = 6708 (31.087 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6808...
I1010 19:01:26.351084 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6808...
INFO:tensorflow:Saving checkpoints for 6808 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:01:26.351303 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6808 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6808...
I1010 19:01:28.098956 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6808...
INFO:tensorflow:global_step/sec: 3.23153
I1010 19:01:28.373275 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.23153
INFO:tensorflow:loss = 0.7664298, step = 6808 (30.945 sec)
I1010 19:01:28.374482 140455904991104 basic_session_run_hooks.py:260] loss = 0.7664298, step = 6808 (30.945 sec)
INFO:tensorflow:box_loss = 0.0046224343, cls_loss = 0.43837738, det_loss = 0.6694991, step = 6808 (30.945 sec)
I1010 19:01:28.374708 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0046224343, cls_loss = 0.43837738, det_loss = 0.6694991, step = 6808 (30.945 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6908...
I1010 19:01:57.013767 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 6908...
INFO:tensorflow:Saving checkpoints for 6908 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:01:57.013994 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 6908 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6908...
I1010 19:01:58.758675 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 6908...
INFO:tensorflow:global_step/sec: 3.25643
I1010 19:01:59.081769 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.25643
INFO:tensorflow:loss = 0.37686342, step = 6908 (30.708 sec)
I1010 19:01:59.082725 140455904991104 basic_session_run_hooks.py:260] loss = 0.37686342, step = 6908 (30.708 sec)
INFO:tensorflow:box_loss = 0.0011214351, cls_loss = 0.2238617, det_loss = 0.27993345, step = 6908 (30.708 sec)
I1010 19:01:59.082927 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0011214351, cls_loss = 0.2238617, det_loss = 0.27993345, step = 6908 (30.708 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7008...
I1010 19:02:28.043986 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7008...
INFO:tensorflow:Saving checkpoints for 7008 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:02:28.044301 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 7008 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7008...
I1010 19:02:29.829035 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7008...
INFO:tensorflow:global_step/sec: 3.22478
I1010 19:02:30.091554 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.22478
INFO:tensorflow:loss = 0.48081535, step = 7008 (31.010 sec)
I1010 19:02:30.092514 140455904991104 basic_session_run_hooks.py:260] loss = 0.48081535, step = 7008 (31.010 sec)
INFO:tensorflow:box_loss = 0.0023263977, cls_loss = 0.26756668, det_loss = 0.38388658, step = 7008 (31.010 sec)
I1010 19:02:30.092724 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0023263977, cls_loss = 0.26756668, det_loss = 0.38388658, step = 7008 (31.010 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7108...
I1010 19:02:59.117872 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7108...
INFO:tensorflow:Saving checkpoints for 7108 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:02:59.118140 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 7108 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7108...
I1010 19:03:00.910013 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7108...
INFO:tensorflow:global_step/sec: 3.20849
I1010 19:03:01.258833 140455904991104 basic_session_run_hooks.py:702] global_step/sec: 3.20849
INFO:tensorflow:loss = 0.434323, step = 7108 (31.167 sec)
I1010 19:03:01.259787 140455904991104 basic_session_run_hooks.py:260] loss = 0.434323, step = 7108 (31.167 sec)
INFO:tensorflow:box_loss = 0.0017610416, cls_loss = 0.24934387, det_loss = 0.33739597, step = 7108 (31.167 sec)
I1010 19:03:01.259984 140455904991104 basic_session_run_hooks.py:260] box_loss = 0.0017610416, cls_loss = 0.24934387, det_loss = 0.33739597, step = 7108 (31.167 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7120...
I1010 19:03:04.503827 140455904991104 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7120...
INFO:tensorflow:Saving checkpoints for 7120 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
I1010 19:03:04.504059 140455904991104 basic_session_run_hooks.py:618] Saving checkpoints for 7120 into /tmp/model_dir/efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7120...
I1010 19:03:06.290281 140455904991104 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7120...
INFO:tensorflow:Loss for final step: 0.53028405.
I1010 19:03:06.680745 140455904991104 estimator.py:350] Loss for final step: 0.53028405.
INFO:tensorflow:Calling model_fn.
I1010 19:03:07.160879 140455904991104 estimator.py:1162] Calling model_fn.
I1010 19:03:07.161211 140455904991104 utils.py:585] use mixed precision policy name mixed_float16
I1010 19:03:07.166133 140455904991104 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7fbe28861488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1010 19:03:07.404399 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 19:03:07.405297 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 19:03:07.406142 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 19:03:07.406917 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 19:03:07.407696 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 19:03:07.408524 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 19:03:07.409310 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 19:03:07.410087 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 19:03:07.411245 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 19:03:07.411993 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 19:03:07.412758 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 19:03:07.413586 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 19:03:07.414427 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 19:03:07.415194 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 19:03:07.415972 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 19:03:07.416807 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 19:03:07.418017 140455904991104 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1010 19:03:07.418784 140455904991104 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1010 19:03:07.419535 140455904991104 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1010 19:03:07.420406 140455904991104 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1010 19:03:07.421325 140455904991104 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1010 19:03:07.422140 140455904991104 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1010 19:03:07.422982 140455904991104 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1010 19:03:07.423861 140455904991104 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1010 19:03:07.747889 140455904991104 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1010 19:03:07.748440 140455904991104 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1010 19:03:07.770546 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1010 19:03:07.793685 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1010 19:03:07.814328 140455904991104 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1010 19:03:07.814926 140455904991104 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1010 19:03:07.837229 140455904991104 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1010 19:03:07.860020 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1010 19:03:07.883937 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1010 19:03:07.903831 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 19:03:07.904415 140455904991104 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1010 19:03:07.924700 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 19:03:07.946359 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1010 19:03:07.973363 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 19:03:07.997155 140455904991104 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1010 19:03:07.997805 140455904991104 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1010 19:03:08.022617 140455904991104 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1010 19:03:08.046952 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1010 19:03:08.069782 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1010 19:03:08.091105 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 19:03:08.091737 140455904991104 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1010 19:03:08.112284 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 19:03:08.134109 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1010 19:03:08.157214 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 19:03:08.179788 140455904991104 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1010 19:03:08.180740 140455904991104 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1010 19:03:08.205815 140455904991104 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1010 19:03:08.227985 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1010 19:03:08.251122 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1010 19:03:08.276127 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 19:03:08.276780 140455904991104 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1010 19:03:08.301625 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 19:03:08.327414 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 19:03:08.357450 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 19:03:08.380339 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 19:03:08.381045 140455904991104 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1010 19:03:08.402798 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 19:03:08.433432 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 19:03:08.458768 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 19:03:08.479441 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1010 19:03:08.480145 140455904991104 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1010 19:03:08.501467 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1010 19:03:08.523634 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1010 19:03:08.547974 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1010 19:03:08.578170 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 19:03:08.579045 140455904991104 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1010 19:03:08.601114 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 19:03:08.624211 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 19:03:08.647907 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 19:03:08.671151 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 19:03:08.671799 140455904991104 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1010 19:03:08.694990 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 19:03:08.717694 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1010 19:03:08.743483 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 19:03:08.763899 140455904991104 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1010 19:03:08.764526 140455904991104 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1010 19:03:08.786598 140455904991104 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1010 19:03:08.809306 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1010 19:03:08.832421 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1010 19:03:08.852306 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 19:03:08.852904 140455904991104 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1010 19:03:08.884275 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 19:03:08.915394 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 19:03:08.944964 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 19:03:08.968130 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 19:03:08.968710 140455904991104 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1010 19:03:08.994504 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 19:03:09.020190 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 19:03:09.048376 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 19:03:09.068838 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 19:03:09.069477 140455904991104 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1010 19:03:09.094367 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 19:03:09.119620 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 19:03:09.146984 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 19:03:09.171777 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1010 19:03:09.172556 140455904991104 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1010 19:03:09.206830 140455904991104 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1010 19:03:09.234371 140455904991104 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1010 19:03:09.259073 140455904991104 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1010 19:03:09.279443 140455904991104 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1010 19:03:11.627331 140455904991104 utils.py:585] use mixed precision policy name float32
I1010 19:03:11.627743 140455904991104 det_model_fn.py:76] LR schedule method: cosine
I1010 19:03:11.906450 140455904991104 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1010 19:03:12.062415 140455904991104 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1010 19:03:12.104251 140455904991104 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-10T19:03:12Z
I1010 19:03:12.119827 140455904991104 evaluation.py:255] Starting evaluation at 2020-10-10T19:03:12Z
INFO:tensorflow:Graph was finalized.
I1010 19:03:13.023378 140455904991104 monitored_session.py:246] Graph was finalized.
2020-10-10 19:03:13.024074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 19:03:13.024582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-10 19:03:13.024660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-10 19:03:13.024752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-10 19:03:13.024790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-10 19:03:13.024812: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-10 19:03:13.024849: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-10 19:03:13.024872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-10 19:03:13.024896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-10 19:03:13.024983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 19:03:13.025456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 19:03:13.025905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-10 19:03:13.025957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-10 19:03:13.025972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-10 19:03:13.025982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-10 19:03:13.026075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 19:03:13.026567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-10 19:03:13.026994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-7120
I1010 19:03:13.028008 140455904991104 saver.py:1293] Restoring parameters from /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-7120
INFO:tensorflow:Running local_init_op.
I1010 19:03:14.219435 140455904991104 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1010 19:03:14.290177 140455904991104 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1010 19:05:59.675697 140455904991104 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1010 19:08:39.375108 140455904991104 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1010 19:11:24.981767 140455904991104 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1010 19:14:07.478701 140455904991104 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1010 19:16:46.063791 140455904991104 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1010 19:19:24.211388 140455904991104 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1010 19:22:05.642836 140455904991104 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1010 19:24:46.689505 140455904991104 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1010 19:27:25.596121 140455904991104 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1010 19:30:05.056939 140455904991104 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1010 19:30:10.210743 140455904991104 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1678.55244s
I1010 19:31:10.672444 140455904991104 evaluation.py:273] Inference Time : 1678.55244s
INFO:tensorflow:Finished evaluation at 2020-10-10-19:31:10
I1010 19:31:10.672702 140455904991104 evaluation.py:276] Finished evaluation at 2020-10-10-19:31:10
INFO:tensorflow:Saving dict for global step 7120: AP = 0.3827134, AP50 = 0.4918204, AP75 = 0.43867928, APl = 0.46016628, APm = 0.48877168, APs = 0.13672376, ARl = 0.8189471, ARm = 0.62850994, ARmax1 = 0.49113178, ARmax10 = 0.6793972, ARmax100 = 0.7184588, ARs = 0.2833851, box_loss = 0.0021285296, cls_loss = 0.25276527, global_step = 7120, loss = 0.45611873
I1010 19:31:10.672875 140455904991104 estimator.py:2063] Saving dict for global step 7120: AP = 0.3827134, AP50 = 0.4918204, AP75 = 0.43867928, APl = 0.46016628, APm = 0.48877168, APs = 0.13672376, ARl = 0.8189471, ARm = 0.62850994, ARmax1 = 0.49113178, ARmax10 = 0.6793972, ARmax100 = 0.7184588, ARs = 0.2833851, box_loss = 0.0021285296, cls_loss = 0.25276527, global_step = 7120, loss = 0.45611873
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7120: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-7120
I1010 19:31:11.614863 140455904991104 estimator.py:2124] Saving 'checkpoint_path' summary for global step 7120: /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-7120
I1010 19:31:11.622521 140455904991104 utils.py:444] mv /tmp/model_dir/efficientdet-d0-finetune/archive to /tmp/model_dir/efficientdet-d0-finetune/backup
INFO:tensorflow:/tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-7120 is not in all_model_checkpoint_paths. Manually adding it.
I1010 19:31:11.658761 140455904991104 checkpoint_management.py:102] /tmp/model_dir/efficientdet-d0-finetune/archive/model.ckpt-7120 is not in all_model_checkpoint_paths. Manually adding it.
I1010 19:31:11.659242 140455904991104 utils.py:464] Copying checkpoint /tmp/model_dir/efficientdet-d0-finetune/model.ckpt-7120 to /tmp/model_dir/efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 10.

   =====> Starting evaluation, epoch: 10.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.94s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=46.27s).
Accumulating evaluation results...
DONE (t=8.49s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819



2020-10-11 04:18:59.041495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
I1011 04:19:00.811338 140235064469376 main.py:228] {'name': 'efficientdet-d0', 'act_type': 'swish', 'image_size': (512, 512), 'target_size': None, 'input_rand_hflip': True, 'jitter_min': 0.1, 'jitter_max': 2.0, 'autoaugment_policy': None, 'use_augmix': False, 'augmix_params': [3, -1, 1], 'sample_image': None, 'num_classes': 20, 'seg_num_classes': 3, 'heads': ['object_detection'], 'skip_crowd_during_training': True, 'label_map': None, 'max_instances_per_image': 100, 'regenerate_source_id': False, 'min_level': 3, 'max_level': 7, 'num_scales': 3, 'aspect_ratios': [1.0, 2.0, 0.5], 'anchor_scale': 4.0, 'is_training_bn': True, 'momentum': 0.9, 'optimizer': 'sgd', 'learning_rate': 0.08, 'lr_warmup_init': 0.008, 'lr_warmup_epoch': 1.0, 'first_lr_drop_epoch': 200.0, 'second_lr_drop_epoch': 250.0, 'poly_lr_power': 0.9, 'clip_gradients_norm': 10.0, 'num_epochs': 20, 'data_format': 'channels_last', 'label_smoothing': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'delta': 0.1, 'box_loss_weight': 50.0, 'iou_loss_type': None, 'iou_loss_weight': 1.0, 'weight_decay': 4e-05, 'strategy': None, 'mixed_precision': True, 'box_class_repeats': 3, 'fpn_cell_repeats': 3, 'fpn_num_filters': 64, 'separable_conv': True, 'apply_bn_for_resampling': True, 'conv_after_downsample': False, 'conv_bn_act_pattern': False, 'drop_remainder': True, 'nms_configs': {'method': 'gaussian', 'iou_thresh': None, 'score_thresh': None, 'sigma': None, 'max_nms_inputs': 0, 'max_output_size': 100}, 'fpn_name': None, 'fpn_weight_method': None, 'fpn_config': None, 'survival_prob': None, 'img_summary_steps': None, 'lr_decay_method': 'cosine', 'moving_average_decay': 0, 'ckpt_var_scope': None, 'skip_mismatch': True, 'backbone_name': 'efficientnet-b0', 'backbone_config': None, 'var_freeze_expr': None, 'use_keras_model': True, 'dataset_type': None, 'positives_momentum': None, 'device': {'grad_ckpting': False, 'grad_ckpting_list': ['Add_', 'AddN'], 'nvgpu_logging': False}, 'model_name': 'efficientdet-d0', 'iterations_per_loop': 100, 'model_dir': 'efficientdet-d0-finetune', 'num_shards': 8, 'num_examples_per_epoch': 5696, 'backbone_ckpt': '', 'ckpt': 'efficientdet-d0', 'val_json_file': None, 'testdev_dir': None, 'profile': False, 'mode': 'train_and_eval'}
INFO:tensorflow:Using config: {'_model_dir': 'efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1011 04:19:00.904512 140235064469376 estimator.py:191] Using config: {'_model_dir': 'efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': 'efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1011 04:19:00.905724 140235064469376 estimator.py:191] Using config: {'_model_dir': 'efficientdet-d0-finetune', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1011 04:19:00.908334 140235064469376 main.py:334] found ckpt at step 7120 (epoch 10)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 04:19:00.959806 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 04:19:00.981645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 04:19:01.042278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:01.043011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 04:19:01.043084: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:19:01.231937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 04:19:01.388212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 04:19:01.403433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 04:19:01.679973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 04:19:01.699129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 04:19:02.222043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:19:02.222254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:02.223038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:02.223694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 04:19:02.552391 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 04:19:02.957396 140235064469376 estimator.py:1162] Calling model_fn.
I1011 04:19:02.957752 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 04:19:02.962602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 04:19:02.966117 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 04:19:02.976546 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 04:19:03.267734 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:19:03.268799 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:19:03.269678 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:19:03.270519 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:19:03.271532 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:19:03.272528 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:19:03.273432 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:19:03.274317 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:19:03.275728 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:19:03.276635 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:19:03.277554 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:19:03.278417 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:19:03.279364 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:19:03.280275 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:19:03.281157 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:19:03.282066 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:19:03.283507 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:19:03.284468 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:19:03.285445 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:19:03.286420 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:19:03.287348 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:19:03.288296 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:19:03.289192 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:19:03.290191 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:19:03.390958 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 04:19:03.391467 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 04:19:03.421664 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 04:19:03.447295 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 04:19:03.475920 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 04:19:03.476584 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 04:19:03.505383 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 04:19:03.540389 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 04:19:03.680788 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 04:19:03.711224 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:19:03.711861 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 04:19:03.741938 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:19:03.772604 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 04:19:03.797434 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:19:03.829912 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:19:03.830652 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 04:19:03.861992 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:19:03.892304 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 04:19:03.917312 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:19:03.946159 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:19:03.946793 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 04:19:03.975455 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:19:04.004976 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 04:19:04.028056 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:19:04.054268 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:19:04.054890 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 04:19:04.081880 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:19:04.108810 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 04:19:04.138451 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:19:04.167535 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:19:04.168086 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 04:19:04.195580 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:19:04.223486 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:19:04.249397 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:19:04.277328 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:19:04.277884 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 04:19:04.305514 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:19:04.333262 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:19:04.356918 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:19:04.384045 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:19:04.384590 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 04:19:04.411372 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:19:04.443434 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:19:04.468186 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:19:04.494494 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:19:04.495043 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 04:19:04.522483 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:19:04.550968 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:19:04.574421 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:19:04.601406 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:19:04.601967 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 04:19:04.632242 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:19:04.664426 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:19:04.688433 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:19:04.716172 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:19:04.716782 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 04:19:04.744838 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:19:04.775396 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 04:19:04.798085 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:19:04.823804 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:19:04.824319 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 04:19:04.856050 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:19:04.889671 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:19:04.913688 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:19:04.942131 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:19:04.942735 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 04:19:04.973731 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:19:05.005738 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:19:05.032114 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:19:05.063383 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:19:05.063942 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 04:19:05.098805 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:19:05.141165 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:19:05.171224 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:19:05.198399 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:19:05.199096 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 04:19:05.232861 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:19:05.269189 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:19:05.294905 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:19:05.321504 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 04:19:08.170106 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 04:19:08.170440 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 04:19:08.419063 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 04:19:08.420611 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 04:19:08.422063 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 04:19:08.423509 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 04:19:08.424978 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 04:19:08.426466 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 04:19:08.429363 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 04:19:08.430897 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 04:19:16.538600 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 04:19:18.497485 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 04:19:18.497759 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 04:19:18.507740 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 04:19:18.507875 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 04:19:18.507973 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 04:19:18.508083 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 04:19:18.508163 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 04:19:18.513015 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 04:19:18.513127 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 04:19:20.147447 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 04:19:20.148650 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 04:19:24.332170 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 04:19:24.361397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 04:19:24.361624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 04:19:24.361655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 04:19:24.503031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:24.503757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 04:19:24.503798: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 04:19:24.504514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:24.505099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 04:19:24.505165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:19:24.505228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 04:19:24.505256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 04:19:24.505287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 04:19:24.505322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 04:19:24.505351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 04:19:24.505382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:19:24.505490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:24.506160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:24.506703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 04:19:24.509056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:19:28.343059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 04:19:28.343115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 04:19:28.343127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 04:19:28.343331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:28.343973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:19:28.344483: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 04:19:28.344525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-7120
I1011 04:19:28.349537 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-7120
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 04:19:30.093870 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 04:19:30.958583 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 04:19:31.111650 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7120...
I1011 04:19:42.336922 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7120...
INFO:tensorflow:Saving checkpoints for 7120 into efficientdet-d0-finetune/model.ckpt.
I1011 04:19:42.350204 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7120 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7120...
I1011 04:19:44.984992 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7120...
2020-10-11 04:19:47.966308: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-11 04:19:48.394134: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-11 04:19:48.879029: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-11 04:19:49.271655: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-11 04:19:50.468550: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of free system memory.
2020-10-11 04:19:54.975085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:19:59.976755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.48766333, step = 7120
I1011 04:20:02.034616 140235064469376 basic_session_run_hooks.py:262] loss = 0.48766333, step = 7120
INFO:tensorflow:box_loss = 0.001998387, cls_loss = 0.29081726, det_loss = 0.39073664, step = 7120
I1011 04:20:02.035403 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.001998387, cls_loss = 0.29081726, det_loss = 0.39073664, step = 7120
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7220...
I1011 04:20:39.888288 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7220...
INFO:tensorflow:Saving checkpoints for 7220 into efficientdet-d0-finetune/model.ckpt.
I1011 04:20:39.888575 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7220 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 04:20:39.953517 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7220...
I1011 04:20:41.684539 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7220...
INFO:tensorflow:global_step/sec: 2.50098
I1011 04:20:42.018188 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.50098
INFO:tensorflow:loss = 0.5060612, step = 7220 (39.985 sec)
I1011 04:20:42.019146 140235064469376 basic_session_run_hooks.py:260] loss = 0.5060612, step = 7220 (39.985 sec)
INFO:tensorflow:box_loss = 0.0017370112, cls_loss = 0.3222847, det_loss = 0.40913525, step = 7220 (39.984 sec)
I1011 04:20:42.019454 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0017370112, cls_loss = 0.3222847, det_loss = 0.40913525, step = 7220 (39.984 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7320...
I1011 04:21:11.966371 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7320...
INFO:tensorflow:Saving checkpoints for 7320 into efficientdet-d0-finetune/model.ckpt.
I1011 04:21:11.966669 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7320 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7320...
I1011 04:21:13.736310 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7320...
INFO:tensorflow:global_step/sec: 3.12616
I1011 04:21:14.006251 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.12616
INFO:tensorflow:loss = 0.66364527, step = 7320 (31.988 sec)
I1011 04:21:14.007390 140235064469376 basic_session_run_hooks.py:260] loss = 0.66364527, step = 7320 (31.988 sec)
INFO:tensorflow:box_loss = 0.0039003731, cls_loss = 0.3716917, det_loss = 0.56671035, step = 7320 (31.988 sec)
I1011 04:21:14.007603 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0039003731, cls_loss = 0.3716917, det_loss = 0.56671035, step = 7320 (31.988 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7366 vs previous value: 7366. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 04:21:27.800482 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7366 vs previous value: 7366. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7420...
I1011 04:21:43.750677 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7420...
INFO:tensorflow:Saving checkpoints for 7420 into efficientdet-d0-finetune/model.ckpt.
I1011 04:21:43.750963 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7420 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7420...
I1011 04:21:45.481883 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7420...
INFO:tensorflow:global_step/sec: 3.14706
I1011 04:21:45.781934 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.14706
INFO:tensorflow:loss = 0.49600416, step = 7420 (31.776 sec)
I1011 04:21:45.783062 140235064469376 basic_session_run_hooks.py:260] loss = 0.49600416, step = 7420 (31.776 sec)
INFO:tensorflow:box_loss = 0.0026087486, cls_loss = 0.26862335, det_loss = 0.3990608, step = 7420 (31.776 sec)
I1011 04:21:45.783281 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0026087486, cls_loss = 0.26862335, det_loss = 0.3990608, step = 7420 (31.776 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7520...
I1011 04:22:15.970086 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7520...
INFO:tensorflow:Saving checkpoints for 7520 into efficientdet-d0-finetune/model.ckpt.
I1011 04:22:15.970335 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7520 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7520...
I1011 04:22:17.812900 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7520...
INFO:tensorflow:global_step/sec: 3.09045
I1011 04:22:18.139629 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.09045
INFO:tensorflow:loss = 0.58563644, step = 7520 (32.358 sec)
I1011 04:22:18.140619 140235064469376 basic_session_run_hooks.py:260] loss = 0.58563644, step = 7520 (32.358 sec)
INFO:tensorflow:box_loss = 0.0030508721, cls_loss = 0.3361435, det_loss = 0.4886871, step = 7520 (32.358 sec)
I1011 04:22:18.140844 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0030508721, cls_loss = 0.3361435, det_loss = 0.4886871, step = 7520 (32.358 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7620...
I1011 04:22:48.049401 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7620...
INFO:tensorflow:Saving checkpoints for 7620 into efficientdet-d0-finetune/model.ckpt.
I1011 04:22:48.049658 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7620 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7620...
I1011 04:22:49.799026 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7620...
INFO:tensorflow:global_step/sec: 3.12415
I1011 04:22:50.148365 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.12415
INFO:tensorflow:loss = 0.45146906, step = 7620 (32.009 sec)
I1011 04:22:50.149469 140235064469376 basic_session_run_hooks.py:260] loss = 0.45146906, step = 7620 (32.009 sec)
INFO:tensorflow:box_loss = 0.0014186058, cls_loss = 0.2835846, det_loss = 0.3545149, step = 7620 (32.009 sec)
I1011 04:22:50.149669 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0014186058, cls_loss = 0.2835846, det_loss = 0.3545149, step = 7620 (32.009 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7720...
I1011 04:23:20.473420 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7720...
INFO:tensorflow:Saving checkpoints for 7720 into efficientdet-d0-finetune/model.ckpt.
I1011 04:23:20.473699 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7720 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7720...
I1011 04:23:22.220367 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7720...
INFO:tensorflow:global_step/sec: 3.08472
I1011 04:23:22.566200 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.08472
INFO:tensorflow:loss = 0.3973568, step = 7720 (32.418 sec)
I1011 04:23:22.567344 140235064469376 basic_session_run_hooks.py:260] loss = 0.3973568, step = 7720 (32.418 sec)
INFO:tensorflow:box_loss = 0.0015811842, cls_loss = 0.22133923, det_loss = 0.30039844, step = 7720 (32.418 sec)
I1011 04:23:22.567591 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0015811842, cls_loss = 0.22133923, det_loss = 0.30039844, step = 7720 (32.418 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7820...
I1011 04:23:52.749732 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7820...
INFO:tensorflow:Saving checkpoints for 7820 into efficientdet-d0-finetune/model.ckpt.
I1011 04:23:52.749998 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7820 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7820...
I1011 04:23:54.550960 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7820...
INFO:tensorflow:global_step/sec: 3.09192
I1011 04:23:54.908561 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.09192
INFO:tensorflow:loss = 0.5382499, step = 7820 (32.342 sec)
I1011 04:23:54.909522 140235064469376 basic_session_run_hooks.py:260] loss = 0.5382499, step = 7820 (32.342 sec)
INFO:tensorflow:box_loss = 0.0022685484, cls_loss = 0.3278656, det_loss = 0.44129303, step = 7820 (32.342 sec)
I1011 04:23:54.909760 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0022685484, cls_loss = 0.3278656, det_loss = 0.44129303, step = 7820 (32.342 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7832...
I1011 04:23:58.130054 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7832...
INFO:tensorflow:Saving checkpoints for 7832 into efficientdet-d0-finetune/model.ckpt.
I1011 04:23:58.130305 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7832 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7832...
I1011 04:23:59.963039 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7832...
INFO:tensorflow:Loss for final step: 0.6398387.
I1011 04:24:00.329979 140235064469376 estimator.py:350] Loss for final step: 0.6398387.
INFO:tensorflow:Calling model_fn.
I1011 04:24:00.827371 140235064469376 estimator.py:1162] Calling model_fn.
I1011 04:24:00.827663 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 04:24:00.831279 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 04:24:01.078840 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:24:01.080120 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:24:01.081148 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:24:01.082110 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:24:01.082969 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:24:01.083891 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:24:01.084846 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:24:01.085808 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:24:01.087162 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:24:01.087974 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:24:01.088847 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:24:01.089864 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:24:01.090691 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:24:01.091511 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:24:01.092453 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:24:01.093291 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:24:01.094836 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:24:01.095743 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:24:01.096579 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:24:01.097441 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:24:01.098300 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:24:01.099137 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:24:01.099995 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:24:01.100834 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:24:01.389615 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 04:24:01.390247 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 04:24:01.411506 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 04:24:01.434301 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 04:24:01.455080 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 04:24:01.455629 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 04:24:01.476861 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 04:24:01.498746 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 04:24:01.521987 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 04:24:01.541365 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:24:01.541873 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 04:24:01.563016 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:24:01.584138 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 04:24:01.607016 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:24:01.627745 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:24:01.628347 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 04:24:01.650119 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:24:01.676384 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 04:24:01.698735 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:24:01.718021 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:24:01.718553 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 04:24:01.743260 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:24:01.765305 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 04:24:01.787796 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:24:01.807795 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:24:01.808417 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 04:24:01.828482 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:24:01.850326 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 04:24:01.872880 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:24:01.892596 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:24:01.893134 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 04:24:01.913920 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:24:01.935954 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:24:01.964793 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:24:01.990633 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:24:01.991289 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 04:24:02.014894 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:24:02.039312 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:24:02.065279 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:24:02.087865 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:24:02.088504 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 04:24:02.111578 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:24:02.136534 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:24:02.161190 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:24:02.181036 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:24:02.181570 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 04:24:02.202492 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:24:02.223890 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:24:02.247300 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:24:02.270784 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:24:02.271342 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 04:24:02.293130 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:24:02.315289 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:24:02.342060 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:24:02.365227 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:24:02.365857 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 04:24:02.387281 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:24:02.410141 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 04:24:02.433731 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:24:02.454042 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:24:02.454566 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 04:24:02.479859 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:24:02.506587 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:24:02.532165 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:24:02.554099 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:24:02.554670 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 04:24:02.582890 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:24:02.609959 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:24:02.634721 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:24:02.656805 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:24:02.657377 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 04:24:02.682837 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:24:02.709972 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:24:02.734764 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:24:02.760404 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:24:02.761000 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 04:24:02.787186 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:24:02.813167 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:24:02.837235 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:24:02.857515 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 04:24:05.286497 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 04:24:05.286782 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 04:24:05.561813 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 04:24:05.721845 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 04:24:05.763464 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T04:24:05Z
I1011 04:24:05.781667 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T04:24:05Z
INFO:tensorflow:Graph was finalized.
I1011 04:24:06.688691 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 04:24:06.689469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:24:06.690043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 04:24:06.690120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:24:06.690207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 04:24:06.690233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 04:24:06.690253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 04:24:06.690281: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 04:24:06.690305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 04:24:06.690326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:24:06.690415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:24:06.690947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:24:06.691399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 04:24:06.691460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 04:24:06.691475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 04:24:06.691484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 04:24:06.691622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:24:06.692184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:24:06.692660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-7832
I1011 04:24:06.693793 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-7832
INFO:tensorflow:Running local_init_op.
I1011 04:24:07.907034 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 04:24:07.970828 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
INFO:tensorflow:Evaluation [71/712]
I1011 04:26:55.856905 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 04:29:37.412355 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 04:32:27.702878 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 04:35:13.006646 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 04:37:54.789008 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 04:40:35.789784 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 04:43:19.365031 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 04:45:58.729574 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 04:48:40.842563 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 04:51:19.713922 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 04:51:24.985445 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1700.80337s
I1011 04:52:26.585248 140235064469376 evaluation.py:273] Inference Time : 1700.80337s
INFO:tensorflow:Finished evaluation at 2020-10-11-04:52:26
I1011 04:52:26.585488 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-04:52:26
INFO:tensorflow:Saving dict for global step 7832: AP = 0.34414774, AP50 = 0.45278567, AP75 = 0.3981812, APl = 0.41703057, APm = 0.47354764, APs = 0.13401772, ARl = 0.8010917, ARm = 0.61429256, ARmax1 = 0.47665095, ARmax10 = 0.66197467, ARmax100 = 0.70195526, ARs = 0.26545605, box_loss = 0.0023160456, cls_loss = 0.26756567, global_step = 7832, loss = 0.48032525
I1011 04:52:26.585664 140235064469376 estimator.py:2063] Saving dict for global step 7832: AP = 0.34414774, AP50 = 0.45278567, AP75 = 0.3981812, APl = 0.41703057, APm = 0.47354764, APs = 0.13401772, ARl = 0.8010917, ARm = 0.61429256, ARmax1 = 0.47665095, ARmax10 = 0.66197467, ARmax100 = 0.70195526, ARs = 0.26545605, box_loss = 0.0023160456, cls_loss = 0.26756567, global_step = 7832, loss = 0.48032525
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7832: efficientdet-d0-finetune/model.ckpt-7832
I1011 04:52:27.609560 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 7832: efficientdet-d0-finetune/model.ckpt-7832
I1011 04:52:27.612377 140235064469376 utils.py:428] Ckpt 0.3441477417945862 is worse than 0.382713

   =====> Starting training, epoch: 11.

   =====> Starting evaluation, epoch: 11.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.91s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=47.35s).
Accumulating evaluation results...
DONE (t=8.57s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.702
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.265
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 04:52:27.810378 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 04:52:27.823697: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 04:52:27.857288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:27.857899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 04:52:27.857954: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:52:27.862177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 04:52:27.865064: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 04:52:27.865455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 04:52:27.867411: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 04:52:27.868602: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 04:52:27.872851: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:52:27.872988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:27.873580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:27.874119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 04:52:28.160420 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 04:52:28.522856 140235064469376 estimator.py:1162] Calling model_fn.
I1011 04:52:28.523181 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 04:52:28.528024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 04:52:28.528696 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 04:52:28.537018 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 04:52:28.777987 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:52:28.778918 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:52:28.779685 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:52:28.780457 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:52:28.781228 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:52:28.781978 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:52:28.782730 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:52:28.783513 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:52:28.784677 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:52:28.785419 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:52:28.786161 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:52:28.786920 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:52:28.787646 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:52:28.788450 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:52:28.789224 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:52:28.790003 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:52:28.791250 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:52:28.791991 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:52:28.792744 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:52:28.793585 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:52:28.794325 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:52:28.795124 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:52:28.795955 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:52:28.796688 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:52:28.889124 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 04:52:28.889593 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 04:52:28.916954 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 04:52:28.943034 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 04:52:28.969487 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 04:52:28.970078 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 04:52:28.997320 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 04:52:29.025227 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 04:52:29.160183 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 04:52:29.186488 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:52:29.187073 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 04:52:29.213426 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:52:29.240752 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 04:52:29.262471 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:52:29.288192 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:52:29.288770 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 04:52:29.314614 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:52:29.341224 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 04:52:29.363231 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:52:29.388188 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:52:29.388756 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 04:52:29.416897 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:52:29.445619 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 04:52:29.469211 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:52:29.494509 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:52:29.495102 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 04:52:29.521158 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:52:29.548617 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 04:52:29.570540 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:52:29.595891 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:52:29.596471 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 04:52:29.622551 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:52:29.649574 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:52:29.672605 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:52:29.703541 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:52:29.704099 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 04:52:29.732981 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:52:29.760316 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:52:29.782251 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:52:29.807891 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:52:29.808483 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 04:52:29.834943 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:52:29.862028 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:52:29.884188 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:52:29.911258 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:52:29.912021 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 04:52:29.938923 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:52:29.971527 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:52:29.994377 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:52:30.020936 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:52:30.021463 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 04:52:30.049160 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:52:30.077756 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:52:30.100576 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:52:30.132130 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:52:30.132750 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 04:52:30.160406 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:52:30.188278 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 04:52:30.211027 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:52:30.237119 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:52:30.237641 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 04:52:30.267964 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:52:30.300242 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:52:30.326532 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:52:30.358296 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:52:30.358895 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 04:52:30.391427 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:52:30.422955 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:52:30.446509 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:52:30.473070 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:52:30.473599 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 04:52:30.504230 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:52:30.535128 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:52:30.561519 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:52:30.587201 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:52:30.587741 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 04:52:30.619941 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:52:30.652274 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:52:30.678274 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:52:30.709238 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 04:52:33.488612 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 04:52:33.488944 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 04:52:33.718273 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 04:52:33.720002 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 04:52:33.721405 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 04:52:33.722746 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 04:52:33.724165 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 04:52:33.726119 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 04:52:33.729952 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 04:52:33.731927 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 04:52:41.451696 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 04:52:43.335899 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 04:52:43.336078 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 04:52:43.341824 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 04:52:43.341956 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 04:52:43.342058 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 04:52:43.342184 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 04:52:43.342275 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 04:52:43.347281 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 04:52:43.347396 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 04:52:44.850994 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 04:52:44.852070 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 04:52:48.919434 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 04:52:48.927037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 04:52:48.927293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 04:52:48.927326: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 04:52:49.033644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:49.034319: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 04:52:49.034351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 04:52:49.034602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:49.035143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 04:52:49.035193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:52:49.035243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 04:52:49.035267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 04:52:49.035283: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 04:52:49.035303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 04:52:49.035323: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 04:52:49.035342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:52:49.035434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:49.036019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:49.036603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 04:52:49.036707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:52:49.592838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 04:52:49.592893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 04:52:49.592904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 04:52:49.593100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:49.593699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:52:49.594251: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 04:52:49.594296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-7832
I1011 04:52:49.596556 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-7832
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 04:52:51.336054 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 04:52:52.157104 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 04:52:52.310476 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7832...
I1011 04:53:02.801681 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7832...
INFO:tensorflow:Saving checkpoints for 7832 into efficientdet-d0-finetune/model.ckpt.
I1011 04:53:02.814606 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7832 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7832...
I1011 04:53:05.325425 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7832...
2020-10-11 04:53:15.514173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:53:17.434583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.68441755, step = 7832
I1011 04:53:18.390085 140235064469376 basic_session_run_hooks.py:262] loss = 0.68441755, step = 7832
INFO:tensorflow:box_loss = 0.0044171265, cls_loss = 0.36660385, det_loss = 0.58746016, step = 7832
I1011 04:53:18.391559 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0044171265, cls_loss = 0.36660385, det_loss = 0.58746016, step = 7832
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7932...
I1011 04:53:56.005132 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 7932...
INFO:tensorflow:Saving checkpoints for 7932 into efficientdet-d0-finetune/model.ckpt.
I1011 04:53:56.005439 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 7932 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 04:53:56.063855 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7932...
I1011 04:53:57.704884 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 7932...
INFO:tensorflow:global_step/sec: 2.52642
I1011 04:53:57.970844 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.52642
INFO:tensorflow:loss = 0.75280875, step = 7932 (39.582 sec)
I1011 04:53:57.971822 140235064469376 basic_session_run_hooks.py:260] loss = 0.75280875, step = 7932 (39.582 sec)
INFO:tensorflow:box_loss = 0.004101479, cls_loss = 0.45077515, det_loss = 0.6558491, step = 7932 (39.581 sec)
I1011 04:53:57.972126 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.004101479, cls_loss = 0.45077515, det_loss = 0.6558491, step = 7932 (39.581 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8032...
I1011 04:54:27.275943 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8032...
INFO:tensorflow:Saving checkpoints for 8032 into efficientdet-d0-finetune/model.ckpt.
I1011 04:54:27.276196 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8032 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8032...
I1011 04:54:28.979353 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8032...
INFO:tensorflow:global_step/sec: 3.19083
I1011 04:54:29.310571 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19083
INFO:tensorflow:loss = 0.5069244, step = 8032 (31.340 sec)
I1011 04:54:29.311560 140235064469376 basic_session_run_hooks.py:260] loss = 0.5069244, step = 8032 (31.340 sec)
INFO:tensorflow:box_loss = 0.003127098, cls_loss = 0.2536087, det_loss = 0.4099636, step = 8032 (31.340 sec)
I1011 04:54:29.311821 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.003127098, cls_loss = 0.2536087, det_loss = 0.4099636, step = 8032 (31.340 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8132...
I1011 04:54:58.737108 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8132...
INFO:tensorflow:Saving checkpoints for 8132 into efficientdet-d0-finetune/model.ckpt.
I1011 04:54:58.737344 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8132 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8132...
I1011 04:55:00.427341 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8132...
INFO:tensorflow:global_step/sec: 3.18439
I1011 04:55:00.713829 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18439
INFO:tensorflow:loss = 0.5817486, step = 8132 (31.403 sec)
I1011 04:55:00.714729 140235064469376 basic_session_run_hooks.py:260] loss = 0.5817486, step = 8132 (31.403 sec)
INFO:tensorflow:box_loss = 0.0029243191, cls_loss = 0.3385744, det_loss = 0.48479033, step = 8132 (31.403 sec)
I1011 04:55:00.715083 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0029243191, cls_loss = 0.3385744, det_loss = 0.48479033, step = 8132 (31.403 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8232...
I1011 04:55:29.963934 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8232...
INFO:tensorflow:Saving checkpoints for 8232 into efficientdet-d0-finetune/model.ckpt.
I1011 04:55:29.964242 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8232 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8232...
I1011 04:55:31.637342 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8232...
INFO:tensorflow:global_step/sec: 3.20127
I1011 04:55:31.951426 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.20127
INFO:tensorflow:loss = 0.42988527, step = 8232 (31.238 sec)
I1011 04:55:31.952358 140235064469376 basic_session_run_hooks.py:260] loss = 0.42988527, step = 8232 (31.238 sec)
INFO:tensorflow:box_loss = 0.0016964308, cls_loss = 0.24810791, det_loss = 0.33292946, step = 8232 (31.237 sec)
I1011 04:55:31.952558 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0016964308, cls_loss = 0.24810791, det_loss = 0.33292946, step = 8232 (31.237 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8332...
I1011 04:56:01.137216 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8332...
INFO:tensorflow:Saving checkpoints for 8332 into efficientdet-d0-finetune/model.ckpt.
I1011 04:56:01.137490 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8332 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8332...
I1011 04:56:02.803916 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8332...
INFO:tensorflow:global_step/sec: 3.20888
I1011 04:56:03.114991 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.20888
INFO:tensorflow:loss = 0.45446026, step = 8332 (31.164 sec)
I1011 04:56:03.116145 140235064469376 basic_session_run_hooks.py:260] loss = 0.45446026, step = 8332 (31.164 sec)
INFO:tensorflow:box_loss = 0.0020132146, cls_loss = 0.2568457, det_loss = 0.35750645, step = 8332 (31.164 sec)
I1011 04:56:03.116388 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0020132146, cls_loss = 0.2568457, det_loss = 0.35750645, step = 8332 (31.164 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8432...
I1011 04:56:32.580650 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8432...
INFO:tensorflow:Saving checkpoints for 8432 into efficientdet-d0-finetune/model.ckpt.
I1011 04:56:32.580965 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8432 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8432...
I1011 04:56:34.272966 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8432...
INFO:tensorflow:global_step/sec: 3.17313
I1011 04:56:34.629621 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17313
INFO:tensorflow:loss = 0.48437098, step = 8432 (31.515 sec)
I1011 04:56:34.630786 140235064469376 basic_session_run_hooks.py:260] loss = 0.48437098, step = 8432 (31.515 sec)
INFO:tensorflow:box_loss = 0.0016211807, cls_loss = 0.30635834, det_loss = 0.38741738, step = 8432 (31.515 sec)
I1011 04:56:34.631007 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0016211807, cls_loss = 0.30635834, det_loss = 0.38741738, step = 8432 (31.515 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8532...
I1011 04:57:03.827095 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8532...
INFO:tensorflow:Saving checkpoints for 8532 into efficientdet-d0-finetune/model.ckpt.
I1011 04:57:03.827343 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8532 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8532...
I1011 04:57:05.495093 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8532...
INFO:tensorflow:global_step/sec: 3.20676
I1011 04:57:05.813706 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.20676
INFO:tensorflow:loss = 0.65375483, step = 8532 (31.184 sec)
I1011 04:57:05.814573 140235064469376 basic_session_run_hooks.py:260] loss = 0.65375483, step = 8532 (31.184 sec)
INFO:tensorflow:box_loss = 0.004147233, cls_loss = 0.34944344, det_loss = 0.5568051, step = 8532 (31.184 sec)
I1011 04:57:05.814794 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.004147233, cls_loss = 0.34944344, det_loss = 0.5568051, step = 8532 (31.184 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8544...
I1011 04:57:09.132114 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8544...
INFO:tensorflow:Saving checkpoints for 8544 into efficientdet-d0-finetune/model.ckpt.
I1011 04:57:09.132353 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8544 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8544...
I1011 04:57:10.890002 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8544...
INFO:tensorflow:Loss for final step: 0.40069532.
I1011 04:57:11.270566 140235064469376 estimator.py:350] Loss for final step: 0.40069532.
INFO:tensorflow:Calling model_fn.
I1011 04:57:11.751922 140235064469376 estimator.py:1162] Calling model_fn.
I1011 04:57:11.752223 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 04:57:11.756133 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 04:57:11.989854 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:57:11.990680 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:57:11.991483 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:57:11.992243 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:57:11.993008 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:57:11.993938 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:57:11.994828 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:57:11.995632 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:57:11.996836 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:57:11.997564 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:57:11.998314 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:57:11.999180 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:57:11.999939 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:57:12.000730 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:57:12.001467 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:57:12.002218 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:57:12.003406 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 04:57:12.004228 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 04:57:12.005048 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 04:57:12.005806 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 04:57:12.006540 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 04:57:12.007292 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 04:57:12.008161 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 04:57:12.009109 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 04:57:12.305789 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 04:57:12.306317 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 04:57:12.327566 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 04:57:12.354028 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 04:57:12.374473 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 04:57:12.375109 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 04:57:12.395370 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 04:57:12.416663 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 04:57:12.440277 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 04:57:12.460163 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:57:12.460700 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 04:57:12.480812 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:57:12.501837 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 04:57:12.525552 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:57:12.549077 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 04:57:12.549727 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 04:57:12.574009 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 04:57:12.598261 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 04:57:12.622171 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 04:57:12.641891 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:57:12.642430 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 04:57:12.663205 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:57:12.686018 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 04:57:12.708251 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:57:12.728552 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 04:57:12.729133 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 04:57:12.750336 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 04:57:12.772434 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 04:57:12.795414 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 04:57:12.815386 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:57:12.815978 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 04:57:12.841240 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:57:12.866279 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:57:12.890056 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:57:12.910360 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:57:12.910938 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 04:57:12.931624 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:57:12.952884 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:57:12.975653 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:57:12.998336 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 04:57:12.998906 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 04:57:13.020379 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 04:57:13.045408 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 04:57:13.070926 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 04:57:13.092775 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:57:13.093381 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 04:57:13.118550 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:57:13.148499 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:57:13.174064 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:57:13.195257 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:57:13.195879 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 04:57:13.217239 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:57:13.239571 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 04:57:13.263047 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:57:13.283360 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 04:57:13.283998 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 04:57:13.305672 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 04:57:13.334186 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 04:57:13.362037 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 04:57:13.383137 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:57:13.383665 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 04:57:13.407887 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:57:13.433610 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:57:13.458056 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:57:13.479021 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:57:13.479570 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 04:57:13.504265 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:57:13.529622 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:57:13.554111 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:57:13.574789 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:57:13.575365 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 04:57:13.600291 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:57:13.625813 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:57:13.654985 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:57:13.675378 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 04:57:13.675990 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 04:57:13.701056 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 04:57:13.727329 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 04:57:13.752178 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 04:57:13.772285 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 04:57:16.099412 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 04:57:16.099760 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 04:57:16.379112 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 04:57:16.530888 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 04:57:16.571470 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T04:57:16Z
I1011 04:57:16.586882 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T04:57:16Z
INFO:tensorflow:Graph was finalized.
I1011 04:57:17.489386 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 04:57:17.490061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:57:17.490570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 04:57:17.490631: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 04:57:17.490684: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 04:57:17.490724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 04:57:17.490752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 04:57:17.490775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 04:57:17.490794: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 04:57:17.490813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 04:57:17.490895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:57:17.491368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:57:17.491797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 04:57:17.491848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 04:57:17.491865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 04:57:17.491873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 04:57:17.491972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:57:17.492445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 04:57:17.492885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-8544
I1011 04:57:17.494095 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-8544
INFO:tensorflow:Running local_init_op.
I1011 04:57:18.731141 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 04:57:18.801276 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 05:00:00.460145 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 05:02:38.056866 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 05:05:24.348370 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 05:08:07.105096 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 05:10:48.403146 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 05:13:26.814861 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 05:16:07.719586 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 05:18:47.997015 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 05:21:30.092479 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 05:24:11.399066 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 05:24:16.745399 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1682.45975s
I1011 05:25:19.046838 140235064469376 evaluation.py:273] Inference Time : 1682.45975s
INFO:tensorflow:Finished evaluation at 2020-10-11-05:25:19
I1011 05:25:19.047126 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-05:25:19
INFO:tensorflow:Saving dict for global step 8544: AP = 0.36733165, AP50 = 0.47711414, AP75 = 0.42435604, APl = 0.43805793, APm = 0.4724325, APs = 0.1342858, ARl = 0.80907494, ARm = 0.62152505, ARmax1 = 0.4862227, ARmax10 = 0.67294544, ARmax100 = 0.7114862, ARs = 0.27935538, box_loss = 0.0021880162, cls_loss = 0.2605222, global_step = 8544, loss = 0.4668726
I1011 05:25:19.047324 140235064469376 estimator.py:2063] Saving dict for global step 8544: AP = 0.36733165, AP50 = 0.47711414, AP75 = 0.42435604, APl = 0.43805793, APm = 0.4724325, APs = 0.1342858, ARl = 0.80907494, ARm = 0.62152505, ARmax1 = 0.4862227, ARmax10 = 0.67294544, ARmax100 = 0.7114862, ARs = 0.27935538, box_loss = 0.0021880162, cls_loss = 0.2605222, global_step = 8544, loss = 0.4668726
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8544: efficientdet-d0-finetune/model.ckpt-8544
I1011 05:25:20.014559 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 8544: efficientdet-d0-finetune/model.ckpt-8544
I1011 05:25:20.017100 140235064469376 utils.py:428] Ckpt 0.3673316538333893 is worse than 0.382713

   =====> Starting training, epoch: 12.

   =====> Starting evaluation, epoch: 12.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.88s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=47.85s).
Accumulating evaluation results...
DONE (t=8.81s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.438
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.711
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 05:25:20.202649 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 05:25:20.214993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 05:25:20.248109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:20.248683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 05:25:20.248744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:25:20.251973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 05:25:20.254860: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 05:25:20.255252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 05:25:20.257238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 05:25:20.258402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 05:25:20.262935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:25:20.263061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:20.263638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:20.264187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 05:25:20.531962 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 05:25:20.907826 140235064469376 estimator.py:1162] Calling model_fn.
I1011 05:25:20.908141 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 05:25:20.913010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 05:25:20.913683 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 05:25:20.922199 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 05:25:21.165794 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:25:21.166692 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:25:21.167497 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:25:21.168254 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:25:21.169039 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:25:21.169794 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:25:21.170539 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:25:21.171308 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:25:21.172486 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:25:21.173231 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:25:21.173980 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:25:21.174738 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:25:21.175472 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:25:21.176431 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:25:21.177292 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:25:21.178173 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:25:21.179395 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:25:21.180154 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:25:21.180912 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:25:21.181691 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:25:21.182435 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:25:21.183230 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:25:21.183989 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:25:21.184733 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:25:21.281348 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 05:25:21.281836 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 05:25:21.309924 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 05:25:21.332368 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 05:25:21.359451 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 05:25:21.360160 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 05:25:21.388287 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 05:25:21.417116 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 05:25:21.565351 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 05:25:21.596335 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 05:25:21.597193 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 05:25:21.625496 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 05:25:21.653418 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 05:25:21.676545 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 05:25:21.702628 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 05:25:21.703359 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 05:25:21.729642 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 05:25:21.758179 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 05:25:21.781054 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 05:25:21.809074 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 05:25:21.809642 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 05:25:21.842644 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 05:25:21.880673 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 05:25:21.904535 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 05:25:21.930759 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 05:25:21.931341 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 05:25:21.958773 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 05:25:21.986416 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 05:25:22.011606 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 05:25:22.038049 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:25:22.038622 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 05:25:22.066174 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:25:22.095736 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:25:22.118767 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:25:22.144557 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:25:22.145176 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 05:25:22.172987 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:25:22.200640 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:25:22.225868 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:25:22.252429 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:25:22.253018 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 05:25:22.279821 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:25:22.306828 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:25:22.329282 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:25:22.355935 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:25:22.356529 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 05:25:22.384177 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:25:22.415136 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 05:25:22.438446 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:25:22.464675 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:25:22.465228 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 05:25:22.492491 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:25:22.520499 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 05:25:22.543880 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:25:22.575179 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:25:22.575864 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 05:25:22.603514 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:25:22.637028 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 05:25:22.663794 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:25:22.694092 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:25:22.694680 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 05:25:22.729486 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:25:22.765929 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:25:22.789917 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:25:22.816123 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:25:22.816759 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 05:25:22.848205 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:25:22.884565 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:25:22.908457 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:25:22.937223 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:25:22.937798 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 05:25:22.968974 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:25:23.000656 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:25:23.026435 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:25:23.054586 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:25:23.055210 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 05:25:23.091894 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:25:23.124316 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:25:23.149062 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:25:23.174999 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 05:25:26.038969 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 05:25:26.039288 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 05:25:26.273559 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 05:25:26.275122 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 05:25:26.276778 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 05:25:26.278337 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 05:25:26.279788 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 05:25:26.281180 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 05:25:26.283739 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 05:25:26.285163 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 05:25:34.076678 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 05:25:35.972306 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 05:25:35.972488 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 05:25:35.978219 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 05:25:35.978348 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 05:25:35.978434 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 05:25:35.978527 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 05:25:35.978602 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 05:25:35.983353 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 05:25:35.983466 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 05:25:37.519315 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 05:25:37.520462 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 05:25:41.675012 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 05:25:41.681809: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 05:25:41.682042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 05:25:41.682073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 05:25:41.785489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:41.786238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 05:25:41.786270: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 05:25:41.786489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:41.787187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 05:25:41.787248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:25:41.787308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 05:25:41.787332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 05:25:41.787364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 05:25:41.787390: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 05:25:41.787416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 05:25:41.787443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:25:41.787530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:41.788164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:41.788695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 05:25:41.788821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:25:42.367311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 05:25:42.367367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 05:25:42.367378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 05:25:42.367574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:42.368218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:25:42.368743: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 05:25:42.368789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-8544
I1011 05:25:42.371007 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-8544
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 05:25:43.991883 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 05:25:44.810396 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 05:25:44.957276 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8544...
I1011 05:25:55.496971 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8544...
INFO:tensorflow:Saving checkpoints for 8544 into efficientdet-d0-finetune/model.ckpt.
I1011 05:25:55.510247 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8544 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8544...
I1011 05:25:58.147574 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8544...
2020-10-11 05:26:07.672235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:26:09.630805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.5272412, step = 8544
I1011 05:26:10.608906 140235064469376 basic_session_run_hooks.py:262] loss = 0.5272412, step = 8544
INFO:tensorflow:box_loss = 0.0016723188, cls_loss = 0.34667587, det_loss = 0.4302918, step = 8544
I1011 05:26:10.609622 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0016723188, cls_loss = 0.34667587, det_loss = 0.4302918, step = 8544
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8644...
I1011 05:26:47.405230 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8644...
INFO:tensorflow:Saving checkpoints for 8644 into efficientdet-d0-finetune/model.ckpt.
I1011 05:26:47.405483 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8644 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 05:26:47.469015 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8644...
I1011 05:26:49.196820 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8644...
INFO:tensorflow:global_step/sec: 2.56933
I1011 05:26:49.528686 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.56933
INFO:tensorflow:loss = 0.4327623, step = 8644 (38.921 sec)
I1011 05:26:49.529729 140235064469376 basic_session_run_hooks.py:260] loss = 0.4327623, step = 8644 (38.921 sec)
INFO:tensorflow:box_loss = 0.0022772665, cls_loss = 0.22195244, det_loss = 0.33581576, step = 8644 (38.921 sec)
I1011 05:26:49.530146 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0022772665, cls_loss = 0.22195244, det_loss = 0.33581576, step = 8644 (38.921 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8744...
I1011 05:27:18.824596 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8744...
INFO:tensorflow:Saving checkpoints for 8744 into efficientdet-d0-finetune/model.ckpt.
I1011 05:27:18.824860 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8744 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8744...
I1011 05:27:20.537622 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8744...
INFO:tensorflow:global_step/sec: 3.18597
I1011 05:27:20.916341 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18597
INFO:tensorflow:loss = 0.48691165, step = 8744 (31.388 sec)
I1011 05:27:20.917237 140235064469376 basic_session_run_hooks.py:260] loss = 0.48691165, step = 8744 (31.388 sec)
INFO:tensorflow:box_loss = 0.0027954783, cls_loss = 0.25019073, det_loss = 0.38996467, step = 8744 (31.387 sec)
I1011 05:27:20.917421 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0027954783, cls_loss = 0.25019073, det_loss = 0.38996467, step = 8744 (31.387 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8844...
I1011 05:27:49.873480 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8844...
INFO:tensorflow:Saving checkpoints for 8844 into efficientdet-d0-finetune/model.ckpt.
I1011 05:27:49.873771 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8844 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8844...
I1011 05:27:51.631401 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8844...
INFO:tensorflow:global_step/sec: 3.21877
I1011 05:27:51.984078 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.21877
INFO:tensorflow:loss = 0.5298375, step = 8844 (31.069 sec)
I1011 05:27:51.986276 140235064469376 basic_session_run_hooks.py:260] loss = 0.5298375, step = 8844 (31.069 sec)
INFO:tensorflow:box_loss = 0.002109584, cls_loss = 0.32741547, det_loss = 0.43289465, step = 8844 (31.069 sec)
I1011 05:27:51.986647 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.002109584, cls_loss = 0.32741547, det_loss = 0.43289465, step = 8844 (31.069 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8944...
I1011 05:28:20.857180 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 8944...
INFO:tensorflow:Saving checkpoints for 8944 into efficientdet-d0-finetune/model.ckpt.
I1011 05:28:20.857428 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 8944 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8944...
I1011 05:28:22.572374 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 8944...
INFO:tensorflow:global_step/sec: 3.23258
I1011 05:28:22.919070 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.23258
INFO:tensorflow:loss = 0.5332142, step = 8944 (30.934 sec)
I1011 05:28:22.920118 140235064469376 basic_session_run_hooks.py:260] loss = 0.5332142, step = 8944 (30.934 sec)
INFO:tensorflow:box_loss = 0.0025164436, cls_loss = 0.31045532, det_loss = 0.4362775, step = 8944 (30.934 sec)
I1011 05:28:22.920345 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0025164436, cls_loss = 0.31045532, det_loss = 0.4362775, step = 8944 (30.934 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9044...
I1011 05:28:52.196682 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9044...
INFO:tensorflow:Saving checkpoints for 9044 into efficientdet-d0-finetune/model.ckpt.
I1011 05:28:52.196938 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9044 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9044...
I1011 05:28:53.881344 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9044...
INFO:tensorflow:global_step/sec: 3.19648
I1011 05:28:54.203511 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19648
INFO:tensorflow:loss = 0.5540409, step = 9044 (31.285 sec)
I1011 05:28:54.204676 140235064469376 basic_session_run_hooks.py:260] loss = 0.5540409, step = 9044 (31.285 sec)
INFO:tensorflow:box_loss = 0.0029072668, cls_loss = 0.3117447, det_loss = 0.45710802, step = 9044 (31.285 sec)
I1011 05:28:54.204892 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0029072668, cls_loss = 0.3117447, det_loss = 0.45710802, step = 9044 (31.285 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9144...
I1011 05:29:23.346872 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9144...
INFO:tensorflow:Saving checkpoints for 9144 into efficientdet-d0-finetune/model.ckpt.
I1011 05:29:23.347199 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9144 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9144...
I1011 05:29:25.132687 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9144...
INFO:tensorflow:global_step/sec: 3.19997
I1011 05:29:25.453838 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19997
INFO:tensorflow:loss = 0.5215707, step = 9144 (31.250 sec)
I1011 05:29:25.454738 140235064469376 basic_session_run_hooks.py:260] loss = 0.5215707, step = 9144 (31.250 sec)
INFO:tensorflow:box_loss = 0.0025966645, cls_loss = 0.29481125, det_loss = 0.42464447, step = 9144 (31.250 sec)
I1011 05:29:25.454954 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0025966645, cls_loss = 0.29481125, det_loss = 0.42464447, step = 9144 (31.250 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9244...
I1011 05:29:55.032377 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9244...
INFO:tensorflow:Saving checkpoints for 9244 into efficientdet-d0-finetune/model.ckpt.
I1011 05:29:55.032616 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9244 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9244...
I1011 05:29:56.714698 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9244...
INFO:tensorflow:global_step/sec: 3.16276
I1011 05:29:57.071841 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16276
INFO:tensorflow:loss = 0.42242324, step = 9244 (31.618 sec)
I1011 05:29:57.072771 140235064469376 basic_session_run_hooks.py:260] loss = 0.42242324, step = 9244 (31.618 sec)
INFO:tensorflow:box_loss = 0.002116441, cls_loss = 0.21968079, det_loss = 0.3255028, step = 9244 (31.618 sec)
I1011 05:29:57.072968 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.002116441, cls_loss = 0.21968079, det_loss = 0.3255028, step = 9244 (31.618 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9256...
I1011 05:30:00.310792 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9256...
INFO:tensorflow:Saving checkpoints for 9256 into efficientdet-d0-finetune/model.ckpt.
I1011 05:30:00.311197 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9256 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9256...
I1011 05:30:02.019220 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9256...
INFO:tensorflow:Loss for final step: 0.48379076.
I1011 05:30:02.387655 140235064469376 estimator.py:350] Loss for final step: 0.48379076.
INFO:tensorflow:Calling model_fn.
I1011 05:30:02.864288 140235064469376 estimator.py:1162] Calling model_fn.
I1011 05:30:02.864600 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 05:30:02.868032 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 05:30:03.107645 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:30:03.109017 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:30:03.109869 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:30:03.110626 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:30:03.111437 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:30:03.112321 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:30:03.113117 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:30:03.113899 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:30:03.115154 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:30:03.116039 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:30:03.116874 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:30:03.117782 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:30:03.118661 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:30:03.119436 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:30:03.120226 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:30:03.121106 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:30:03.122300 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:30:03.123115 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:30:03.123997 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:30:03.124754 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:30:03.125582 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:30:03.126350 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:30:03.127129 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:30:03.128027 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:30:03.410801 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 05:30:03.411347 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 05:30:03.432666 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 05:30:03.457214 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 05:30:03.476604 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 05:30:03.477188 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 05:30:03.497411 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 05:30:03.517976 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 05:30:03.540294 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 05:30:03.560832 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 05:30:03.561337 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 05:30:03.581516 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 05:30:03.602579 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 05:30:03.624386 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 05:30:03.644091 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 05:30:03.644660 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 05:30:03.665645 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 05:30:03.687001 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 05:30:03.713933 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 05:30:03.735923 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 05:30:03.736527 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 05:30:03.759845 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 05:30:03.781853 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 05:30:03.805732 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 05:30:03.825578 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 05:30:03.826158 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 05:30:03.846475 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 05:30:03.870438 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 05:30:03.892980 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 05:30:03.912234 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:30:03.912773 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 05:30:03.938152 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:30:03.960592 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:30:03.983528 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:30:04.008423 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:30:04.009085 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 05:30:04.031169 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:30:04.054230 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:30:04.079690 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:30:04.102471 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:30:04.103123 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 05:30:04.132798 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:30:04.158137 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:30:04.182844 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:30:04.204349 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:30:04.204910 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 05:30:04.227781 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:30:04.251008 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 05:30:04.275162 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:30:04.299158 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:30:04.299730 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 05:30:04.322401 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:30:04.345258 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 05:30:04.369865 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:30:04.391456 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:30:04.392420 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 05:30:04.414953 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:30:04.438939 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 05:30:04.465658 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:30:04.487045 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:30:04.487581 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 05:30:04.513960 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:30:04.540748 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:30:04.566065 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:30:04.587701 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:30:04.588270 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 05:30:04.617316 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:30:04.644125 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:30:04.670090 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:30:04.691584 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:30:04.692192 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 05:30:04.718883 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:30:04.748113 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:30:04.779215 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:30:04.804174 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:30:04.804749 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 05:30:04.833985 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:30:04.862353 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:30:04.888155 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:30:04.913702 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 05:30:07.323228 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 05:30:07.323506 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 05:30:07.583928 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 05:30:07.738314 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 05:30:07.777809 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T05:30:07Z
I1011 05:30:07.792854 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T05:30:07Z
INFO:tensorflow:Graph was finalized.
I1011 05:30:08.676433 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 05:30:08.677134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:30:08.677697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 05:30:08.677803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:30:08.677867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 05:30:08.677898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 05:30:08.677920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 05:30:08.677940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 05:30:08.677959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 05:30:08.677981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:30:08.678073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:30:08.678584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:30:08.679031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 05:30:08.679085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 05:30:08.679102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 05:30:08.679111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 05:30:08.679231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:30:08.679752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:30:08.680177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-9256
I1011 05:30:08.681258 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-9256
INFO:tensorflow:Running local_init_op.
I1011 05:30:09.866624 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 05:30:09.935334 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 05:32:52.699699 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 05:35:29.490197 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 05:38:13.116019 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 05:40:53.852765 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 05:43:32.804403 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 05:46:11.085920 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 05:48:50.876702 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 05:51:30.130846 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 05:54:09.651886 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 05:56:50.518240 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 05:56:55.636397 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1669.64841s
I1011 05:57:57.441450 140235064469376 evaluation.py:273] Inference Time : 1669.64841s
INFO:tensorflow:Finished evaluation at 2020-10-11-05:57:57
I1011 05:57:57.441749 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-05:57:57
INFO:tensorflow:Saving dict for global step 9256: AP = 0.3648726, AP50 = 0.47549182, AP75 = 0.42389196, APl = 0.44173294, APm = 0.4866242, APs = 0.13351244, ARl = 0.81003726, ARm = 0.6149653, ARmax1 = 0.48186606, ARmax10 = 0.67022645, ARmax100 = 0.70885724, ARs = 0.25682506, box_loss = 0.0021594116, cls_loss = 0.24955308, global_step = 9256, loss = 0.45444253
I1011 05:57:57.442039 140235064469376 estimator.py:2063] Saving dict for global step 9256: AP = 0.3648726, AP50 = 0.47549182, AP75 = 0.42389196, APl = 0.44173294, APm = 0.4866242, APs = 0.13351244, ARl = 0.81003726, ARm = 0.6149653, ARmax1 = 0.48186606, ARmax10 = 0.67022645, ARmax100 = 0.70885724, ARs = 0.25682506, box_loss = 0.0021594116, cls_loss = 0.24955308, global_step = 9256, loss = 0.45444253
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9256: efficientdet-d0-finetune/model.ckpt-9256
I1011 05:57:58.467909 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 9256: efficientdet-d0-finetune/model.ckpt-9256
I1011 05:57:58.470355 140235064469376 utils.py:428] Ckpt 0.36487260460853577 is worse than 0.382713

   =====> Starting training, epoch: 13.

   =====> Starting evaluation, epoch: 13.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.90s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=47.60s).
Accumulating evaluation results...
DONE (t=8.56s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.257
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.810
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 05:57:58.654556 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 05:57:58.667054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 05:57:58.700271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:57:58.700902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 05:57:58.700952: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:57:58.704121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 05:57:58.706982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 05:57:58.707347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 05:57:58.709221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 05:57:58.710379: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 05:57:58.714772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:57:58.714931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:57:58.715796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:57:58.716538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 05:57:58.991942 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 05:57:59.405354 140235064469376 estimator.py:1162] Calling model_fn.
I1011 05:57:59.405725 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 05:57:59.410935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 05:57:59.411597 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 05:57:59.420738 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 05:57:59.662972 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:57:59.663951 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:57:59.664784 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:57:59.665615 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:57:59.666391 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:57:59.667171 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:57:59.667954 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:57:59.668757 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:57:59.670043 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:57:59.670868 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:57:59.671631 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:57:59.672411 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:57:59.673256 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:57:59.674193 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:57:59.675081 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:57:59.675911 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:57:59.677257 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 05:57:59.678080 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 05:57:59.678946 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 05:57:59.679845 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 05:57:59.680619 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 05:57:59.681397 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 05:57:59.682347 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 05:57:59.683129 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 05:57:59.777044 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 05:57:59.777539 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 05:57:59.807949 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 05:57:59.832438 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 05:57:59.860861 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 05:57:59.861423 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 05:57:59.889940 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 05:57:59.919556 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 05:58:00.067948 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 05:58:00.094106 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 05:58:00.094666 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 05:58:00.120952 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 05:58:00.151534 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 05:58:00.174588 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 05:58:00.200791 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 05:58:00.201372 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 05:58:00.232692 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 05:58:00.259976 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 05:58:00.283160 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 05:58:00.311090 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 05:58:00.311877 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 05:58:00.341273 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 05:58:00.370214 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 05:58:00.392417 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 05:58:00.417833 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 05:58:00.418516 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 05:58:00.447779 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 05:58:00.474547 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 05:58:00.496647 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 05:58:00.523095 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:58:00.523737 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 05:58:00.550472 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:58:00.578525 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:58:00.600772 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:58:00.627698 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:58:00.628497 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 05:58:00.656597 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:58:00.684024 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:58:00.706418 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:58:00.732531 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 05:58:00.733075 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 05:58:00.759834 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 05:58:00.787281 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 05:58:00.810505 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 05:58:00.836489 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:58:00.837104 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 05:58:00.864619 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:58:00.892288 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 05:58:00.914511 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:58:00.945649 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:58:00.946227 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 05:58:00.976551 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:58:01.008199 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 05:58:01.033795 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:58:01.060772 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 05:58:01.061347 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 05:58:01.088639 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 05:58:01.116023 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 05:58:01.141029 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 05:58:01.170485 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:58:01.171024 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 05:58:01.201559 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:58:01.238673 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:58:01.263350 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:58:01.289105 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:58:01.289701 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 05:58:01.320228 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:58:01.359583 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:58:01.383484 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:58:01.410611 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:58:01.411162 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 05:58:01.442558 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:58:01.474080 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:58:01.497576 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:58:01.525953 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 05:58:01.526490 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 05:58:01.564830 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 05:58:01.601584 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 05:58:01.627072 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 05:58:01.653930 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 05:58:04.470974 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 05:58:04.471308 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 05:58:04.723817 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 05:58:04.725620 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 05:58:04.727195 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 05:58:04.728677 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 05:58:04.730219 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 05:58:04.731785 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 05:58:04.734579 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 05:58:04.736273 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 05:58:12.562018 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 05:58:14.459700 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 05:58:14.459884 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 05:58:14.465578 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 05:58:14.465707 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 05:58:14.465821 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 05:58:14.465915 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 05:58:14.466024 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 05:58:14.470821 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 05:58:14.470929 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 05:58:16.004993 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 05:58:16.006079 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 05:58:20.133869 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 05:58:20.140950: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 05:58:20.141180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 05:58:20.141208: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 05:58:20.243470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:58:20.244162: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 05:58:20.244207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 05:58:20.244421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:58:20.244999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 05:58:20.245054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:58:20.245106: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 05:58:20.245129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 05:58:20.245149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 05:58:20.245169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 05:58:20.245191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 05:58:20.245211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:58:20.245298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:58:20.245900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:58:20.246390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 05:58:20.246483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 05:58:20.819993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 05:58:20.820069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 05:58:20.820080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 05:58:20.820288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:58:20.820964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 05:58:20.821508: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 05:58:20.821553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-9256
I1011 05:58:20.823669 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-9256
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 05:58:22.501420 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 05:58:23.431872 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 05:58:23.584625 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9256...
I1011 05:58:34.119647 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9256...
INFO:tensorflow:Saving checkpoints for 9256 into efficientdet-d0-finetune/model.ckpt.
I1011 05:58:34.132808 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9256 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9256...
I1011 05:58:36.737187 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9256...
2020-10-11 05:58:46.174013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 05:58:48.240910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.50260353, step = 9256
I1011 05:58:49.235790 140235064469376 basic_session_run_hooks.py:262] loss = 0.50260353, step = 9256
INFO:tensorflow:box_loss = 0.0033160942, cls_loss = 0.23987961, det_loss = 0.40568432, step = 9256
I1011 05:58:49.236497 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0033160942, cls_loss = 0.23987961, det_loss = 0.40568432, step = 9256
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9356...
I1011 05:59:26.911400 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9356...
INFO:tensorflow:Saving checkpoints for 9356 into efficientdet-d0-finetune/model.ckpt.
I1011 05:59:26.911809 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9356 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 05:59:26.976262 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9356...
I1011 05:59:28.653266 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9356...
INFO:tensorflow:global_step/sec: 2.51513
I1011 05:59:28.994439 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.51513
INFO:tensorflow:loss = 0.35186678, step = 9356 (39.760 sec)
I1011 05:59:28.995486 140235064469376 basic_session_run_hooks.py:260] loss = 0.35186678, step = 9356 (39.760 sec)
INFO:tensorflow:box_loss = 0.0012488888, cls_loss = 0.1925087, det_loss = 0.25495315, step = 9356 (39.759 sec)
I1011 05:59:28.995768 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0012488888, cls_loss = 0.1925087, det_loss = 0.25495315, step = 9356 (39.759 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9456...
I1011 05:59:58.401829 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9456...
INFO:tensorflow:Saving checkpoints for 9456 into efficientdet-d0-finetune/model.ckpt.
I1011 05:59:58.402097 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9456 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9456...
I1011 06:00:00.115469 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9456...
INFO:tensorflow:global_step/sec: 3.18215
I1011 06:00:00.419751 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18215
INFO:tensorflow:loss = 0.47942472, step = 9456 (31.425 sec)
I1011 06:00:00.420802 140235064469376 basic_session_run_hooks.py:260] loss = 0.47942472, step = 9456 (31.425 sec)
INFO:tensorflow:box_loss = 0.0023375463, cls_loss = 0.26564026, det_loss = 0.38251758, step = 9456 (31.425 sec)
I1011 06:00:00.420995 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0023375463, cls_loss = 0.26564026, det_loss = 0.38251758, step = 9456 (31.425 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9556...
I1011 06:00:29.610838 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9556...
INFO:tensorflow:Saving checkpoints for 9556 into efficientdet-d0-finetune/model.ckpt.
I1011 06:00:29.611092 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9556 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9556...
I1011 06:00:31.373087 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9556...
INFO:tensorflow:global_step/sec: 3.19483
I1011 06:00:31.720329 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19483
INFO:tensorflow:loss = 0.44284153, step = 9556 (31.301 sec)
I1011 06:00:31.721365 140235064469376 basic_session_run_hooks.py:260] loss = 0.44284153, step = 9556 (31.301 sec)
INFO:tensorflow:box_loss = 0.001944471, cls_loss = 0.24871731, det_loss = 0.34594086, step = 9556 (31.301 sec)
I1011 06:00:31.721564 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.001944471, cls_loss = 0.24871731, det_loss = 0.34594086, step = 9556 (31.301 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9656...
I1011 06:01:00.929759 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9656...
INFO:tensorflow:Saving checkpoints for 9656 into efficientdet-d0-finetune/model.ckpt.
I1011 06:01:00.930026 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9656 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9656...
I1011 06:01:02.612841 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9656...
INFO:tensorflow:global_step/sec: 3.20898
I1011 06:01:02.882893 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.20898
INFO:tensorflow:loss = 0.4567246, step = 9656 (31.163 sec)
I1011 06:01:02.883882 140235064469376 basic_session_run_hooks.py:260] loss = 0.4567246, step = 9656 (31.163 sec)
INFO:tensorflow:box_loss = 0.0025913334, cls_loss = 0.23026466, det_loss = 0.35983133, step = 9656 (31.163 sec)
I1011 06:01:02.884070 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0025913334, cls_loss = 0.23026466, det_loss = 0.35983133, step = 9656 (31.163 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9756...
I1011 06:01:31.526826 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9756...
INFO:tensorflow:Saving checkpoints for 9756 into efficientdet-d0-finetune/model.ckpt.
I1011 06:01:31.527095 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9756 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9756...
I1011 06:01:33.208370 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9756...
INFO:tensorflow:global_step/sec: 3.26095
I1011 06:01:33.548831 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.26095
INFO:tensorflow:loss = 0.63392735, step = 9756 (30.666 sec)
I1011 06:01:33.549881 140235064469376 basic_session_run_hooks.py:260] loss = 0.63392735, step = 9756 (30.666 sec)
INFO:tensorflow:box_loss = 0.0041927923, cls_loss = 0.3274002, det_loss = 0.5370398, step = 9756 (30.666 sec)
I1011 06:01:33.550068 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0041927923, cls_loss = 0.3274002, det_loss = 0.5370398, step = 9756 (30.666 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9856...
I1011 06:02:03.178033 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9856...
INFO:tensorflow:Saving checkpoints for 9856 into efficientdet-d0-finetune/model.ckpt.
I1011 06:02:03.178292 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9856 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9856...
I1011 06:02:04.848292 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9856...
INFO:tensorflow:global_step/sec: 3.16212
I1011 06:02:05.173207 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16212
INFO:tensorflow:loss = 0.40560788, step = 9856 (31.624 sec)
I1011 06:02:05.174148 140235064469376 basic_session_run_hooks.py:260] loss = 0.40560788, step = 9856 (31.624 sec)
INFO:tensorflow:box_loss = 0.0018881833, cls_loss = 0.21431732, det_loss = 0.3087265, step = 9856 (31.624 sec)
I1011 06:02:05.174344 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0018881833, cls_loss = 0.21431732, det_loss = 0.3087265, step = 9856 (31.624 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9956...
I1011 06:02:34.271956 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9956...
INFO:tensorflow:Saving checkpoints for 9956 into efficientdet-d0-finetune/model.ckpt.
I1011 06:02:34.272218 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9956 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9956...
I1011 06:02:35.985219 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9956...
INFO:tensorflow:global_step/sec: 3.21746
I1011 06:02:36.253602 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.21746
INFO:tensorflow:loss = 0.63849324, step = 9956 (31.080 sec)
I1011 06:02:36.254647 140235064469376 basic_session_run_hooks.py:260] loss = 0.63849324, step = 9956 (31.080 sec)
INFO:tensorflow:box_loss = 0.0042536985, cls_loss = 0.32893372, det_loss = 0.54161865, step = 9956 (31.081 sec)
I1011 06:02:36.254990 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0042536985, cls_loss = 0.32893372, det_loss = 0.54161865, step = 9956 (31.081 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9968...
I1011 06:02:39.787072 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9968...
INFO:tensorflow:Saving checkpoints for 9968 into efficientdet-d0-finetune/model.ckpt.
I1011 06:02:39.787318 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9968 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9968...
I1011 06:02:41.488554 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9968...
INFO:tensorflow:Loss for final step: 0.48986763.
I1011 06:02:41.847681 140235064469376 estimator.py:350] Loss for final step: 0.48986763.
INFO:tensorflow:Calling model_fn.
I1011 06:02:42.351916 140235064469376 estimator.py:1162] Calling model_fn.
I1011 06:02:42.352273 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 06:02:42.355739 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 06:02:42.596375 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:02:42.597456 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:02:42.598387 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:02:42.599489 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:02:42.600512 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:02:42.601528 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:02:42.602525 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:02:42.603413 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:02:42.604701 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:02:42.605501 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:02:42.606274 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:02:42.607240 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:02:42.608144 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:02:42.609072 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:02:42.609988 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:02:42.610861 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:02:42.612254 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:02:42.613320 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:02:42.614274 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:02:42.615129 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:02:42.616083 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:02:42.616953 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:02:42.617835 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:02:42.618793 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:02:42.926561 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 06:02:42.927487 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 06:02:42.953358 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 06:02:42.978764 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 06:02:42.998485 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 06:02:42.999145 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 06:02:43.020007 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 06:02:43.040728 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 06:02:43.063246 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 06:02:43.082436 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 06:02:43.082955 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 06:02:43.104690 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 06:02:43.127957 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 06:02:43.153402 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 06:02:43.174223 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 06:02:43.174816 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 06:02:43.200064 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 06:02:43.223476 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 06:02:43.249461 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 06:02:43.273004 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 06:02:43.273567 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 06:02:43.295473 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 06:02:43.316314 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 06:02:43.338368 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 06:02:43.358114 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 06:02:43.358767 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 06:02:43.378622 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 06:02:43.399609 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 06:02:43.421230 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 06:02:43.440920 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:02:43.441444 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 06:02:43.461746 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:02:43.483502 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:02:43.507692 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:02:43.528156 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:02:43.528693 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 06:02:43.551987 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:02:43.573880 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:02:43.597131 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:02:43.617490 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:02:43.618060 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 06:02:43.638365 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:02:43.660784 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:02:43.688635 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:02:43.708452 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:02:43.708996 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 06:02:43.729201 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:02:43.750628 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 06:02:43.772880 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:02:43.793213 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:02:43.793748 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 06:02:43.814153 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:02:43.836127 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 06:02:43.860845 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:02:43.880414 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:02:43.881010 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 06:02:43.901879 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:02:43.923086 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 06:02:43.951652 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:02:43.972257 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:02:43.972820 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 06:02:44.002248 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:02:44.027866 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:02:44.051947 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:02:44.072984 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:02:44.073532 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 06:02:44.097948 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:02:44.123116 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:02:44.146692 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:02:44.167746 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:02:44.168333 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 06:02:44.195067 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:02:44.221092 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:02:44.245002 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:02:44.265432 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:02:44.265987 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 06:02:44.292807 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:02:44.318312 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:02:44.342082 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:02:44.361734 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 06:02:46.733933 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 06:02:46.734199 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 06:02:47.060080 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 06:02:47.212827 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 06:02:47.255587 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T06:02:47Z
I1011 06:02:47.273409 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T06:02:47Z
INFO:tensorflow:Graph was finalized.
I1011 06:02:48.193564 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 06:02:48.194277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:02:48.194810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 06:02:48.194872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 06:02:48.194939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 06:02:48.194964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 06:02:48.194981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 06:02:48.195004: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 06:02:48.195025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 06:02:48.195045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 06:02:48.195135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:02:48.195608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:02:48.196039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 06:02:48.196166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 06:02:48.196182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 06:02:48.196191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 06:02:48.196299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:02:48.196801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:02:48.197242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-9968
I1011 06:02:48.198420 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-9968
INFO:tensorflow:Running local_init_op.
I1011 06:02:49.402295 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 06:02:49.466182 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 06:05:39.937488 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 06:08:26.183630 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 06:11:19.078231 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 06:14:07.880498 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 06:16:53.248246 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 06:19:39.561964 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 06:22:28.642036 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 06:25:17.007039 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 06:28:06.356031 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 06:30:56.371915 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 06:31:01.946264 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1757.18732s
I1011 06:32:04.460934 140235064469376 evaluation.py:273] Inference Time : 1757.18732s
INFO:tensorflow:Finished evaluation at 2020-10-11-06:32:04
I1011 06:32:04.461194 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-06:32:04
INFO:tensorflow:Saving dict for global step 9968: AP = 0.38632178, AP50 = 0.49101615, AP75 = 0.44439495, APl = 0.4637649, APm = 0.5134892, APs = 0.15334377, ARl = 0.825605, ARm = 0.6402631, ARmax1 = 0.498317, ARmax10 = 0.6886949, ARmax100 = 0.72763216, ARs = 0.2816621, box_loss = 0.0020268736, cls_loss = 0.2365299, global_step = 9968, loss = 0.43474728
I1011 06:32:04.461416 140235064469376 estimator.py:2063] Saving dict for global step 9968: AP = 0.38632178, AP50 = 0.49101615, AP75 = 0.44439495, APl = 0.4637649, APm = 0.5134892, APs = 0.15334377, ARl = 0.825605, ARm = 0.6402631, ARmax1 = 0.498317, ARmax10 = 0.6886949, ARmax100 = 0.72763216, ARs = 0.2816621, box_loss = 0.0020268736, cls_loss = 0.2365299, global_step = 9968, loss = 0.43474728
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9968: efficientdet-d0-finetune/model.ckpt-9968
I1011 06:32:05.501507 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 9968: efficientdet-d0-finetune/model.ckpt-9968
I1011 06:32:05.509215 140235064469376 utils.py:444] mv efficientdet-d0-finetune/archive to efficientdet-d0-finetune/backup
INFO:tensorflow:efficientdet-d0-finetune/archive/model.ckpt-9968 is not in all_model_checkpoint_paths. Manually adding it.
I1011 06:32:05.549271 140235064469376 checkpoint_management.py:102] efficientdet-d0-finetune/archive/model.ckpt-9968 is not in all_model_checkpoint_paths. Manually adding it.
I1011 06:32:05.549960 140235064469376 utils.py:464] Copying checkpoint efficientdet-d0-finetune/model.ckpt-9968 to efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 14.

   =====> Starting evaluation, epoch: 14.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.93s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=48.16s).
Accumulating evaluation results...
DONE (t=8.62s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.728
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.282
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 06:32:05.732405 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 06:32:05.745076: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 06:32:05.783359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:05.784006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 06:32:05.784062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 06:32:05.787384: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 06:32:05.790193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 06:32:05.790567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 06:32:05.792527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 06:32:05.793723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 06:32:05.798103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 06:32:05.798226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:05.798823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:05.799342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 06:32:06.071681 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 06:32:06.448628 140235064469376 estimator.py:1162] Calling model_fn.
I1011 06:32:06.448972 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 06:32:06.454312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 06:32:06.455052 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 06:32:06.464390 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 06:32:06.712404 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:32:06.713301 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:32:06.714072 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:32:06.714818 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:32:06.715563 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:32:06.716328 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:32:06.717102 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:32:06.717908 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:32:06.719120 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:32:06.719871 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:32:06.720598 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:32:06.721393 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:32:06.722165 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:32:06.723000 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:32:06.723766 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:32:06.724506 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:32:06.725730 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:32:06.726516 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:32:06.727315 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:32:06.728169 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:32:06.728921 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:32:06.729666 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:32:06.730428 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:32:06.731182 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:32:06.822369 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 06:32:06.822853 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 06:32:06.850484 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 06:32:06.873548 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 06:32:06.899507 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 06:32:06.900082 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 06:32:06.926341 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 06:32:06.954384 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 06:32:07.101114 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 06:32:07.127502 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 06:32:07.128079 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 06:32:07.155947 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 06:32:07.184575 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 06:32:07.207052 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 06:32:07.233644 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 06:32:07.234272 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 06:32:07.261466 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 06:32:07.289483 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 06:32:07.312024 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 06:32:07.338461 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 06:32:07.339068 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 06:32:07.370753 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 06:32:07.405456 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 06:32:07.431670 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 06:32:07.459491 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 06:32:07.460111 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 06:32:07.486920 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 06:32:07.519933 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 06:32:07.542755 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 06:32:07.572091 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:32:07.572957 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 06:32:07.599622 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:32:07.627302 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:32:07.650391 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:32:07.677889 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:32:07.678463 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 06:32:07.705661 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:32:07.734272 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:32:07.757251 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:32:07.788357 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:32:07.788957 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 06:32:07.816418 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:32:07.844156 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:32:07.866905 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:32:07.892980 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:32:07.893508 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 06:32:07.922003 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:32:07.952499 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 06:32:07.980799 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:32:08.013993 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:32:08.014582 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 06:32:08.042803 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:32:08.071563 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 06:32:08.095322 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:32:08.121770 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:32:08.122405 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 06:32:08.151637 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:32:08.183263 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 06:32:08.206047 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:32:08.233398 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:32:08.233966 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 06:32:08.265849 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:32:08.298837 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:32:08.322136 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:32:08.348672 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:32:08.349226 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 06:32:08.380456 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:32:08.411302 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:32:08.435017 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:32:08.462860 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:32:08.463407 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 06:32:08.499079 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:32:08.538998 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:32:08.565820 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:32:08.596888 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:32:08.597488 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 06:32:08.632231 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:32:08.667008 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:32:08.690821 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:32:08.716590 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 06:32:11.531337 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 06:32:11.531661 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 06:32:11.782192 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 06:32:11.783820 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 06:32:11.785282 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 06:32:11.786634 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 06:32:11.788053 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 06:32:11.789506 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 06:32:11.793007 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 06:32:11.795242 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 06:32:19.584146 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 06:32:21.532907 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 06:32:21.533084 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 06:32:21.538794 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 06:32:21.538932 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 06:32:21.539019 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 06:32:21.539115 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 06:32:21.539195 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 06:32:21.544188 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 06:32:21.544310 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 06:32:23.080368 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 06:32:23.081525 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 06:32:27.210615 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 06:32:27.217590: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 06:32:27.217911: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 06:32:27.217943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 06:32:27.327579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:27.328287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 06:32:27.328321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 06:32:27.328535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:27.329133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 06:32:27.329187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 06:32:27.329244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 06:32:27.329272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 06:32:27.329287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 06:32:27.329319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 06:32:27.329357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 06:32:27.329373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 06:32:27.329470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:27.330089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:27.330677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 06:32:27.330813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 06:32:27.913008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 06:32:27.913059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 06:32:27.913071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 06:32:27.913302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:27.914036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:32:27.914588: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 06:32:27.914634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-9968
I1011 06:32:27.916958 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-9968
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 06:32:29.651779 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 06:32:30.589689 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 06:32:30.743303 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9968...
I1011 06:32:41.742544 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 9968...
INFO:tensorflow:Saving checkpoints for 9968 into efficientdet-d0-finetune/model.ckpt.
I1011 06:32:41.756750 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 9968 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9968...
I1011 06:32:44.349969 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 9968...
2020-10-11 06:32:53.957906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 06:32:56.000335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.3644762, step = 9968
I1011 06:32:56.973552 140235064469376 basic_session_run_hooks.py:262] loss = 0.3644762, step = 9968
INFO:tensorflow:box_loss = 0.0012163062, cls_loss = 0.20678711, det_loss = 0.2676024, step = 9968
I1011 06:32:56.974266 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0012163062, cls_loss = 0.20678711, det_loss = 0.2676024, step = 9968
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10068...
I1011 06:33:34.459668 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10068...
INFO:tensorflow:Saving checkpoints for 10068 into efficientdet-d0-finetune/model.ckpt.
I1011 06:33:34.460044 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10068 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 06:33:34.518420 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10068...
I1011 06:33:36.191730 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10068...
INFO:tensorflow:global_step/sec: 2.52892
I1011 06:33:36.515276 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.52892
INFO:tensorflow:loss = 0.57482666, step = 10068 (39.543 sec)
I1011 06:33:36.516372 140235064469376 basic_session_run_hooks.py:260] loss = 0.57482666, step = 10068 (39.543 sec)
INFO:tensorflow:box_loss = 0.0031175148, cls_loss = 0.32208252, det_loss = 0.47795826, step = 10068 (39.542 sec)
I1011 06:33:36.516569 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0031175148, cls_loss = 0.32208252, det_loss = 0.47795826, step = 10068 (39.542 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10168...
I1011 06:34:06.367564 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10168...
INFO:tensorflow:Saving checkpoints for 10168 into efficientdet-d0-finetune/model.ckpt.
I1011 06:34:06.367815 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10168 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10168...
I1011 06:34:08.093384 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10168...
INFO:tensorflow:global_step/sec: 3.12674
I1011 06:34:08.497418 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.12674
INFO:tensorflow:loss = 0.45562172, step = 10168 (31.982 sec)
I1011 06:34:08.498593 140235064469376 basic_session_run_hooks.py:260] loss = 0.45562172, step = 10168 (31.982 sec)
INFO:tensorflow:box_loss = 0.0017538216, cls_loss = 0.27106857, det_loss = 0.35875964, step = 10168 (31.982 sec)
I1011 06:34:08.498833 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0017538216, cls_loss = 0.27106857, det_loss = 0.35875964, step = 10168 (31.982 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10268...
I1011 06:34:38.109401 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10268...
INFO:tensorflow:Saving checkpoints for 10268 into efficientdet-d0-finetune/model.ckpt.
I1011 06:34:38.109631 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10268 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10268...
I1011 06:34:39.824218 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10268...
INFO:tensorflow:global_step/sec: 3.16028
I1011 06:34:40.140199 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16028
INFO:tensorflow:loss = 0.5508488, step = 10268 (31.643 sec)
I1011 06:34:40.141134 140235064469376 basic_session_run_hooks.py:260] loss = 0.5508488, step = 10268 (31.643 sec)
INFO:tensorflow:box_loss = 0.0034884415, cls_loss = 0.27957153, det_loss = 0.45399362, step = 10268 (31.643 sec)
I1011 06:34:40.141428 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0034884415, cls_loss = 0.27957153, det_loss = 0.45399362, step = 10268 (31.643 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10368...
I1011 06:35:09.471512 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10368...
INFO:tensorflow:Saving checkpoints for 10368 into efficientdet-d0-finetune/model.ckpt.
I1011 06:35:09.471808 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10368 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10368...
I1011 06:35:11.182940 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10368...
INFO:tensorflow:global_step/sec: 3.19257
I1011 06:35:11.462924 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19257
INFO:tensorflow:loss = 0.62449163, step = 10368 (31.323 sec)
I1011 06:35:11.463932 140235064469376 basic_session_run_hooks.py:260] loss = 0.62449163, step = 10368 (31.323 sec)
INFO:tensorflow:box_loss = 0.004153989, cls_loss = 0.31994247, det_loss = 0.5276419, step = 10368 (31.323 sec)
I1011 06:35:11.464133 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.004153989, cls_loss = 0.31994247, det_loss = 0.5276419, step = 10368 (31.323 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10384 vs previous value: 10384. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 06:35:16.243976 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10384 vs previous value: 10384. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10468...
I1011 06:35:41.244415 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10468...
INFO:tensorflow:Saving checkpoints for 10468 into efficientdet-d0-finetune/model.ckpt.
I1011 06:35:41.244794 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10468 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10468...
I1011 06:35:42.963598 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10468...
INFO:tensorflow:global_step/sec: 3.14351
I1011 06:35:43.274476 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.14351
INFO:tensorflow:loss = 0.46188068, step = 10468 (31.812 sec)
I1011 06:35:43.275447 140235064469376 basic_session_run_hooks.py:260] loss = 0.46188068, step = 10468 (31.812 sec)
INFO:tensorflow:box_loss = 0.0021023273, cls_loss = 0.25992012, det_loss = 0.3650365, step = 10468 (31.812 sec)
I1011 06:35:43.275636 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0021023273, cls_loss = 0.25992012, det_loss = 0.3650365, step = 10468 (31.812 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10524 vs previous value: 10524. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 06:35:59.832385 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10524 vs previous value: 10524. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10568...
I1011 06:36:12.619519 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10568...
INFO:tensorflow:Saving checkpoints for 10568 into efficientdet-d0-finetune/model.ckpt.
I1011 06:36:12.619786 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10568 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10568...
I1011 06:36:14.380455 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10568...
INFO:tensorflow:global_step/sec: 3.18299
I1011 06:36:14.691461 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18299
INFO:tensorflow:loss = 0.53260374, step = 10568 (31.417 sec)
I1011 06:36:14.692434 140235064469376 basic_session_run_hooks.py:260] loss = 0.53260374, step = 10568 (31.417 sec)
INFO:tensorflow:box_loss = 0.0031730114, cls_loss = 0.27711487, det_loss = 0.43576545, step = 10568 (31.417 sec)
I1011 06:36:14.692629 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0031730114, cls_loss = 0.27711487, det_loss = 0.43576545, step = 10568 (31.417 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10668...
I1011 06:36:44.667302 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10668...
INFO:tensorflow:Saving checkpoints for 10668 into efficientdet-d0-finetune/model.ckpt.
I1011 06:36:44.667528 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10668 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10668...
I1011 06:36:46.383921 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10668...
INFO:tensorflow:global_step/sec: 3.12631
I1011 06:36:46.678071 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.12631
INFO:tensorflow:loss = 0.41806072, step = 10668 (31.987 sec)
I1011 06:36:46.679036 140235064469376 basic_session_run_hooks.py:260] loss = 0.41806072, step = 10668 (31.987 sec)
INFO:tensorflow:box_loss = 0.0019281686, cls_loss = 0.22481918, det_loss = 0.3212276, step = 10668 (31.987 sec)
I1011 06:36:46.679333 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0019281686, cls_loss = 0.22481918, det_loss = 0.3212276, step = 10668 (31.987 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10680...
I1011 06:36:50.074159 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10680...
INFO:tensorflow:Saving checkpoints for 10680 into efficientdet-d0-finetune/model.ckpt.
I1011 06:36:50.074393 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10680 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10680...
I1011 06:36:51.832926 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10680...
INFO:tensorflow:Loss for final step: 0.5276889.
I1011 06:36:52.222765 140235064469376 estimator.py:350] Loss for final step: 0.5276889.
INFO:tensorflow:Calling model_fn.
I1011 06:36:52.712266 140235064469376 estimator.py:1162] Calling model_fn.
I1011 06:36:52.712615 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 06:36:52.716242 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 06:36:52.950936 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:36:52.951992 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:36:52.952952 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:36:52.953831 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:36:52.954672 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:36:52.955630 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:36:52.956499 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:36:52.957339 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:36:52.958666 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:36:52.959619 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:36:52.960542 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:36:52.961498 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:36:52.962345 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:36:52.963196 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:36:52.964051 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:36:52.964966 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:36:52.966342 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 06:36:52.967226 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 06:36:52.968264 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 06:36:52.969165 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 06:36:52.970026 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 06:36:52.970913 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 06:36:52.971835 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 06:36:52.972773 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 06:36:53.279092 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 06:36:53.279657 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 06:36:53.303831 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 06:36:53.326878 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 06:36:53.346574 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 06:36:53.347193 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 06:36:53.368384 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 06:36:53.389662 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 06:36:53.411877 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 06:36:53.432115 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 06:36:53.432672 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 06:36:53.453161 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 06:36:53.475134 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 06:36:53.497093 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 06:36:53.516896 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 06:36:53.517572 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 06:36:53.545516 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 06:36:53.567111 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 06:36:53.592815 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 06:36:53.613560 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 06:36:53.614141 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 06:36:53.634827 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 06:36:53.656548 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 06:36:53.679330 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 06:36:53.699327 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 06:36:53.699930 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 06:36:53.720351 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 06:36:53.742463 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 06:36:53.765481 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 06:36:53.785144 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:36:53.785670 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 06:36:53.806501 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:36:53.827747 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:36:53.854110 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:36:53.874460 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:36:53.875026 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 06:36:53.896634 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:36:53.919466 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:36:53.942131 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:36:53.964630 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 06:36:53.965184 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 06:36:53.985586 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 06:36:54.007235 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 06:36:54.029436 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 06:36:54.049559 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:36:54.050115 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 06:36:54.070785 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:36:54.091961 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 06:36:54.114424 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:36:54.137454 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:36:54.138178 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 06:36:54.159727 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:36:54.181423 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 06:36:54.203867 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:36:54.224621 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 06:36:54.225277 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 06:36:54.246921 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 06:36:54.273963 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 06:36:54.301031 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 06:36:54.320879 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:36:54.321443 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 06:36:54.346346 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:36:54.372689 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:36:54.399338 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:36:54.420363 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:36:54.420957 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 06:36:54.447633 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:36:54.473338 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:36:54.497561 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:36:54.517557 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:36:54.518139 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 06:36:54.549003 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:36:54.575940 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:36:54.600259 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:36:54.620089 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 06:36:54.620625 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 06:36:54.645100 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 06:36:54.671042 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 06:36:54.694693 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 06:36:54.714595 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 06:36:57.111013 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 06:36:57.111280 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 06:36:57.390801 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 06:36:57.544392 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 06:36:57.588247 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T06:36:57Z
I1011 06:36:57.605306 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T06:36:57Z
INFO:tensorflow:Graph was finalized.
I1011 06:36:58.509749 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 06:36:58.510475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:36:58.511079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 06:36:58.511144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 06:36:58.511206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 06:36:58.511231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 06:36:58.511248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 06:36:58.511270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 06:36:58.511290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 06:36:58.511309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 06:36:58.511395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:36:58.511909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:36:58.512340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 06:36:58.512392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 06:36:58.512406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 06:36:58.512415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 06:36:58.512515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:36:58.513010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 06:36:58.513458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-10680
I1011 06:36:58.514565 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-10680
INFO:tensorflow:Running local_init_op.
I1011 06:36:59.702965 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 06:36:59.769912 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 06:39:51.782923 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 06:42:36.443175 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 06:45:27.019447 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 06:48:17.267524 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 06:51:02.890101 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 06:53:47.836055 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 06:56:34.688575 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 06:59:21.729381 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 07:02:09.441246 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 07:04:56.854323 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 07:05:02.309084 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1747.14931s
I1011 07:06:04.754797 140235064469376 evaluation.py:273] Inference Time : 1747.14931s
INFO:tensorflow:Finished evaluation at 2020-10-11-07:06:04
I1011 07:06:04.755074 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-07:06:04
INFO:tensorflow:Saving dict for global step 10680: AP = 0.40416402, AP50 = 0.5110375, AP75 = 0.46368363, APl = 0.48193684, APm = 0.53014034, APs = 0.16729333, ARl = 0.83405024, ARm = 0.6485716, ARmax1 = 0.50331306, ARmax10 = 0.6982698, ARmax100 = 0.7360342, ARs = 0.29739627, box_loss = 0.0019421467, cls_loss = 0.22837386, global_step = 10680, loss = 0.4223139
I1011 07:06:04.755259 140235064469376 estimator.py:2063] Saving dict for global step 10680: AP = 0.40416402, AP50 = 0.5110375, AP75 = 0.46368363, APl = 0.48193684, APm = 0.53014034, APs = 0.16729333, ARl = 0.83405024, ARm = 0.6485716, ARmax1 = 0.50331306, ARmax10 = 0.6982698, ARmax100 = 0.7360342, ARs = 0.29739627, box_loss = 0.0019421467, cls_loss = 0.22837386, global_step = 10680, loss = 0.4223139
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10680: efficientdet-d0-finetune/model.ckpt-10680
I1011 07:06:05.777705 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 10680: efficientdet-d0-finetune/model.ckpt-10680
I1011 07:06:05.784366 140235064469376 utils.py:444] mv efficientdet-d0-finetune/archive to efficientdet-d0-finetune/backup
INFO:tensorflow:efficientdet-d0-finetune/archive/model.ckpt-10680 is not in all_model_checkpoint_paths. Manually adding it.
I1011 07:06:05.826071 140235064469376 checkpoint_management.py:102] efficientdet-d0-finetune/archive/model.ckpt-10680 is not in all_model_checkpoint_paths. Manually adding it.
I1011 07:06:05.826706 140235064469376 utils.py:464] Copying checkpoint efficientdet-d0-finetune/model.ckpt-10680 to efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 15.

   =====> Starting evaluation, epoch: 15.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.88s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=47.87s).
Accumulating evaluation results...
DONE (t=8.89s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.834
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 07:06:06.021269 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 07:06:06.034336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 07:06:06.068933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:06.069515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 07:06:06.069581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:06:06.072844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 07:06:06.075782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 07:06:06.076156: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 07:06:06.078141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 07:06:06.079445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 07:06:06.083969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:06:06.084096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:06.084698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:06.085242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 07:06:06.351760 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 07:06:06.739884 140235064469376 estimator.py:1162] Calling model_fn.
I1011 07:06:06.740193 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 07:06:06.745027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 07:06:06.745673 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 07:06:06.753987 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 07:06:06.992061 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:06:06.992979 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:06:06.993790 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:06:06.994557 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:06:06.995359 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:06:06.996209 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:06:06.997234 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:06:06.998039 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:06:06.999440 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:06:07.000320 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:06:07.001196 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:06:07.002008 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:06:07.002781 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:06:07.003594 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:06:07.004450 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:06:07.005311 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:06:07.006652 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:06:07.007470 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:06:07.008254 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:06:07.009109 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:06:07.009892 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:06:07.010653 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:06:07.011435 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:06:07.012212 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:06:07.121113 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 07:06:07.121693 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 07:06:07.151862 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 07:06:07.175152 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 07:06:07.201516 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 07:06:07.202132 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 07:06:07.233412 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 07:06:07.264667 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 07:06:07.395872 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 07:06:07.422554 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:06:07.423198 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 07:06:07.456079 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:06:07.487499 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 07:06:07.517606 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:06:07.551343 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:06:07.552260 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 07:06:07.580383 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:06:07.607635 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 07:06:07.630366 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:06:07.656400 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:06:07.656944 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 07:06:07.683636 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:06:07.711519 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 07:06:07.735831 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:06:07.762040 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:06:07.762606 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 07:06:07.788760 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:06:07.815594 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 07:06:07.837576 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:06:07.863230 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:06:07.863767 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 07:06:07.890907 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:06:07.918209 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:06:07.940467 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:06:07.967045 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:06:07.967578 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 07:06:07.994318 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:06:08.022592 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:06:08.049494 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:06:08.075903 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:06:08.076426 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 07:06:08.104071 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:06:08.133038 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:06:08.156103 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:06:08.182223 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:06:08.182761 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 07:06:08.210435 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:06:08.241771 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:06:08.265056 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:06:08.291385 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:06:08.291928 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 07:06:08.320256 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:06:08.348750 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:06:08.372465 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:06:08.398296 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:06:08.398993 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 07:06:08.426553 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:06:08.464254 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 07:06:08.487880 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:06:08.516778 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:06:08.517541 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 07:06:08.557505 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:06:08.590973 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:06:08.616945 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:06:08.649402 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:06:08.650030 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 07:06:08.683671 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:06:08.715294 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:06:08.739393 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:06:08.766443 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:06:08.767185 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 07:06:08.799000 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:06:08.831124 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:06:08.856245 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:06:08.882971 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:06:08.883497 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 07:06:08.914808 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:06:08.951474 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:06:08.977126 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:06:09.004894 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 07:06:11.942117 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 07:06:11.942436 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 07:06:12.202058 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 07:06:12.203944 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 07:06:12.205684 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 07:06:12.207202 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 07:06:12.208921 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 07:06:12.210438 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 07:06:12.213451 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 07:06:12.215125 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 07:06:19.938076 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 07:06:21.887313 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 07:06:21.887491 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 07:06:21.893469 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 07:06:21.893681 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 07:06:21.893871 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 07:06:21.894003 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 07:06:21.894095 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 07:06:21.899213 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 07:06:21.899351 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 07:06:23.487476 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 07:06:23.488560 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 07:06:27.721604 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 07:06:27.729450: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 07:06:27.729725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 07:06:27.729759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 07:06:27.834467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:27.835199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 07:06:27.835233: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 07:06:27.835475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:27.836076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 07:06:27.836131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:06:27.836192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 07:06:27.836218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 07:06:27.836236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 07:06:27.836258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 07:06:27.836279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 07:06:27.836317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:06:27.836407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:27.837036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:27.837545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 07:06:27.837643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:06:28.409310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 07:06:28.409361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 07:06:28.409373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 07:06:28.409564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:28.410214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:06:28.410733: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 07:06:28.410776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-10680
I1011 07:06:28.412828 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-10680
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 07:06:30.103418 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 07:06:30.934627 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 07:06:31.094649 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10680...
I1011 07:06:41.672326 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10680...
INFO:tensorflow:Saving checkpoints for 10680 into efficientdet-d0-finetune/model.ckpt.
I1011 07:06:41.685938 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10680 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10680...
I1011 07:06:44.254599 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10680...
2020-10-11 07:06:53.873625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:06:55.878643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.43046153, step = 10680
I1011 07:06:56.810858 140235064469376 basic_session_run_hooks.py:262] loss = 0.43046153, step = 10680
INFO:tensorflow:box_loss = 0.0015788964, cls_loss = 0.25468445, det_loss = 0.33362928, step = 10680
I1011 07:06:56.811355 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0015788964, cls_loss = 0.25468445, det_loss = 0.33362928, step = 10680
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10737 vs previous value: 10737. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 07:07:21.759322 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10737 vs previous value: 10737. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10780...
I1011 07:07:34.403458 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10780...
INFO:tensorflow:Saving checkpoints for 10780 into efficientdet-d0-finetune/model.ckpt.
I1011 07:07:34.403742 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10780 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 07:07:34.465558 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10780...
I1011 07:07:36.173724 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10780...
INFO:tensorflow:global_step/sec: 2.52006
I1011 07:07:36.491631 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.52006
INFO:tensorflow:loss = 0.41857672, step = 10780 (39.682 sec)
I1011 07:07:36.492768 140235064469376 basic_session_run_hooks.py:260] loss = 0.41857672, step = 10780 (39.682 sec)
INFO:tensorflow:box_loss = 0.0014203526, cls_loss = 0.25073242, det_loss = 0.32175004, step = 10780 (39.682 sec)
I1011 07:07:36.492969 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0014203526, cls_loss = 0.25073242, det_loss = 0.32175004, step = 10780 (39.682 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10880...
I1011 07:08:06.109833 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10880...
INFO:tensorflow:Saving checkpoints for 10880 into efficientdet-d0-finetune/model.ckpt.
I1011 07:08:06.110080 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10880 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10880...
I1011 07:08:07.820598 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10880...
INFO:tensorflow:global_step/sec: 3.16357
I1011 07:08:08.101512 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16357
INFO:tensorflow:loss = 0.4541791, step = 10880 (31.610 sec)
I1011 07:08:08.102674 140235064469376 basic_session_run_hooks.py:260] loss = 0.4541791, step = 10880 (31.610 sec)
INFO:tensorflow:box_loss = 0.00262398, cls_loss = 0.22615814, det_loss = 0.35735714, step = 10880 (31.610 sec)
I1011 07:08:08.103070 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.00262398, cls_loss = 0.22615814, det_loss = 0.35735714, step = 10880 (31.610 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10980...
I1011 07:08:37.475589 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 10980...
INFO:tensorflow:Saving checkpoints for 10980 into efficientdet-d0-finetune/model.ckpt.
I1011 07:08:37.475841 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 10980 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10980...
I1011 07:08:39.219466 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 10980...
INFO:tensorflow:global_step/sec: 3.17923
I1011 07:08:39.555670 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17923
INFO:tensorflow:loss = 0.320341, step = 10980 (31.454 sec)
I1011 07:08:39.556700 140235064469376 basic_session_run_hooks.py:260] loss = 0.320341, step = 10980 (31.454 sec)
INFO:tensorflow:box_loss = 0.0007653348, cls_loss = 0.18525696, det_loss = 0.22352369, step = 10980 (31.454 sec)
I1011 07:08:39.556932 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0007653348, cls_loss = 0.18525696, det_loss = 0.22352369, step = 10980 (31.454 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11080...
I1011 07:09:08.974773 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11080...
INFO:tensorflow:Saving checkpoints for 11080 into efficientdet-d0-finetune/model.ckpt.
I1011 07:09:08.975039 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11080 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11080...
I1011 07:09:10.678639 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11080...
INFO:tensorflow:global_step/sec: 3.18252
I1011 07:09:10.977334 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18252
INFO:tensorflow:loss = 0.4034555, step = 11080 (31.422 sec)
I1011 07:09:10.978678 140235064469376 basic_session_run_hooks.py:260] loss = 0.4034555, step = 11080 (31.422 sec)
INFO:tensorflow:box_loss = 0.001573064, cls_loss = 0.2279892, det_loss = 0.3066424, step = 11080 (31.422 sec)
I1011 07:09:10.979043 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.001573064, cls_loss = 0.2279892, det_loss = 0.3066424, step = 11080 (31.422 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11180...
I1011 07:09:40.547266 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11180...
INFO:tensorflow:Saving checkpoints for 11180 into efficientdet-d0-finetune/model.ckpt.
I1011 07:09:40.547548 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11180 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11180...
I1011 07:09:42.286190 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11180...
INFO:tensorflow:global_step/sec: 3.16631
I1011 07:09:42.559783 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16631
INFO:tensorflow:loss = 0.8370154, step = 11180 (31.582 sec)
I1011 07:09:42.560706 140235064469376 basic_session_run_hooks.py:260] loss = 0.8370154, step = 11180 (31.582 sec)
INFO:tensorflow:box_loss = 0.005860971, cls_loss = 0.4471588, det_loss = 0.74020743, step = 11180 (31.582 sec)
I1011 07:09:42.561015 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.005860971, cls_loss = 0.4471588, det_loss = 0.74020743, step = 11180 (31.582 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11280...
I1011 07:10:11.977579 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11280...
INFO:tensorflow:Saving checkpoints for 11280 into efficientdet-d0-finetune/model.ckpt.
I1011 07:10:11.978002 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11280 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11280...
I1011 07:10:13.705068 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11280...
INFO:tensorflow:global_step/sec: 3.17267
I1011 07:10:14.078988 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17267
INFO:tensorflow:loss = 0.5981849, step = 11280 (31.519 sec)
I1011 07:10:14.080156 140235064469376 basic_session_run_hooks.py:260] loss = 0.5981849, step = 11280 (31.519 sec)
INFO:tensorflow:box_loss = 0.0029552549, cls_loss = 0.35361862, det_loss = 0.50138134, step = 11280 (31.519 sec)
I1011 07:10:14.080366 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0029552549, cls_loss = 0.35361862, det_loss = 0.50138134, step = 11280 (31.519 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11380...
I1011 07:10:43.470811 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11380...
INFO:tensorflow:Saving checkpoints for 11380 into efficientdet-d0-finetune/model.ckpt.
I1011 07:10:43.471051 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11380 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11380...
I1011 07:10:45.164840 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11380...
INFO:tensorflow:global_step/sec: 3.18282
I1011 07:10:45.497662 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18282
INFO:tensorflow:loss = 0.42766452, step = 11380 (31.419 sec)
I1011 07:10:45.498729 140235064469376 basic_session_run_hooks.py:260] loss = 0.42766452, step = 11380 (31.419 sec)
INFO:tensorflow:box_loss = 0.002273109, cls_loss = 0.21720886, det_loss = 0.3308643, step = 11380 (31.419 sec)
I1011 07:10:45.498957 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.002273109, cls_loss = 0.21720886, det_loss = 0.3308643, step = 11380 (31.419 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11392...
I1011 07:10:48.864196 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11392...
INFO:tensorflow:Saving checkpoints for 11392 into efficientdet-d0-finetune/model.ckpt.
I1011 07:10:48.864413 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11392 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11392...
I1011 07:10:50.553631 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11392...
INFO:tensorflow:Loss for final step: 0.55387473.
I1011 07:10:50.914863 140235064469376 estimator.py:350] Loss for final step: 0.55387473.
INFO:tensorflow:Calling model_fn.
I1011 07:10:51.398951 140235064469376 estimator.py:1162] Calling model_fn.
I1011 07:10:51.399274 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 07:10:51.403048 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 07:10:51.631867 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:10:51.632687 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:10:51.633476 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:10:51.634253 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:10:51.635025 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:10:51.635905 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:10:51.636699 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:10:51.637515 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:10:51.638652 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:10:51.639409 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:10:51.640172 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:10:51.641057 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:10:51.641815 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:10:51.642574 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:10:51.643384 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:10:51.644141 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:10:51.645445 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:10:51.646262 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:10:51.647084 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:10:51.648083 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:10:51.649043 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:10:51.649813 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:10:51.650572 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:10:51.651380 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:10:51.937327 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 07:10:51.937885 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 07:10:51.958918 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 07:10:51.981673 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 07:10:52.003660 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 07:10:52.004316 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 07:10:52.024513 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 07:10:52.045890 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 07:10:52.068248 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 07:10:52.087422 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:10:52.088083 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 07:10:52.108677 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:10:52.130606 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 07:10:52.156475 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:10:52.176589 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:10:52.177186 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 07:10:52.203917 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:10:52.228351 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 07:10:52.253654 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:10:52.275975 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:10:52.276541 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 07:10:52.299888 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:10:52.323796 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 07:10:52.346004 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:10:52.366328 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:10:52.366921 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 07:10:52.386931 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:10:52.410326 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 07:10:52.432281 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:10:52.452549 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:10:52.453127 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 07:10:52.474694 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:10:52.496033 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:10:52.518661 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:10:52.539479 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:10:52.540022 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 07:10:52.566640 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:10:52.591283 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:10:52.616768 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:10:52.636609 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:10:52.637185 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 07:10:52.657967 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:10:52.679649 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:10:52.702219 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:10:52.721622 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:10:52.722159 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 07:10:52.742928 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:10:52.765052 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:10:52.787304 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:10:52.807889 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:10:52.808431 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 07:10:52.828779 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:10:52.855227 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:10:52.881772 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:10:52.906105 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:10:52.906779 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 07:10:52.927800 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:10:52.949194 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 07:10:52.972132 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:10:52.992491 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:10:52.993172 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 07:10:53.020448 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:10:53.047891 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:10:53.073457 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:10:53.096181 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:10:53.096898 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 07:10:53.123441 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:10:53.155023 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:10:53.180674 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:10:53.202484 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:10:53.203213 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 07:10:53.229484 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:10:53.255564 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:10:53.278855 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:10:53.298857 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:10:53.299384 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 07:10:53.324126 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:10:53.350921 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:10:53.375603 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:10:53.395162 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 07:10:55.756376 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 07:10:55.756669 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 07:10:56.052058 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 07:10:56.208085 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 07:10:56.247576 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T07:10:56Z
I1011 07:10:56.262524 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T07:10:56Z
INFO:tensorflow:Graph was finalized.
I1011 07:10:57.144210 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 07:10:57.144967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:10:57.145554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 07:10:57.145622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:10:57.145703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 07:10:57.145770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 07:10:57.145796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 07:10:57.145816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 07:10:57.145837: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 07:10:57.145859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:10:57.145967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:10:57.146455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:10:57.146876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 07:10:57.146934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 07:10:57.146953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 07:10:57.146962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 07:10:57.147079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:10:57.147620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:10:57.148060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-11392
I1011 07:10:57.149088 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-11392
INFO:tensorflow:Running local_init_op.
I1011 07:10:58.313026 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 07:10:58.378052 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 07:13:51.179647 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 07:16:35.920661 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 07:19:27.988525 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 07:22:18.053280 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 07:25:06.216899 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 07:27:54.403069 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 07:30:44.905047 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 07:33:35.831595 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 07:36:22.705274 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 07:39:10.631766 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 07:39:16.019908 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1761.96275s
I1011 07:40:18.225435 140235064469376 evaluation.py:273] Inference Time : 1761.96275s
INFO:tensorflow:Finished evaluation at 2020-10-11-07:40:18
I1011 07:40:18.225684 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-07:40:18
INFO:tensorflow:Saving dict for global step 11392: AP = 0.3948608, AP50 = 0.4980371, AP75 = 0.45190513, APl = 0.47039852, APm = 0.53734547, APs = 0.17002799, ARl = 0.8373683, ARm = 0.658049, ARmax1 = 0.50626755, ARmax10 = 0.70223755, ARmax100 = 0.74022806, ARs = 0.29814667, box_loss = 0.0019101268, cls_loss = 0.22460955, global_step = 11392, loss = 0.41691568
I1011 07:40:18.225879 140235064469376 estimator.py:2063] Saving dict for global step 11392: AP = 0.3948608, AP50 = 0.4980371, AP75 = 0.45190513, APl = 0.47039852, APm = 0.53734547, APs = 0.17002799, ARl = 0.8373683, ARm = 0.658049, ARmax1 = 0.50626755, ARmax10 = 0.70223755, ARmax100 = 0.74022806, ARs = 0.29814667, box_loss = 0.0019101268, cls_loss = 0.22460955, global_step = 11392, loss = 0.41691568
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11392: efficientdet-d0-finetune/model.ckpt-11392
I1011 07:40:19.183461 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 11392: efficientdet-d0-finetune/model.ckpt-11392
I1011 07:40:19.185922 140235064469376 utils.py:428] Ckpt 0.39486080408096313 is worse than 0.404164

   =====> Starting training, epoch: 16.

   =====> Starting evaluation, epoch: 16.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.92s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=48.02s).
Accumulating evaluation results...
DONE (t=8.52s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.702
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 07:40:19.383202 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 07:40:19.395404: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 07:40:19.431754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:19.432318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 07:40:19.432364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:40:19.435662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 07:40:19.438485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 07:40:19.438884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 07:40:19.440929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 07:40:19.442094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 07:40:19.446407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:40:19.446534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:19.447157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:19.447702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 07:40:19.702740 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 07:40:20.067386 140235064469376 estimator.py:1162] Calling model_fn.
I1011 07:40:20.067698 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 07:40:20.072459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 07:40:20.073118 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 07:40:20.081365 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 07:40:20.327245 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:40:20.328251 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:40:20.329071 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:40:20.329851 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:40:20.330657 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:40:20.331484 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:40:20.332263 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:40:20.333062 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:40:20.334296 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:40:20.335076 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:40:20.335921 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:40:20.336701 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:40:20.337494 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:40:20.338336 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:40:20.339128 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:40:20.339926 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:40:20.341197 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:40:20.341971 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:40:20.342755 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:40:20.343586 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:40:20.344358 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:40:20.345151 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:40:20.345942 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:40:20.346726 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:40:20.441431 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 07:40:20.441999 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 07:40:20.471548 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 07:40:20.495746 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 07:40:20.523668 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 07:40:20.524255 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 07:40:20.552524 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 07:40:20.582000 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 07:40:20.733915 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 07:40:20.762144 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:40:20.762751 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 07:40:20.791064 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:40:20.826311 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 07:40:20.850848 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:40:20.879318 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:40:20.879945 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 07:40:20.908199 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:40:20.937234 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 07:40:20.961747 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:40:20.989289 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:40:20.989890 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 07:40:21.016214 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:40:21.051543 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 07:40:21.077224 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:40:21.107493 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:40:21.108164 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 07:40:21.138693 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:40:21.173325 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 07:40:21.197155 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:40:21.229358 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:40:21.229930 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 07:40:21.256758 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:40:21.283940 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:40:21.305954 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:40:21.334771 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:40:21.335370 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 07:40:21.362480 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:40:21.389653 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:40:21.412132 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:40:21.438556 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:40:21.439147 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 07:40:21.465763 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:40:21.493027 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:40:21.515262 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:40:21.541195 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:40:21.541727 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 07:40:21.568378 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:40:21.596367 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:40:21.618901 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:40:21.648060 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:40:21.648578 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 07:40:21.675116 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:40:21.702472 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:40:21.726084 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:40:21.752089 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:40:21.752670 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 07:40:21.779447 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:40:21.806469 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 07:40:21.831826 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:40:21.863963 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:40:21.864606 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 07:40:21.895444 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:40:21.931124 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:40:21.954968 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:40:21.980856 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:40:21.981417 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 07:40:22.012130 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:40:22.043107 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:40:22.066684 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:40:22.092921 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:40:22.093453 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 07:40:22.124287 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:40:22.156341 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:40:22.179955 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:40:22.205698 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:40:22.206265 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 07:40:22.249316 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:40:22.285786 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:40:22.312622 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:40:22.340492 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 07:40:25.154994 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 07:40:25.155319 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 07:40:25.394342 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 07:40:25.396001 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 07:40:25.397516 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 07:40:25.398931 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 07:40:25.400475 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 07:40:25.401978 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 07:40:25.404607 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 07:40:25.406116 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 07:40:33.150510 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 07:40:35.044456 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 07:40:35.044630 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 07:40:35.050276 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 07:40:35.050410 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 07:40:35.050553 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 07:40:35.050658 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 07:40:35.050768 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 07:40:35.055551 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 07:40:35.055677 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 07:40:36.608864 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 07:40:36.610034 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 07:40:40.741416 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 07:40:40.748271: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 07:40:40.748501: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 07:40:40.748531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 07:40:40.847037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:40.847815: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 07:40:40.847843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 07:40:40.848036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:40.848565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 07:40:40.848607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:40:40.848649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 07:40:40.848672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 07:40:40.848687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 07:40:40.848702: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 07:40:40.848737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 07:40:40.848755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:40:40.848824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:40.849363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:40.849866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 07:40:40.849958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:40:41.420088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 07:40:41.420146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 07:40:41.420157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 07:40:41.420358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:41.420996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:40:41.421520: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 07:40:41.421562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-11392
I1011 07:40:41.423833 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-11392
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 07:40:43.064684 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 07:40:44.007572 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 07:40:44.168632 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11392...
I1011 07:40:54.679504 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11392...
INFO:tensorflow:Saving checkpoints for 11392 into efficientdet-d0-finetune/model.ckpt.
I1011 07:40:54.691913 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11392 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11392...
I1011 07:40:57.252273 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11392...
2020-10-11 07:41:06.870661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:41:08.863042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.49338797, step = 11392
I1011 07:41:09.799638 140235064469376 basic_session_run_hooks.py:262] loss = 0.49338797, step = 11392
INFO:tensorflow:box_loss = 0.0027315654, cls_loss = 0.26000977, det_loss = 0.39658803, step = 11392
I1011 07:41:09.800114 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0027315654, cls_loss = 0.26000977, det_loss = 0.39658803, step = 11392
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11492...
I1011 07:41:47.114546 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11492...
INFO:tensorflow:Saving checkpoints for 11492 into efficientdet-d0-finetune/model.ckpt.
I1011 07:41:47.114902 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11492 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 07:41:47.173280 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11492...
I1011 07:41:48.840371 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11492...
INFO:tensorflow:global_step/sec: 2.54055
I1011 07:41:49.160369 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.54055
INFO:tensorflow:loss = 0.5609817, step = 11492 (39.362 sec)
I1011 07:41:49.161399 140235064469376 basic_session_run_hooks.py:260] loss = 0.5609817, step = 11492 (39.362 sec)
INFO:tensorflow:box_loss = 0.0034178204, cls_loss = 0.29329395, det_loss = 0.464185, step = 11492 (39.362 sec)
I1011 07:41:49.161615 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0034178204, cls_loss = 0.29329395, det_loss = 0.464185, step = 11492 (39.362 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11592...
I1011 07:42:18.384804 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11592...
INFO:tensorflow:Saving checkpoints for 11592 into efficientdet-d0-finetune/model.ckpt.
I1011 07:42:18.385061 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11592 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11592...
I1011 07:42:20.095805 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11592...
INFO:tensorflow:global_step/sec: 3.19853
I1011 07:42:20.424664 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19853
INFO:tensorflow:loss = 0.4599081, step = 11592 (31.265 sec)
I1011 07:42:20.425975 140235064469376 basic_session_run_hooks.py:260] loss = 0.4599081, step = 11592 (31.265 sec)
INFO:tensorflow:box_loss = 0.002471794, cls_loss = 0.23952484, det_loss = 0.36311454, step = 11592 (31.265 sec)
I1011 07:42:20.426165 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.002471794, cls_loss = 0.23952484, det_loss = 0.36311454, step = 11592 (31.265 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11692...
I1011 07:42:49.727791 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11692...
INFO:tensorflow:Saving checkpoints for 11692 into efficientdet-d0-finetune/model.ckpt.
I1011 07:42:49.728026 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11692 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11692...
I1011 07:42:51.436565 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11692...
INFO:tensorflow:global_step/sec: 3.19232
I1011 07:42:51.749869 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19232
INFO:tensorflow:loss = 0.42884853, step = 11692 (31.325 sec)
I1011 07:42:51.750931 140235064469376 basic_session_run_hooks.py:260] loss = 0.42884853, step = 11692 (31.325 sec)
INFO:tensorflow:box_loss = 0.0016092737, cls_loss = 0.25159454, det_loss = 0.33205825, step = 11692 (31.325 sec)
I1011 07:42:51.751133 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0016092737, cls_loss = 0.25159454, det_loss = 0.33205825, step = 11692 (31.325 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11792...
I1011 07:43:20.872450 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11792...
INFO:tensorflow:Saving checkpoints for 11792 into efficientdet-d0-finetune/model.ckpt.
I1011 07:43:20.872725 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11792 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11792...
I1011 07:43:22.621303 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11792...
INFO:tensorflow:global_step/sec: 3.21111
I1011 07:43:22.891696 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.21111
INFO:tensorflow:loss = 0.45838696, step = 11792 (31.142 sec)
I1011 07:43:22.892658 140235064469376 basic_session_run_hooks.py:260] loss = 0.45838696, step = 11792 (31.142 sec)
INFO:tensorflow:box_loss = 0.0020313333, cls_loss = 0.26003265, det_loss = 0.3615993, step = 11792 (31.142 sec)
I1011 07:43:22.892878 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0020313333, cls_loss = 0.26003265, det_loss = 0.3615993, step = 11792 (31.142 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11892...
I1011 07:43:52.469886 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11892...
INFO:tensorflow:Saving checkpoints for 11892 into efficientdet-d0-finetune/model.ckpt.
I1011 07:43:52.470117 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11892 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11892...
I1011 07:43:54.134328 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11892...
INFO:tensorflow:global_step/sec: 3.17317
I1011 07:43:54.405965 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17317
INFO:tensorflow:loss = 0.36555448, step = 11892 (31.514 sec)
I1011 07:43:54.406908 140235064469376 basic_session_run_hooks.py:260] loss = 0.36555448, step = 11892 (31.514 sec)
INFO:tensorflow:box_loss = 0.0014047369, cls_loss = 0.1985321, det_loss = 0.26876897, step = 11892 (31.514 sec)
I1011 07:43:54.407116 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0014047369, cls_loss = 0.1985321, det_loss = 0.26876897, step = 11892 (31.514 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11992...
I1011 07:44:23.546674 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 11992...
INFO:tensorflow:Saving checkpoints for 11992 into efficientdet-d0-finetune/model.ckpt.
I1011 07:44:23.546960 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 11992 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11992...
I1011 07:44:25.244030 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 11992...
INFO:tensorflow:global_step/sec: 3.21297
I1011 07:44:25.529865 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.21297
INFO:tensorflow:loss = 0.6398894, step = 11992 (31.124 sec)
I1011 07:44:25.530824 140235064469376 basic_session_run_hooks.py:260] loss = 0.6398894, step = 11992 (31.124 sec)
INFO:tensorflow:box_loss = 0.0035808603, cls_loss = 0.36406326, det_loss = 0.54310626, step = 11992 (31.124 sec)
I1011 07:44:25.531017 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0035808603, cls_loss = 0.36406326, det_loss = 0.54310626, step = 11992 (31.124 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12092...
I1011 07:44:54.176927 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12092...
INFO:tensorflow:Saving checkpoints for 12092 into efficientdet-d0-finetune/model.ckpt.
I1011 07:44:54.177190 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12092 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12092...
I1011 07:44:55.902042 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12092...
INFO:tensorflow:global_step/sec: 3.25129
I1011 07:44:56.286867 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.25129
INFO:tensorflow:loss = 0.54556787, step = 12092 (30.757 sec)
I1011 07:44:56.287826 140235064469376 basic_session_run_hooks.py:260] loss = 0.54556787, step = 12092 (30.757 sec)
INFO:tensorflow:box_loss = 0.0024152207, cls_loss = 0.32802582, det_loss = 0.44878685, step = 12092 (30.757 sec)
I1011 07:44:56.288029 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0024152207, cls_loss = 0.32802582, det_loss = 0.44878685, step = 12092 (30.757 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12104...
I1011 07:44:59.572584 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12104...
INFO:tensorflow:Saving checkpoints for 12104 into efficientdet-d0-finetune/model.ckpt.
I1011 07:44:59.572996 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12104 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12104...
I1011 07:45:01.329180 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12104...
INFO:tensorflow:Loss for final step: 0.42427987.
I1011 07:45:01.703286 140235064469376 estimator.py:350] Loss for final step: 0.42427987.
INFO:tensorflow:Calling model_fn.
I1011 07:45:02.219794 140235064469376 estimator.py:1162] Calling model_fn.
I1011 07:45:02.220176 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 07:45:02.223805 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 07:45:02.450323 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:45:02.451198 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:45:02.452016 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:45:02.452810 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:45:02.453759 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:45:02.454603 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:45:02.455383 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:45:02.456170 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:45:02.457351 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:45:02.458147 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:45:02.458973 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:45:02.459975 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:45:02.460879 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:45:02.461802 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:45:02.462632 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:45:02.463430 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:45:02.464640 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 07:45:02.465473 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 07:45:02.466319 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 07:45:02.467177 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 07:45:02.468341 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 07:45:02.469517 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 07:45:02.470669 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 07:45:02.471942 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 07:45:02.798274 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 07:45:02.799145 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 07:45:02.821575 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 07:45:02.843858 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 07:45:02.866327 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 07:45:02.866954 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 07:45:02.888018 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 07:45:02.909393 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 07:45:02.931867 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 07:45:02.951887 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:45:02.952437 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 07:45:02.973071 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:45:02.994400 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 07:45:03.017107 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:45:03.037132 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 07:45:03.037754 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 07:45:03.060662 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 07:45:03.088312 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 07:45:03.117568 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 07:45:03.145097 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:45:03.145900 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 07:45:03.175010 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:45:03.206100 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 07:45:03.238744 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:45:03.263400 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 07:45:03.264135 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 07:45:03.285325 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 07:45:03.306938 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 07:45:03.329751 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 07:45:03.349993 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:45:03.350580 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 07:45:03.371419 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:45:03.395919 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:45:03.419288 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:45:03.440280 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:45:03.440932 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 07:45:03.463627 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:45:03.485166 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:45:03.507730 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:45:03.528537 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 07:45:03.529173 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 07:45:03.555701 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 07:45:03.581985 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 07:45:03.605253 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 07:45:03.625204 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:45:03.625787 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 07:45:03.646997 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:45:03.668902 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:45:03.692158 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:45:03.712927 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:45:03.713501 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 07:45:03.734537 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:45:03.756550 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 07:45:03.779989 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:45:03.804517 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 07:45:03.805176 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 07:45:03.827174 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 07:45:03.850845 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 07:45:03.873937 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 07:45:03.894226 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:45:03.894805 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 07:45:03.919598 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:45:03.945455 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:45:03.973897 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:45:03.999511 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:45:04.000218 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 07:45:04.025324 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:45:04.051173 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:45:04.075191 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:45:04.100049 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:45:04.100945 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 07:45:04.131806 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:45:04.163438 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:45:04.191134 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:45:04.216810 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 07:45:04.217472 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 07:45:04.251831 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 07:45:04.277914 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 07:45:04.302342 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 07:45:04.322263 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 07:45:06.677564 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 07:45:06.677839 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 07:45:06.947459 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 07:45:07.099822 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 07:45:07.139823 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T07:45:07Z
I1011 07:45:07.155583 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T07:45:07Z
INFO:tensorflow:Graph was finalized.
I1011 07:45:08.043829 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 07:45:08.044539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:45:08.045126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 07:45:08.045192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 07:45:08.045261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 07:45:08.045286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 07:45:08.045308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 07:45:08.045334: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 07:45:08.045355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 07:45:08.045379: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 07:45:08.045469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:45:08.046060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:45:08.046554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 07:45:08.046611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 07:45:08.046643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 07:45:08.046652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 07:45:08.046813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:45:08.047324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 07:45:08.047813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-12104
I1011 07:45:08.048890 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-12104
INFO:tensorflow:Running local_init_op.
I1011 07:45:09.244330 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 07:45:09.306483 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 07:48:00.057937 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 07:50:45.555662 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 07:53:36.701575 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 07:56:29.425899 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 07:59:16.792197 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 08:02:03.230496 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 08:04:51.316466 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 08:07:41.138234 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 08:10:31.461209 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 08:13:22.070246 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 08:13:27.656636 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1763.38624s
I1011 08:14:30.542051 140235064469376 evaluation.py:273] Inference Time : 1763.38624s
INFO:tensorflow:Finished evaluation at 2020-10-11-08:14:30
I1011 08:14:30.542486 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-08:14:30
INFO:tensorflow:Saving dict for global step 12104: AP = 0.40696642, AP50 = 0.5121155, AP75 = 0.46523556, APl = 0.4839267, APm = 0.5410127, APs = 0.17169194, ARl = 0.8391627, ARm = 0.6578212, ARmax1 = 0.50801283, ARmax10 = 0.7049993, ARmax100 = 0.7417062, ARs = 0.29807085, box_loss = 0.0018799684, cls_loss = 0.22145659, global_step = 12104, loss = 0.41223547
I1011 08:14:30.542742 140235064469376 estimator.py:2063] Saving dict for global step 12104: AP = 0.40696642, AP50 = 0.5121155, AP75 = 0.46523556, APl = 0.4839267, APm = 0.5410127, APs = 0.17169194, ARl = 0.8391627, ARm = 0.6578212, ARmax1 = 0.50801283, ARmax10 = 0.7049993, ARmax100 = 0.7417062, ARs = 0.29807085, box_loss = 0.0018799684, cls_loss = 0.22145659, global_step = 12104, loss = 0.41223547
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12104: efficientdet-d0-finetune/model.ckpt-12104
I1011 08:14:31.596188 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 12104: efficientdet-d0-finetune/model.ckpt-12104
I1011 08:14:31.604255 140235064469376 utils.py:444] mv efficientdet-d0-finetune/archive to efficientdet-d0-finetune/backup
INFO:tensorflow:efficientdet-d0-finetune/archive/model.ckpt-12104 is not in all_model_checkpoint_paths. Manually adding it.
I1011 08:14:31.646584 140235064469376 checkpoint_management.py:102] efficientdet-d0-finetune/archive/model.ckpt-12104 is not in all_model_checkpoint_paths. Manually adding it.
I1011 08:14:31.647292 140235064469376 utils.py:464] Copying checkpoint efficientdet-d0-finetune/model.ckpt-12104 to efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 17.

   =====> Starting evaluation, epoch: 17.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.97s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=48.35s).
Accumulating evaluation results...
DONE (t=8.80s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.839
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 08:14:31.844533 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 08:14:31.858702: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 08:14:31.897508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:31.898123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 08:14:31.898178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:14:31.901460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 08:14:31.904331: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 08:14:31.904756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 08:14:31.906932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 08:14:31.908211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 08:14:31.912640: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:14:31.912795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:31.913381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:31.913922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 08:14:32.201396 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 08:14:32.573208 140235064469376 estimator.py:1162] Calling model_fn.
I1011 08:14:32.573549 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 08:14:32.578229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 08:14:32.578898 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 08:14:32.587409 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 08:14:32.821605 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:14:32.822551 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:14:32.823404 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:14:32.824199 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:14:32.824984 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:14:32.825736 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:14:32.826500 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:14:32.827312 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:14:32.828479 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:14:32.829227 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:14:32.829978 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:14:32.830784 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:14:32.831590 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:14:32.832384 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:14:32.833257 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:14:32.834040 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:14:32.835319 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:14:32.836097 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:14:32.836894 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:14:32.837759 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:14:32.838518 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:14:32.839399 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:14:32.840658 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:14:32.841845 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:14:32.944799 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 08:14:32.945361 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 08:14:32.973119 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 08:14:32.995083 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 08:14:33.021400 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 08:14:33.021974 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 08:14:33.055723 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 08:14:33.091656 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 08:14:33.229078 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 08:14:33.256817 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:14:33.257412 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 08:14:33.284283 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:14:33.312152 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 08:14:33.334953 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:14:33.367729 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:14:33.368340 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 08:14:33.397237 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:14:33.425472 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 08:14:33.448223 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:14:33.475130 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:14:33.475668 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 08:14:33.501977 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:14:33.529834 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 08:14:33.552736 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:14:33.579392 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:14:33.580002 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 08:14:33.606594 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:14:33.633821 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 08:14:33.659318 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:14:33.689316 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:14:33.689899 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 08:14:33.720133 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:14:33.751108 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:14:33.773959 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:14:33.800546 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:14:33.801187 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 08:14:33.828661 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:14:33.857408 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:14:33.881384 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:14:33.913112 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:14:33.913648 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 08:14:33.940588 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:14:33.976579 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:14:34.003097 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:14:34.033502 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:14:34.034163 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 08:14:34.063452 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:14:34.096887 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:14:34.122302 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:14:34.149205 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:14:34.149827 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 08:14:34.180136 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:14:34.208029 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:14:34.230695 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:14:34.261529 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:14:34.262216 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 08:14:34.289819 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:14:34.318243 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 08:14:34.341486 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:14:34.370388 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:14:34.371097 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 08:14:34.403951 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:14:34.436592 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:14:34.464427 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:14:34.494784 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:14:34.495548 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 08:14:34.528425 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:14:34.560734 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:14:34.587155 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:14:34.613957 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:14:34.614511 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 08:14:34.646233 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:14:34.678454 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:14:34.702461 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:14:34.729399 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:14:34.729985 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 08:14:34.763817 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:14:34.796242 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:14:34.820869 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:14:34.847580 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 08:14:37.786447 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 08:14:37.786785 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 08:14:38.029404 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 08:14:38.031038 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 08:14:38.032444 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 08:14:38.033790 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 08:14:38.035156 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 08:14:38.036541 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 08:14:38.039488 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 08:14:38.041335 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 08:14:45.919449 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 08:14:47.800644 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 08:14:47.800839 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 08:14:47.806832 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 08:14:47.806985 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 08:14:47.807078 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 08:14:47.807177 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 08:14:47.807272 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 08:14:47.812025 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 08:14:47.812143 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 08:14:49.365126 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 08:14:49.366413 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 08:14:53.601875 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 08:14:53.608677: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 08:14:53.608934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 08:14:53.608981: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 08:14:53.707185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:53.707891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 08:14:53.707923: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 08:14:53.708147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:53.708682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 08:14:53.708751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:14:53.708805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 08:14:53.708836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 08:14:53.708863: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 08:14:53.708888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 08:14:53.708913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 08:14:53.708939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:14:53.709027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:53.709595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:53.710114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 08:14:53.710214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:14:54.285625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 08:14:54.285681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 08:14:54.285692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 08:14:54.285899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:54.286508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:14:54.287053: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 08:14:54.287098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-12104
I1011 08:14:54.289179 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-12104
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 08:14:55.952933 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 08:14:56.820283 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 08:14:56.973509 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12104...
I1011 08:15:07.716563 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12104...
INFO:tensorflow:Saving checkpoints for 12104 into efficientdet-d0-finetune/model.ckpt.
I1011 08:15:07.730071 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12104 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12104...
I1011 08:15:10.313627 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12104...
2020-10-11 08:15:19.859427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:15:21.852874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.42220435, step = 12104
I1011 08:15:22.868677 140235064469376 basic_session_run_hooks.py:262] loss = 0.42220435, step = 12104
INFO:tensorflow:box_loss = 0.001803881, cls_loss = 0.23522949, det_loss = 0.32542354, step = 12104
I1011 08:15:22.869467 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.001803881, cls_loss = 0.23522949, det_loss = 0.32542354, step = 12104
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12204...
I1011 08:16:00.506228 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12204...
INFO:tensorflow:Saving checkpoints for 12204 into efficientdet-d0-finetune/model.ckpt.
I1011 08:16:00.506536 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12204 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 08:16:00.569529 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12204...
I1011 08:16:02.292663 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12204...
INFO:tensorflow:global_step/sec: 2.51434
I1011 08:16:02.639663 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.51434
INFO:tensorflow:loss = 0.42695454, step = 12204 (39.772 sec)
I1011 08:16:02.640909 140235064469376 basic_session_run_hooks.py:260] loss = 0.42695454, step = 12204 (39.772 sec)
INFO:tensorflow:box_loss = 0.0019039488, cls_loss = 0.23497772, det_loss = 0.33017516, step = 12204 (39.772 sec)
I1011 08:16:02.641132 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0019039488, cls_loss = 0.23497772, det_loss = 0.33017516, step = 12204 (39.772 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12304...
I1011 08:16:32.406509 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12304...
INFO:tensorflow:Saving checkpoints for 12304 into efficientdet-d0-finetune/model.ckpt.
I1011 08:16:32.406788 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12304 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12304...
I1011 08:16:34.106363 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12304...
INFO:tensorflow:global_step/sec: 3.14562
I1011 08:16:34.429887 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.14562
INFO:tensorflow:loss = 0.2997518, step = 12304 (31.790 sec)
I1011 08:16:34.430794 140235064469376 basic_session_run_hooks.py:260] loss = 0.2997518, step = 12304 (31.790 sec)
INFO:tensorflow:box_loss = 0.0005757429, cls_loss = 0.1741867, det_loss = 0.20297386, step = 12304 (31.790 sec)
I1011 08:16:34.431100 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0005757429, cls_loss = 0.1741867, det_loss = 0.20297386, step = 12304 (31.790 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12404...
I1011 08:17:03.782659 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12404...
INFO:tensorflow:Saving checkpoints for 12404 into efficientdet-d0-finetune/model.ckpt.
I1011 08:17:03.782992 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12404 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12404...
I1011 08:17:05.588346 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12404...
INFO:tensorflow:global_step/sec: 3.17475
I1011 08:17:05.928436 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17475
INFO:tensorflow:loss = 0.46267408, step = 12404 (31.499 sec)
I1011 08:17:05.929527 140235064469376 basic_session_run_hooks.py:260] loss = 0.46267408, step = 12404 (31.499 sec)
INFO:tensorflow:box_loss = 0.0023527376, cls_loss = 0.2482605, det_loss = 0.3658974, step = 12404 (31.499 sec)
I1011 08:17:05.929744 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0023527376, cls_loss = 0.2482605, det_loss = 0.3658974, step = 12404 (31.499 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12504...
I1011 08:17:34.972703 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12504...
INFO:tensorflow:Saving checkpoints for 12504 into efficientdet-d0-finetune/model.ckpt.
I1011 08:17:34.973060 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12504 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12504...
I1011 08:17:36.711697 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12504...
INFO:tensorflow:global_step/sec: 3.21112
I1011 08:17:37.070252 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.21112
INFO:tensorflow:loss = 0.4512076, step = 12504 (31.142 sec)
I1011 08:17:37.071525 140235064469376 basic_session_run_hooks.py:260] loss = 0.4512076, step = 12504 (31.142 sec)
INFO:tensorflow:box_loss = 0.0024595016, cls_loss = 0.23145676, det_loss = 0.3544318, step = 12504 (31.142 sec)
I1011 08:17:37.071771 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0024595016, cls_loss = 0.23145676, det_loss = 0.3544318, step = 12504 (31.142 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12604...
I1011 08:18:06.583096 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12604...
INFO:tensorflow:Saving checkpoints for 12604 into efficientdet-d0-finetune/model.ckpt.
I1011 08:18:06.583355 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12604 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12604...
I1011 08:18:08.303077 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12604...
INFO:tensorflow:global_step/sec: 3.16863
I1011 08:18:08.629622 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16863
INFO:tensorflow:loss = 0.49064165, step = 12604 (31.559 sec)
I1011 08:18:08.630653 140235064469376 basic_session_run_hooks.py:260] loss = 0.49064165, step = 12604 (31.559 sec)
INFO:tensorflow:box_loss = 0.0025898796, cls_loss = 0.26437283, det_loss = 0.39386684, step = 12604 (31.559 sec)
I1011 08:18:08.630974 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0025898796, cls_loss = 0.26437283, det_loss = 0.39386684, step = 12604 (31.559 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12704...
I1011 08:18:38.011612 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12704...
INFO:tensorflow:Saving checkpoints for 12704 into efficientdet-d0-finetune/model.ckpt.
I1011 08:18:38.011856 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12704 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12704...
I1011 08:18:39.838490 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12704...
INFO:tensorflow:global_step/sec: 3.16617
I1011 08:18:40.213491 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16617
INFO:tensorflow:loss = 0.4703758, step = 12704 (31.584 sec)
I1011 08:18:40.214523 140235064469376 basic_session_run_hooks.py:260] loss = 0.4703758, step = 12704 (31.584 sec)
INFO:tensorflow:box_loss = 0.0017116885, cls_loss = 0.28801727, det_loss = 0.37360168, step = 12704 (31.584 sec)
I1011 08:18:40.214920 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0017116885, cls_loss = 0.28801727, det_loss = 0.37360168, step = 12704 (31.584 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12804...
I1011 08:19:09.483794 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12804...
INFO:tensorflow:Saving checkpoints for 12804 into efficientdet-d0-finetune/model.ckpt.
I1011 08:19:09.484061 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12804 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12804...
I1011 08:19:11.253487 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12804...
INFO:tensorflow:global_step/sec: 3.18493
I1011 08:19:11.611392 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.18493
INFO:tensorflow:loss = 0.4874682, step = 12804 (31.398 sec)
I1011 08:19:11.612442 140235064469376 basic_session_run_hooks.py:260] loss = 0.4874682, step = 12804 (31.398 sec)
INFO:tensorflow:box_loss = 0.002500704, cls_loss = 0.26565933, det_loss = 0.39069453, step = 12804 (31.398 sec)
I1011 08:19:11.612647 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.002500704, cls_loss = 0.26565933, det_loss = 0.39069453, step = 12804 (31.398 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12816...
I1011 08:19:14.852364 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12816...
INFO:tensorflow:Saving checkpoints for 12816 into efficientdet-d0-finetune/model.ckpt.
I1011 08:19:14.852620 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12816 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12816...
I1011 08:19:16.589132 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12816...
INFO:tensorflow:Loss for final step: 0.46214813.
I1011 08:19:16.964805 140235064469376 estimator.py:350] Loss for final step: 0.46214813.
INFO:tensorflow:Calling model_fn.
I1011 08:19:17.483145 140235064469376 estimator.py:1162] Calling model_fn.
I1011 08:19:17.483458 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 08:19:17.487259 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 08:19:17.717243 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:19:17.718104 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:19:17.718920 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:19:17.719728 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:19:17.720503 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:19:17.721352 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:19:17.722151 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:19:17.722939 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:19:17.724203 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:19:17.724988 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:19:17.725769 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:19:17.726615 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:19:17.727413 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:19:17.728202 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:19:17.728985 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:19:17.729806 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:19:17.731085 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:19:17.731990 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:19:17.732979 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:19:17.733842 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:19:17.734610 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:19:17.735382 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:19:17.736197 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:19:17.737078 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:19:18.049396 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 08:19:18.050000 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 08:19:18.070919 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 08:19:18.093314 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 08:19:18.112683 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 08:19:18.113288 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 08:19:18.135062 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 08:19:18.159549 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 08:19:18.183453 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 08:19:18.203664 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:19:18.204267 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 08:19:18.225241 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:19:18.246867 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 08:19:18.269656 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:19:18.296323 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:19:18.297195 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 08:19:18.323422 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:19:18.347227 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 08:19:18.373757 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:19:18.398050 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:19:18.398762 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 08:19:18.425107 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:19:18.455654 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 08:19:18.481403 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:19:18.503356 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:19:18.504024 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 08:19:18.529612 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:19:18.553494 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 08:19:18.579342 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:19:18.600660 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:19:18.601261 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 08:19:18.623409 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:19:18.646242 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:19:18.673077 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:19:18.696084 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:19:18.696643 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 08:19:18.719162 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:19:18.742578 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:19:18.773385 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:19:18.799217 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:19:18.799847 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 08:19:18.834745 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:19:18.862044 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:19:18.890658 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:19:18.915628 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:19:18.916257 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 08:19:18.943155 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:19:18.969163 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:19:18.994361 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:19:19.018156 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:19:19.018785 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 08:19:19.042138 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:19:19.066161 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:19:19.092207 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:19:19.116487 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:19:19.117150 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 08:19:19.140789 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:19:19.165077 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 08:19:19.190912 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:19:19.212510 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:19:19.213078 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 08:19:19.240307 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:19:19.269138 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:19:19.296531 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:19:19.324606 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:19:19.325397 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 08:19:19.355399 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:19:19.384176 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:19:19.416295 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:19:19.442591 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:19:19.443258 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 08:19:19.474832 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:19:19.504056 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:19:19.531241 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:19:19.555162 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:19:19.555789 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 08:19:19.584076 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:19:19.613586 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:19:19.642354 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:19:19.668612 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 08:19:22.217913 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 08:19:22.218189 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 08:19:22.499866 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 08:19:22.661920 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 08:19:22.705575 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T08:19:22Z
I1011 08:19:22.722443 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T08:19:22Z
INFO:tensorflow:Graph was finalized.
I1011 08:19:23.642470 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 08:19:23.643223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:19:23.643753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 08:19:23.643821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:19:23.643892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 08:19:23.643920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 08:19:23.643939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 08:19:23.643961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 08:19:23.643983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 08:19:23.644007: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:19:23.644100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:19:23.644585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:19:23.645018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 08:19:23.645075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 08:19:23.645090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 08:19:23.645099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 08:19:23.645224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:19:23.645691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:19:23.646132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-12816
I1011 08:19:23.647370 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-12816
INFO:tensorflow:Running local_init_op.
I1011 08:19:24.824156 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 08:19:24.897278 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 08:22:20.202175 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 08:25:08.143278 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 08:28:01.417264 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 08:30:52.458493 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 08:33:40.479766 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 08:36:26.562887 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 08:39:16.110187 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 08:42:05.722829 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 08:44:55.591471 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 08:47:46.750988 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 08:47:52.414621 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1773.05760s
I1011 08:48:55.780241 140235064469376 evaluation.py:273] Inference Time : 1773.05760s
INFO:tensorflow:Finished evaluation at 2020-10-11-08:48:55
I1011 08:48:55.780501 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-08:48:55
INFO:tensorflow:Saving dict for global step 12816: AP = 0.40800673, AP50 = 0.51314473, AP75 = 0.46637782, APl = 0.48573318, APm = 0.54097134, APs = 0.1714312, ARl = 0.84008807, ARm = 0.6619758, ARmax1 = 0.508404, ARmax10 = 0.7054832, ARmax100 = 0.74317694, ARs = 0.3012335, box_loss = 0.0018747519, cls_loss = 0.22084403, global_step = 12816, loss = 0.4113551
I1011 08:48:55.780681 140235064469376 estimator.py:2063] Saving dict for global step 12816: AP = 0.40800673, AP50 = 0.51314473, AP75 = 0.46637782, APl = 0.48573318, APm = 0.54097134, APs = 0.1714312, ARl = 0.84008807, ARm = 0.6619758, ARmax1 = 0.508404, ARmax10 = 0.7054832, ARmax100 = 0.74317694, ARs = 0.3012335, box_loss = 0.0018747519, cls_loss = 0.22084403, global_step = 12816, loss = 0.4113551
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12816: efficientdet-d0-finetune/model.ckpt-12816
I1011 08:48:56.808227 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 12816: efficientdet-d0-finetune/model.ckpt-12816
I1011 08:48:56.815694 140235064469376 utils.py:444] mv efficientdet-d0-finetune/archive to efficientdet-d0-finetune/backup
INFO:tensorflow:efficientdet-d0-finetune/archive/model.ckpt-12816 is not in all_model_checkpoint_paths. Manually adding it.
I1011 08:48:56.853196 140235064469376 checkpoint_management.py:102] efficientdet-d0-finetune/archive/model.ckpt-12816 is not in all_model_checkpoint_paths. Manually adding it.
I1011 08:48:56.853786 140235064469376 utils.py:464] Copying checkpoint efficientdet-d0-finetune/model.ckpt-12816 to efficientdet-d0-finetune/archive

   =====> Starting training, epoch: 18.

   =====> Starting evaluation, epoch: 18.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=4.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=48.71s).
Accumulating evaluation results...
DONE (t=8.88s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 08:48:57.042380 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 08:48:57.059759: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 08:48:57.094050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:48:57.094626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 08:48:57.094678: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:48:57.098353: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 08:48:57.101316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 08:48:57.101980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 08:48:57.104299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 08:48:57.105700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 08:48:57.110547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:48:57.110695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:48:57.111327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:48:57.111968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 08:48:57.380057 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 08:48:57.779471 140235064469376 estimator.py:1162] Calling model_fn.
I1011 08:48:57.779875 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 08:48:57.786421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 08:48:57.787130 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 08:48:57.796732 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 08:48:58.033989 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:48:58.034934 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:48:58.035730 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:48:58.036504 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:48:58.037262 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:48:58.038019 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:48:58.038781 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:48:58.039597 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:48:58.040859 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:48:58.041935 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:48:58.043143 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:48:58.044412 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:48:58.045743 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:48:58.047052 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:48:58.048207 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:48:58.049323 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:48:58.050670 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:48:58.051494 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:48:58.052362 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:48:58.053386 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:48:58.054256 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:48:58.055087 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:48:58.055881 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:48:58.056676 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:48:58.148400 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 08:48:58.149065 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 08:48:58.177300 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 08:48:58.199656 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 08:48:58.225706 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 08:48:58.226282 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 08:48:58.253235 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 08:48:58.281924 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 08:48:58.433057 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 08:48:58.461311 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:48:58.461942 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 08:48:58.488956 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:48:58.517324 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 08:48:58.540421 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:48:58.568589 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:48:58.569268 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 08:48:58.597344 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:48:58.625298 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 08:48:58.653498 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:48:58.682654 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:48:58.683274 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 08:48:58.710516 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:48:58.739492 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 08:48:58.763031 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:48:58.791362 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:48:58.792347 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 08:48:58.822932 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:48:58.851294 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 08:48:58.874339 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:48:58.900230 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:48:58.900806 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 08:48:58.927889 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:48:58.960372 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:48:58.987356 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:48:59.018308 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:48:59.019006 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 08:48:59.052835 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:48:59.083641 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:48:59.108382 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:48:59.136162 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:48:59.136857 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 08:48:59.164823 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:48:59.192755 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:48:59.215704 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:48:59.242532 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:48:59.243158 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 08:48:59.273697 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:48:59.302462 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:48:59.326253 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:48:59.354264 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:48:59.354851 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 08:48:59.382125 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:48:59.410800 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:48:59.436354 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:48:59.466176 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:48:59.466853 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 08:48:59.493858 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:48:59.522936 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 08:48:59.546884 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:48:59.581545 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:48:59.582178 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 08:48:59.614140 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:48:59.647850 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:48:59.672893 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:48:59.699587 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:48:59.700247 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 08:48:59.731330 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:48:59.763859 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:48:59.787821 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:48:59.819619 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:48:59.820204 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 08:48:59.865016 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:48:59.900516 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:48:59.924570 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:48:59.952420 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:48:59.953229 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 08:48:59.985305 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:49:00.019640 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:49:00.044248 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:49:00.078331 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 08:49:02.990466 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 08:49:02.990836 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 08:49:03.240610 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 08:49:03.242270 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 08:49:03.243730 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 08:49:03.245085 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 08:49:03.246464 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 08:49:03.248045 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 08:49:03.250699 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 08:49:03.252249 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 08:49:11.058188 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 08:49:13.070541 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 08:49:13.070746 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 08:49:13.076588 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 08:49:13.076735 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 08:49:13.076829 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 08:49:13.076925 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 08:49:13.077004 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 08:49:13.083661 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 08:49:13.083863 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 08:49:14.618199 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 08:49:14.619321 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 08:49:18.815468 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 08:49:18.822231: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 08:49:18.822451: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 08:49:18.822479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 08:49:18.923103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:49:18.923775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 08:49:18.923807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 08:49:18.924032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:49:18.924563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 08:49:18.924628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:49:18.924686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 08:49:18.924735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 08:49:18.924766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 08:49:18.924792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 08:49:18.924819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 08:49:18.924844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:49:18.924957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:49:18.925535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:49:18.926062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 08:49:18.926163: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:49:19.506640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 08:49:19.506701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 08:49:19.506725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 08:49:19.506956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:49:19.507611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:49:19.508172: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 08:49:19.508240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-12816
I1011 08:49:19.510346 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-12816
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 08:49:21.250501 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 08:49:22.152235 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 08:49:22.317995 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12816...
I1011 08:49:33.116973 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12816...
INFO:tensorflow:Saving checkpoints for 12816 into efficientdet-d0-finetune/model.ckpt.
I1011 08:49:33.130226 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12816 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12816...
I1011 08:49:35.734391 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12816...
2020-10-11 08:49:45.576516: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:49:47.536462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.579662, step = 12816
I1011 08:49:48.521919 140235064469376 basic_session_run_hooks.py:262] loss = 0.579662, step = 12816
INFO:tensorflow:box_loss = 0.0032551705, cls_loss = 0.32012987, det_loss = 0.4828884, step = 12816
I1011 08:49:48.522430 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0032551705, cls_loss = 0.32012987, det_loss = 0.4828884, step = 12816
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12908 vs previous value: 12908. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 08:50:24.684337 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12908 vs previous value: 12908. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12916...
I1011 08:50:35.814319 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 12916...
INFO:tensorflow:Saving checkpoints for 12916 into efficientdet-d0-finetune/model.ckpt.
I1011 08:50:35.814638 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 12916 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 08:50:35.879599 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12916...
I1011 08:50:37.639804 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 12916...
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12915 vs previous value: 12915. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 08:50:37.640258 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12915 vs previous value: 12915. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:global_step/sec: 1.71564
I1011 08:50:46.808180 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 1.71564
INFO:tensorflow:loss = 0.53429747, step = 12916 (58.287 sec)
I1011 08:50:46.808549 140235064469376 basic_session_run_hooks.py:260] loss = 0.53429747, step = 12916 (58.287 sec)
INFO:tensorflow:box_loss = 0.0027871996, cls_loss = 0.29816437, det_loss = 0.43752432, step = 12916 (58.286 sec)
I1011 08:50:46.808757 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0027871996, cls_loss = 0.29816437, det_loss = 0.43752432, step = 12916 (58.286 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13016...
I1011 08:51:16.371575 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13016...
INFO:tensorflow:Saving checkpoints for 13016 into efficientdet-d0-finetune/model.ckpt.
I1011 08:51:16.371931 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13016 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13016...
I1011 08:51:18.191223 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13016...
INFO:tensorflow:global_step/sec: 3.14945
I1011 08:51:18.559785 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.14945
INFO:tensorflow:loss = 0.4284508, step = 13016 (31.752 sec)
I1011 08:51:18.560120 140235064469376 basic_session_run_hooks.py:260] loss = 0.4284508, step = 13016 (31.752 sec)
INFO:tensorflow:box_loss = 0.0019071487, cls_loss = 0.2363205, det_loss = 0.33167794, step = 13016 (31.752 sec)
I1011 08:51:18.560314 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0019071487, cls_loss = 0.2363205, det_loss = 0.33167794, step = 13016 (31.752 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13116...
I1011 08:51:48.456899 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13116...
INFO:tensorflow:Saving checkpoints for 13116 into efficientdet-d0-finetune/model.ckpt.
I1011 08:51:48.457148 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13116 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13116...
I1011 08:51:50.243969 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13116...
INFO:tensorflow:global_step/sec: 3.12167
I1011 08:51:50.593939 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.12167
INFO:tensorflow:loss = 0.63586295, step = 13116 (32.034 sec)
I1011 08:51:50.594485 140235064469376 basic_session_run_hooks.py:260] loss = 0.63586295, step = 13116 (32.034 sec)
INFO:tensorflow:box_loss = 0.003501346, cls_loss = 0.36402297, det_loss = 0.5390903, step = 13116 (32.034 sec)
I1011 08:51:50.594679 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.003501346, cls_loss = 0.36402297, det_loss = 0.5390903, step = 13116 (32.034 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13216...
I1011 08:52:20.002768 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13216...
INFO:tensorflow:Saving checkpoints for 13216 into efficientdet-d0-finetune/model.ckpt.
I1011 08:52:20.003022 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13216 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13216...
I1011 08:52:21.785378 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13216...
INFO:tensorflow:global_step/sec: 3.17245
I1011 08:52:22.115322 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17245
INFO:tensorflow:loss = 0.63033766, step = 13216 (31.521 sec)
I1011 08:52:22.115647 140235064469376 basic_session_run_hooks.py:260] loss = 0.63033766, step = 13216 (31.521 sec)
INFO:tensorflow:box_loss = 0.002517922, cls_loss = 0.40766907, det_loss = 0.53356516, step = 13216 (31.521 sec)
I1011 08:52:22.115855 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.002517922, cls_loss = 0.40766907, det_loss = 0.53356516, step = 13216 (31.521 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13316...
I1011 08:52:51.671325 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13316...
INFO:tensorflow:Saving checkpoints for 13316 into efficientdet-d0-finetune/model.ckpt.
I1011 08:52:51.671605 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13316 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13316...
I1011 08:52:53.449602 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13316...
INFO:tensorflow:global_step/sec: 3.16135
I1011 08:52:53.747416 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16135
INFO:tensorflow:loss = 0.5955481, step = 13316 (31.632 sec)
I1011 08:52:53.747773 140235064469376 basic_session_run_hooks.py:260] loss = 0.5955481, step = 13316 (31.632 sec)
INFO:tensorflow:box_loss = 0.0038233215, cls_loss = 0.30760956, det_loss = 0.49877563, step = 13316 (31.632 sec)
I1011 08:52:53.747967 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0038233215, cls_loss = 0.30760956, det_loss = 0.49877563, step = 13316 (31.632 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13416...
I1011 08:53:23.506303 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13416...
INFO:tensorflow:Saving checkpoints for 13416 into efficientdet-d0-finetune/model.ckpt.
I1011 08:53:23.506656 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13416 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13416...
I1011 08:53:25.270947 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13416...
INFO:tensorflow:global_step/sec: 3.13959
I1011 08:53:25.598706 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.13959
INFO:tensorflow:loss = 0.65544486, step = 13416 (31.851 sec)
I1011 08:53:25.599040 140235064469376 basic_session_run_hooks.py:260] loss = 0.65544486, step = 13416 (31.851 sec)
INFO:tensorflow:box_loss = 0.0038444991, cls_loss = 0.36644745, det_loss = 0.5586724, step = 13416 (31.851 sec)
I1011 08:53:25.599247 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0038444991, cls_loss = 0.36644745, det_loss = 0.5586724, step = 13416 (31.851 sec)
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13511 vs previous value: 13511. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1011 08:53:53.729773 140235064469376 basic_session_run_hooks.py:734] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13511 vs previous value: 13511. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13516...
I1011 08:53:54.948630 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13516...
INFO:tensorflow:Saving checkpoints for 13516 into efficientdet-d0-finetune/model.ckpt.
I1011 08:53:54.948924 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13516 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13516...
I1011 08:53:56.720887 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13516...
INFO:tensorflow:global_step/sec: 3.17971
I1011 08:53:57.048122 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17971
INFO:tensorflow:loss = 0.39957398, step = 13516 (31.449 sec)
I1011 08:53:57.048470 140235064469376 basic_session_run_hooks.py:260] loss = 0.39957398, step = 13516 (31.449 sec)
INFO:tensorflow:box_loss = 0.0017429815, cls_loss = 0.21565247, det_loss = 0.30280155, step = 13516 (31.449 sec)
I1011 08:53:57.048656 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0017429815, cls_loss = 0.21565247, det_loss = 0.30280155, step = 13516 (31.449 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13528...
I1011 08:54:00.336218 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13528...
INFO:tensorflow:Saving checkpoints for 13528 into efficientdet-d0-finetune/model.ckpt.
I1011 08:54:00.336438 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13528 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13528...
I1011 08:54:02.121595 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13528...
INFO:tensorflow:Loss for final step: 0.5599409.
I1011 08:54:02.653499 140235064469376 estimator.py:350] Loss for final step: 0.5599409.
INFO:tensorflow:Calling model_fn.
I1011 08:54:03.154303 140235064469376 estimator.py:1162] Calling model_fn.
I1011 08:54:03.154644 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 08:54:03.158340 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 08:54:03.396277 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:54:03.397110 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:54:03.397931 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:54:03.398692 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:54:03.399468 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:54:03.400291 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:54:03.401056 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:54:03.401813 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:54:03.402942 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:54:03.403676 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:54:03.404444 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:54:03.405263 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:54:03.406023 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:54:03.406771 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:54:03.407490 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:54:03.408239 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:54:03.409428 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 08:54:03.410177 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 08:54:03.410939 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 08:54:03.411680 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 08:54:03.412418 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 08:54:03.413163 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 08:54:03.413930 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 08:54:03.414772 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 08:54:03.749005 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 08:54:03.749684 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 08:54:03.776215 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 08:54:03.804326 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 08:54:03.828841 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 08:54:03.829881 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 08:54:03.857095 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 08:54:03.878743 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 08:54:03.901675 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 08:54:03.921983 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:54:03.922527 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 08:54:03.943758 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:54:03.966393 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 08:54:03.990044 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:54:04.010166 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 08:54:04.010795 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 08:54:04.035794 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 08:54:04.057341 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 08:54:04.080119 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 08:54:04.101373 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:54:04.102024 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 08:54:04.124762 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:54:04.145992 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 08:54:04.173680 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:54:04.198305 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 08:54:04.198932 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 08:54:04.221500 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 08:54:04.245174 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 08:54:04.270029 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 08:54:04.292220 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:54:04.292840 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 08:54:04.315854 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:54:04.344904 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:54:04.374425 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:54:04.399375 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:54:04.400012 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 08:54:04.425805 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:54:04.454113 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:54:04.479089 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:54:04.501327 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 08:54:04.501924 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 08:54:04.525207 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 08:54:04.549233 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 08:54:04.575034 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 08:54:04.596447 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:54:04.597029 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 08:54:04.620821 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:54:04.647624 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:54:04.679772 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:54:04.704487 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:54:04.705090 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 08:54:04.728421 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:54:04.752618 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 08:54:04.778841 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:54:04.800536 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 08:54:04.801184 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 08:54:04.824639 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 08:54:04.860360 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 08:54:04.886606 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 08:54:04.909340 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:54:04.909989 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 08:54:04.938403 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:54:04.966749 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:54:04.991426 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:54:05.013947 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:54:05.014650 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 08:54:05.039688 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:54:05.064943 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:54:05.092322 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:54:05.112773 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:54:05.113376 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 08:54:05.140263 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:54:05.167775 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:54:05.191969 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:54:05.212342 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 08:54:05.212918 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 08:54:05.238016 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 08:54:05.264398 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 08:54:05.288292 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 08:54:05.308345 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 08:54:07.748485 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 08:54:07.748795 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 08:54:08.052022 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 08:54:08.216669 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 08:54:08.257539 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T08:54:08Z
I1011 08:54:08.272778 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T08:54:08Z
INFO:tensorflow:Graph was finalized.
I1011 08:54:09.236210 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 08:54:09.236992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:54:09.237527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 08:54:09.237603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 08:54:09.237664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 08:54:09.237694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 08:54:09.237744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 08:54:09.237771: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 08:54:09.237796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 08:54:09.237821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 08:54:09.237918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:54:09.238450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:54:09.238940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 08:54:09.238998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 08:54:09.239017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 08:54:09.239029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 08:54:09.239143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:54:09.239671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 08:54:09.240164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-13528
I1011 08:54:09.241445 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-13528
INFO:tensorflow:Running local_init_op.
I1011 08:54:10.581948 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 08:54:10.652549 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 08:57:08.252249 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 08:59:58.144883 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 09:02:53.554125 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 09:05:46.310580 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 09:08:36.235506 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 09:11:23.524700 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 09:14:14.637686 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 09:17:04.280947 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 09:19:55.495271 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 09:22:46.519802 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 09:22:52.176944 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1787.10190s
I1011 09:23:55.374857 140235064469376 evaluation.py:273] Inference Time : 1787.10190s
INFO:tensorflow:Finished evaluation at 2020-10-11-09:23:55
I1011 09:23:55.375123 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-09:23:55
INFO:tensorflow:Saving dict for global step 13528: AP = 0.40287942, AP50 = 0.5066057, AP75 = 0.46063954, APl = 0.48077127, APm = 0.54054296, APs = 0.17170751, ARl = 0.8394979, ARm = 0.6603704, ARmax1 = 0.5083029, ARmax10 = 0.7047839, ARmax100 = 0.74263275, ARs = 0.30006468, box_loss = 0.001873366, cls_loss = 0.22079708, global_step = 13528, loss = 0.41123784
I1011 09:23:55.375349 140235064469376 estimator.py:2063] Saving dict for global step 13528: AP = 0.40287942, AP50 = 0.5066057, AP75 = 0.46063954, APl = 0.48077127, APm = 0.54054296, APs = 0.17170751, ARl = 0.8394979, ARm = 0.6603704, ARmax1 = 0.5083029, ARmax10 = 0.7047839, ARmax100 = 0.74263275, ARs = 0.30006468, box_loss = 0.001873366, cls_loss = 0.22079708, global_step = 13528, loss = 0.41123784
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13528: efficientdet-d0-finetune/model.ckpt-13528
I1011 09:23:56.448704 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 13528: efficientdet-d0-finetune/model.ckpt-13528
I1011 09:23:56.451333 140235064469376 utils.py:428] Ckpt 0.40287941694259644 is worse than 0.408007

   =====> Starting training, epoch: 19.

   =====> Starting evaluation, epoch: 19.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.98s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=48.67s).
Accumulating evaluation results...
DONE (t=8.74s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.839
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W1011 09:23:56.639162 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2020-10-11 09:23:56.651442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-11 09:23:56.695491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:23:56.696587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 09:23:56.696696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 09:23:56.703059: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 09:23:56.705798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 09:23:56.706157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 09:23:56.707998: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 09:23:56.709138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 09:23:56.713396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 09:23:56.713528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:23:56.714114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:23:56.714628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
I1011 09:23:56.983132 140235064469376 dataloader.py:83] target_size = (512, 512), output_size = (512, 512)
INFO:tensorflow:Calling model_fn.
I1011 09:23:57.391194 140235064469376 estimator.py:1162] Calling model_fn.
I1011 09:23:57.391532 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
2020-10-11 09:23:57.396782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 09:23:57.397436 140235064469376 device_compatibility_check.py:124] Mixed precision compatibility check (mixed_float16): OK
Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5
I1011 09:23:57.406654 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 09:23:57.643561 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 09:23:57.644466 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 09:23:57.645264 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 09:23:57.646060 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 09:23:57.646854 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 09:23:57.647748 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 09:23:57.648551 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 09:23:57.649357 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 09:23:57.650660 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 09:23:57.651428 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 09:23:57.652223 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 09:23:57.653066 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 09:23:57.653872 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 09:23:57.654707 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 09:23:57.655490 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 09:23:57.656270 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 09:23:57.657573 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 09:23:57.658418 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 09:23:57.659204 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 09:23:57.660085 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 09:23:57.660913 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 09:23:57.661726 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 09:23:57.662489 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 09:23:57.663268 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 09:23:57.772104 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 09:23:57.772667 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 09:23:57.803912 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 09:23:57.828116 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 09:23:57.857116 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 09:23:57.857697 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 09:23:57.887135 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 09:23:57.921662 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 09:23:58.064061 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 09:23:58.091320 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 09:23:58.091898 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 09:23:58.119554 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 09:23:58.148344 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 09:23:58.170815 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 09:23:58.201794 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 09:23:58.202463 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 09:23:58.232483 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 09:23:58.262433 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 09:23:58.284915 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 09:23:58.310809 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 09:23:58.311363 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 09:23:58.337883 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 09:23:58.370031 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 09:23:58.392414 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 09:23:58.417747 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 09:23:58.418325 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 09:23:58.444873 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 09:23:58.472219 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 09:23:58.498356 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 09:23:58.524015 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 09:23:58.524543 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 09:23:58.551203 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 09:23:58.579395 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 09:23:58.602568 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 09:23:58.627923 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 09:23:58.628454 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 09:23:58.655130 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 09:23:58.682309 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 09:23:58.705049 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 09:23:58.735159 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 09:23:58.735811 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 09:23:58.766555 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 09:23:58.796562 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 09:23:58.823275 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 09:23:58.852937 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 09:23:58.853542 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 09:23:58.883506 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 09:23:58.911960 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 09:23:58.934836 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 09:23:58.962275 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 09:23:58.962921 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 09:23:58.992394 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 09:23:59.024490 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 09:23:59.047476 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 09:23:59.074086 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 09:23:59.074728 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 09:23:59.102808 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 09:23:59.132441 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 09:23:59.157860 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 09:23:59.184531 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:23:59.185091 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 09:23:59.216176 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:23:59.248794 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:23:59.272454 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:23:59.300798 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:23:59.301473 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 09:23:59.336790 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:23:59.374285 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:23:59.400827 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:23:59.428998 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:23:59.429577 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 09:23:59.464074 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:23:59.496079 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:23:59.520548 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:23:59.546925 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:23:59.547494 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 09:23:59.577902 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:23:59.612210 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:23:59.635763 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:23:59.661675 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 09:24:02.500990 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 09:24:02.501329 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 09:24:02.747063 140235064469376 utils.py:361] Adding scale summary ('lrn_rate', <tf.Tensor 'Select:0' shape=() dtype=float32>)
I1011 09:24:02.749081 140235064469376 utils.py:361] Adding scale summary ('trainloss/cls_loss', <tf.Tensor 'AddN:0' shape=() dtype=float32>)
I1011 09:24:02.750861 140235064469376 utils.py:361] Adding scale summary ('trainloss/box_loss', <tf.Tensor 'AddN_1:0' shape=() dtype=float32>)
I1011 09:24:02.752542 140235064469376 utils.py:361] Adding scale summary ('trainloss/det_loss', <tf.Tensor 'add_4:0' shape=() dtype=float32>)
I1011 09:24:02.754214 140235064469376 utils.py:361] Adding scale summary ('trainloss/reg_l2_loss', <tf.Tensor 'mul_14:0' shape=() dtype=float32>)
I1011 09:24:02.755896 140235064469376 utils.py:361] Adding scale summary ('trainloss/loss', <tf.Tensor 'add_5:0' shape=() dtype=float32>)
I1011 09:24:02.759276 140235064469376 utils.py:361] Adding scale summary ('train_epochs', <tf.Tensor 'truediv_7:0' shape=() dtype=float32>)
I1011 09:24:02.761178 140235064469376 det_model_fn.py:436] clip gradients norm by 10.000000
I1011 09:24:10.557258 140235064469376 utils.py:361] Adding scale summary ('gradient_norm', <tf.Tensor 'clip/global_norm_1/global_norm:0' shape=() dtype=float32>)
I1011 09:24:12.484565 140235064469376 det_model_fn.py:578] restore variables from efficientdet-d0
I1011 09:24:12.484769 140235064469376 utils.py:99] Init model from checkpoint efficientdet-d0
I1011 09:24:12.490988 140235064469376 utils.py:142] Init global_step from ckpt var global_step
I1011 09:24:12.491133 140235064469376 utils.py:128] skip current_loss_scale (current_loss_scale) -- not in ckpt
I1011 09:24:12.491249 140235064469376 utils.py:128] skip good_steps (good_steps) -- not in ckpt
I1011 09:24:12.491354 140235064469376 utils.py:142] Init efficientnet-b0/stem/conv2d/kernel from ckpt var efficientnet-b0/stem/conv2d/kernel
I1011 09:24:12.491441 140235064469376 utils.py:142] Init efficientnet-b0/stem/tpu_batch_normalization/gamma from ckpt var efficientnet-b0/stem/tpu_batch_normalization/gamma
I1011 09:24:12.496505 140235064469376 utils.py:135] skip class_net/class-predict/pointwise_kernel ((1, 1, 64, 180) vs [1, 1, 64, 810]) -- shape mismatch
I1011 09:24:12.496638 140235064469376 utils.py:135] skip class_net/class-predict/bias ((180,) vs [810]) -- shape mismatch
INFO:tensorflow:Done calling model_fn.
I1011 09:24:14.089843 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1011 09:24:14.090921 140235064469376 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1011 09:24:18.197767 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 09:24:18.204503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-11 09:24:18.204754: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-11 09:24:18.204784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-11 09:24:18.302639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:24:18.303335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d99640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-11 09:24:18.303366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-10-11 09:24:18.303568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:24:18.304160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 09:24:18.304230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 09:24:18.304288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 09:24:18.304314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 09:24:18.304348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 09:24:18.304378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 09:24:18.304403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 09:24:18.304429: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 09:24:18.304517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:24:18.305164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:24:18.305686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 09:24:18.305802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 09:24:18.877273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 09:24:18.877341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 09:24:18.877352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 09:24:18.877542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:24:18.878214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:24:18.878729: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-10-11 09:24:18.878771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-13528
I1011 09:24:18.880960 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-13528
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W1011 09:24:20.575724 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I1011 09:24:21.414841 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 09:24:21.568207 140235064469376 session_manager.py:508] Done running local_init_op.
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13528...
I1011 09:24:32.557185 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13528...
INFO:tensorflow:Saving checkpoints for 13528 into efficientdet-d0-finetune/model.ckpt.
I1011 09:24:32.571058 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13528 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13528...
I1011 09:24:35.150671 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13528...
2020-10-11 09:24:44.568275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 09:24:46.593825: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:loss = 0.31703418, step = 13528
I1011 09:24:47.568600 140235064469376 basic_session_run_hooks.py:262] loss = 0.31703418, step = 13528
INFO:tensorflow:box_loss = 0.0010896528, cls_loss = 0.16577911, det_loss = 0.22026175, step = 13528
I1011 09:24:47.569377 140235064469376 basic_session_run_hooks.py:262] box_loss = 0.0010896528, cls_loss = 0.16577911, det_loss = 0.22026175, step = 13528
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13628...
I1011 09:25:25.134550 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13628...
INFO:tensorflow:Saving checkpoints for 13628 into efficientdet-d0-finetune/model.ckpt.
I1011 09:25:25.134916 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13628 into efficientdet-d0-finetune/model.ckpt.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W1011 09:25:25.199022 140235064469376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13628...
I1011 09:25:26.882367 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13628...
INFO:tensorflow:global_step/sec: 2.52318
I1011 09:25:27.200344 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 2.52318
INFO:tensorflow:loss = 0.37291598, step = 13628 (39.633 sec)
I1011 09:25:27.201390 140235064469376 basic_session_run_hooks.py:260] loss = 0.37291598, step = 13628 (39.633 sec)
INFO:tensorflow:box_loss = 0.0013045026, cls_loss = 0.21091843, det_loss = 0.27614355, step = 13628 (39.632 sec)
I1011 09:25:27.201589 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0013045026, cls_loss = 0.21091843, det_loss = 0.27614355, step = 13628 (39.632 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13728...
I1011 09:25:56.451153 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13728...
INFO:tensorflow:Saving checkpoints for 13728 into efficientdet-d0-finetune/model.ckpt.
I1011 09:25:56.451416 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13728 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13728...
I1011 09:25:58.181154 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13728...
INFO:tensorflow:global_step/sec: 3.19179
I1011 09:25:58.530779 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19179
INFO:tensorflow:loss = 0.4895889, step = 13728 (31.330 sec)
I1011 09:25:58.531763 140235064469376 basic_session_run_hooks.py:260] loss = 0.4895889, step = 13728 (31.330 sec)
INFO:tensorflow:box_loss = 0.0026082976, cls_loss = 0.26240158, det_loss = 0.39281648, step = 13728 (31.330 sec)
I1011 09:25:58.532010 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0026082976, cls_loss = 0.26240158, det_loss = 0.39281648, step = 13728 (31.330 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13828...
I1011 09:26:27.768401 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13828...
INFO:tensorflow:Saving checkpoints for 13828 into efficientdet-d0-finetune/model.ckpt.
I1011 09:26:27.768638 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13828 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13828...
I1011 09:26:29.469766 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13828...
INFO:tensorflow:global_step/sec: 3.19814
I1011 09:26:29.798902 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.19814
INFO:tensorflow:loss = 0.40125293, step = 13828 (31.268 sec)
I1011 09:26:29.799951 140235064469376 basic_session_run_hooks.py:260] loss = 0.40125293, step = 13828 (31.268 sec)
INFO:tensorflow:box_loss = 0.001257687, cls_loss = 0.24159622, det_loss = 0.30448058, step = 13828 (31.268 sec)
I1011 09:26:29.800158 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.001257687, cls_loss = 0.24159622, det_loss = 0.30448058, step = 13828 (31.268 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13928...
I1011 09:26:58.928754 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 13928...
INFO:tensorflow:Saving checkpoints for 13928 into efficientdet-d0-finetune/model.ckpt.
I1011 09:26:58.929055 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 13928 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13928...
I1011 09:27:00.644975 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 13928...
INFO:tensorflow:global_step/sec: 3.21313
I1011 09:27:00.921150 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.21313
INFO:tensorflow:loss = 0.53152007, step = 13928 (31.122 sec)
I1011 09:27:00.922085 140235064469376 basic_session_run_hooks.py:260] loss = 0.53152007, step = 13928 (31.122 sec)
INFO:tensorflow:box_loss = 0.0031568867, cls_loss = 0.2769035, det_loss = 0.43474784, step = 13928 (31.122 sec)
I1011 09:27:00.922279 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0031568867, cls_loss = 0.2769035, det_loss = 0.43474784, step = 13928 (31.122 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 14028...
I1011 09:27:30.370571 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 14028...
INFO:tensorflow:Saving checkpoints for 14028 into efficientdet-d0-finetune/model.ckpt.
I1011 09:27:30.370896 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 14028 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 14028...
I1011 09:27:32.122602 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 14028...
INFO:tensorflow:global_step/sec: 3.16549
I1011 09:27:32.511867 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.16549
INFO:tensorflow:loss = 0.5235037, step = 14028 (31.591 sec)
I1011 09:27:32.512997 140235064469376 basic_session_run_hooks.py:260] loss = 0.5235037, step = 14028 (31.591 sec)
INFO:tensorflow:box_loss = 0.0023203392, cls_loss = 0.31071472, det_loss = 0.42673168, step = 14028 (31.591 sec)
I1011 09:27:32.513207 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0023203392, cls_loss = 0.31071472, det_loss = 0.42673168, step = 14028 (31.591 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 14128...
I1011 09:28:01.997521 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 14128...
INFO:tensorflow:Saving checkpoints for 14128 into efficientdet-d0-finetune/model.ckpt.
I1011 09:28:01.997777 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 14128 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 14128...
I1011 09:28:03.678397 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 14128...
INFO:tensorflow:global_step/sec: 3.17972
I1011 09:28:03.961202 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.17972
INFO:tensorflow:loss = 0.47204214, step = 14128 (31.449 sec)
I1011 09:28:03.962306 140235064469376 basic_session_run_hooks.py:260] loss = 0.47204214, step = 14128 (31.449 sec)
INFO:tensorflow:box_loss = 0.0029282281, cls_loss = 0.22885895, det_loss = 0.37527037, step = 14128 (31.449 sec)
I1011 09:28:03.962642 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0029282281, cls_loss = 0.22885895, det_loss = 0.37527037, step = 14128 (31.449 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 14228...
I1011 09:28:33.825438 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 14228...
INFO:tensorflow:Saving checkpoints for 14228 into efficientdet-d0-finetune/model.ckpt.
I1011 09:28:33.825670 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 14228 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 14228...
I1011 09:28:35.543764 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 14228...
INFO:tensorflow:global_step/sec: 3.13181
I1011 09:28:35.891607 140235064469376 basic_session_run_hooks.py:702] global_step/sec: 3.13181
INFO:tensorflow:loss = 0.4467933, step = 14228 (31.930 sec)
I1011 09:28:35.892646 140235064469376 basic_session_run_hooks.py:260] loss = 0.4467933, step = 14228 (31.930 sec)
INFO:tensorflow:box_loss = 0.0019040011, cls_loss = 0.25482178, det_loss = 0.35002184, step = 14228 (31.930 sec)
I1011 09:28:35.892862 140235064469376 basic_session_run_hooks.py:260] box_loss = 0.0019040011, cls_loss = 0.25482178, det_loss = 0.35002184, step = 14228 (31.930 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 14240...
I1011 09:28:39.156661 140235064469376 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 14240...
INFO:tensorflow:Saving checkpoints for 14240 into efficientdet-d0-finetune/model.ckpt.
I1011 09:28:39.156896 140235064469376 basic_session_run_hooks.py:618] Saving checkpoints for 14240 into efficientdet-d0-finetune/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 14240...
I1011 09:28:40.969432 140235064469376 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 14240...
INFO:tensorflow:Loss for final step: 0.28523287.
I1011 09:28:41.334461 140235064469376 estimator.py:350] Loss for final step: 0.28523287.
INFO:tensorflow:Calling model_fn.
I1011 09:28:41.804033 140235064469376 estimator.py:1162] Calling model_fn.
I1011 09:28:41.804352 140235064469376 utils.py:585] use mixed precision policy name mixed_float16
I1011 09:28:41.807920 140235064469376 efficientnet_builder.py:215] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.2, data_format='channels_last', num_classes=1000, width_coefficient=1.0, depth_coefficient=1.0, depth_divisor=8, min_depth=None, survival_prob=0.0, relu_fn=functools.partial(<function activation_fn at 0x7f8abd672488>, act_type='swish'), batch_norm=<class 'utils.BatchNormalization'>, use_se=True, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None)
I1011 09:28:42.041508 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 09:28:42.042346 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 09:28:42.043180 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 09:28:42.043940 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 09:28:42.044672 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 09:28:42.045491 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 09:28:42.046263 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 09:28:42.047013 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 09:28:42.048297 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 09:28:42.049087 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 09:28:42.049838 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 09:28:42.050656 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 09:28:42.051405 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 09:28:42.052147 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 09:28:42.052920 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 09:28:42.053661 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 09:28:42.054929 140235064469376 efficientdet_keras.py:682] fnode 0 : {'feat_level': 6, 'inputs_offsets': [3, 4]}
I1011 09:28:42.055766 140235064469376 efficientdet_keras.py:682] fnode 1 : {'feat_level': 5, 'inputs_offsets': [2, 5]}
I1011 09:28:42.056565 140235064469376 efficientdet_keras.py:682] fnode 2 : {'feat_level': 4, 'inputs_offsets': [1, 6]}
I1011 09:28:42.057317 140235064469376 efficientdet_keras.py:682] fnode 3 : {'feat_level': 3, 'inputs_offsets': [0, 7]}
I1011 09:28:42.058074 140235064469376 efficientdet_keras.py:682] fnode 4 : {'feat_level': 4, 'inputs_offsets': [1, 7, 8]}
I1011 09:28:42.058892 140235064469376 efficientdet_keras.py:682] fnode 5 : {'feat_level': 5, 'inputs_offsets': [2, 6, 9]}
I1011 09:28:42.059662 140235064469376 efficientdet_keras.py:682] fnode 6 : {'feat_level': 6, 'inputs_offsets': [3, 5, 10]}
I1011 09:28:42.060471 140235064469376 efficientdet_keras.py:682] fnode 7 : {'feat_level': 7, 'inputs_offsets': [4, 11]}
I1011 09:28:42.348876 140235064469376 efficientnet_model.py:717] Built stem stem : (8, 256, 256, 32)
I1011 09:28:42.349409 140235064469376 efficientnet_model.py:372] Block blocks_0 input shape: (8, 256, 256, 32)
I1011 09:28:42.370094 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 256, 256, 32)
I1011 09:28:42.391698 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 32)
I1011 09:28:42.411226 140235064469376 efficientnet_model.py:412] Project shape: (8, 256, 256, 16)
I1011 09:28:42.411794 140235064469376 efficientnet_model.py:372] Block blocks_1 input shape: (8, 256, 256, 16)
I1011 09:28:42.431633 140235064469376 efficientnet_model.py:388] Expand shape: (8, 256, 256, 96)
I1011 09:28:42.452846 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 96)
I1011 09:28:42.474535 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 96)
I1011 09:28:42.495313 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 09:28:42.496046 140235064469376 efficientnet_model.py:372] Block blocks_2 input shape: (8, 128, 128, 24)
I1011 09:28:42.520061 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 09:28:42.541730 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 128, 128, 144)
I1011 09:28:42.563640 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 09:28:42.583168 140235064469376 efficientnet_model.py:412] Project shape: (8, 128, 128, 24)
I1011 09:28:42.583760 140235064469376 efficientnet_model.py:372] Block blocks_3 input shape: (8, 128, 128, 24)
I1011 09:28:42.608121 140235064469376 efficientnet_model.py:388] Expand shape: (8, 128, 128, 144)
I1011 09:28:42.630129 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 144)
I1011 09:28:42.651869 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 144)
I1011 09:28:42.671285 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 09:28:42.671826 140235064469376 efficientnet_model.py:372] Block blocks_4 input shape: (8, 64, 64, 40)
I1011 09:28:42.691818 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 09:28:42.712530 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 64, 64, 240)
I1011 09:28:42.734317 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 09:28:42.754160 140235064469376 efficientnet_model.py:412] Project shape: (8, 64, 64, 40)
I1011 09:28:42.754808 140235064469376 efficientnet_model.py:372] Block blocks_5 input shape: (8, 64, 64, 40)
I1011 09:28:42.776584 140235064469376 efficientnet_model.py:388] Expand shape: (8, 64, 64, 240)
I1011 09:28:42.799099 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 240)
I1011 09:28:42.821900 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 240)
I1011 09:28:42.841306 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 09:28:42.841856 140235064469376 efficientnet_model.py:372] Block blocks_6 input shape: (8, 32, 32, 80)
I1011 09:28:42.862375 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 09:28:42.883538 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 09:28:42.910287 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 09:28:42.930438 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 09:28:42.931015 140235064469376 efficientnet_model.py:372] Block blocks_7 input shape: (8, 32, 32, 80)
I1011 09:28:42.952327 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 09:28:42.973457 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 09:28:43.002444 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 09:28:43.023008 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 80)
I1011 09:28:43.023563 140235064469376 efficientnet_model.py:372] Block blocks_8 input shape: (8, 32, 32, 80)
I1011 09:28:43.044349 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 480)
I1011 09:28:43.066512 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 480)
I1011 09:28:43.090594 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 480)
I1011 09:28:43.110881 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 09:28:43.111422 140235064469376 efficientnet_model.py:372] Block blocks_9 input shape: (8, 32, 32, 112)
I1011 09:28:43.131687 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 09:28:43.153178 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 09:28:43.175666 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 09:28:43.196151 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 09:28:43.196694 140235064469376 efficientnet_model.py:372] Block blocks_10 input shape: (8, 32, 32, 112)
I1011 09:28:43.222889 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 09:28:43.246920 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 32, 32, 672)
I1011 09:28:43.273011 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 09:28:43.294775 140235064469376 efficientnet_model.py:412] Project shape: (8, 32, 32, 112)
I1011 09:28:43.295362 140235064469376 efficientnet_model.py:372] Block blocks_11 input shape: (8, 32, 32, 112)
I1011 09:28:43.319335 140235064469376 efficientnet_model.py:388] Expand shape: (8, 32, 32, 672)
I1011 09:28:43.340599 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 672)
I1011 09:28:43.365278 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 672)
I1011 09:28:43.385215 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:28:43.385771 140235064469376 efficientnet_model.py:372] Block blocks_12 input shape: (8, 16, 16, 192)
I1011 09:28:43.409900 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:28:43.434515 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:28:43.457972 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:28:43.478760 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:28:43.479282 140235064469376 efficientnet_model.py:372] Block blocks_13 input shape: (8, 16, 16, 192)
I1011 09:28:43.505389 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:28:43.538005 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:28:43.562362 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:28:43.582178 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:28:43.582741 140235064469376 efficientnet_model.py:372] Block blocks_14 input shape: (8, 16, 16, 192)
I1011 09:28:43.607445 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:28:43.632449 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:28:43.657102 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:28:43.677228 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 192)
I1011 09:28:43.677858 140235064469376 efficientnet_model.py:372] Block blocks_15 input shape: (8, 16, 16, 192)
I1011 09:28:43.703402 140235064469376 efficientnet_model.py:388] Expand shape: (8, 16, 16, 1152)
I1011 09:28:43.730742 140235064469376 efficientnet_model.py:391] DWConv shape: (8, 16, 16, 1152)
I1011 09:28:43.758491 140235064469376 efficientnet_model.py:195] Built SE se : (8, 1, 1, 1152)
I1011 09:28:43.781949 140235064469376 efficientnet_model.py:412] Project shape: (8, 16, 16, 320)
I1011 09:28:46.219594 140235064469376 utils.py:585] use mixed precision policy name float32
I1011 09:28:46.219895 140235064469376 det_model_fn.py:76] LR schedule method: cosine
I1011 09:28:46.508077 140235064469376 postprocess.py:85] use max_nms_inputs for pre-nms topk.
I1011 09:28:46.686145 140235064469376 det_model_fn.py:515] Eval val with groudtruths None.
INFO:tensorflow:Done calling model_fn.
I1011 09:28:46.734643 140235064469376 estimator.py:1164] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-10-11T09:28:46Z
I1011 09:28:46.751524 140235064469376 evaluation.py:255] Starting evaluation at 2020-10-11T09:28:46Z
INFO:tensorflow:Graph was finalized.
I1011 09:28:47.677193 140235064469376 monitored_session.py:246] Graph was finalized.
2020-10-11 09:28:47.677960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:28:47.678492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-10-11 09:28:47.678581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-11 09:28:47.678649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-11 09:28:47.678688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-11 09:28:47.678723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-11 09:28:47.678762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-11 09:28:47.678783: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-11 09:28:47.678804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-11 09:28:47.678896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:28:47.679405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:28:47.679850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-11 09:28:47.679907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-11 09:28:47.679926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-11 09:28:47.679939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-11 09:28:47.680079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:28:47.680605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-11 09:28:47.681101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from efficientdet-d0-finetune/model.ckpt-14240
I1011 09:28:47.682322 140235064469376 saver.py:1293] Restoring parameters from efficientdet-d0-finetune/model.ckpt-14240
INFO:tensorflow:Running local_init_op.
I1011 09:28:49.015081 140235064469376 session_manager.py:505] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1011 09:28:49.076510 140235064469376 session_manager.py:508] Done running local_init_op.
/content/automl/efficientdet/nms_np.py:193: RuntimeWarning: overflow encountered in multiply
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
/content/automl/efficientdet/nms_np.py:211: RuntimeWarning: overflow encountered in multiply
  inter = w * h
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: invalid value encountered in subtract
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
/content/automl/efficientdet/nms_np.py:212: RuntimeWarning: overflow encountered in add
  iou = inter / (dets[0, 5] + dets[1:, 5] - inter)
INFO:tensorflow:Evaluation [71/712]
I1011 09:31:43.261524 140235064469376 evaluation.py:167] Evaluation [71/712]
INFO:tensorflow:Evaluation [142/712]
I1011 09:34:29.734465 140235064469376 evaluation.py:167] Evaluation [142/712]
INFO:tensorflow:Evaluation [213/712]
I1011 09:37:23.269300 140235064469376 evaluation.py:167] Evaluation [213/712]
INFO:tensorflow:Evaluation [284/712]
I1011 09:40:14.428740 140235064469376 evaluation.py:167] Evaluation [284/712]
INFO:tensorflow:Evaluation [355/712]
I1011 09:43:03.288172 140235064469376 evaluation.py:167] Evaluation [355/712]
INFO:tensorflow:Evaluation [426/712]
I1011 09:45:51.540981 140235064469376 evaluation.py:167] Evaluation [426/712]
INFO:tensorflow:Evaluation [497/712]
I1011 09:48:41.112878 140235064469376 evaluation.py:167] Evaluation [497/712]
INFO:tensorflow:Evaluation [568/712]
I1011 09:51:32.462265 140235064469376 evaluation.py:167] Evaluation [568/712]
INFO:tensorflow:Evaluation [639/712]
I1011 09:54:22.614691 140235064469376 evaluation.py:167] Evaluation [639/712]
INFO:tensorflow:Evaluation [710/712]
I1011 09:57:14.658189 140235064469376 evaluation.py:167] Evaluation [710/712]
INFO:tensorflow:Evaluation [712/712]
I1011 09:57:20.217247 140235064469376 evaluation.py:167] Evaluation [712/712]
INFO:tensorflow:Inference Time : 1776.44375s
I1011 09:58:23.195480 140235064469376 evaluation.py:273] Inference Time : 1776.44375s
INFO:tensorflow:Finished evaluation at 2020-10-11-09:58:23
I1011 09:58:23.195754 140235064469376 evaluation.py:276] Finished evaluation at 2020-10-11-09:58:23
INFO:tensorflow:Saving dict for global step 14240: AP = 0.40471852, AP50 = 0.50863713, AP75 = 0.4623136, APl = 0.48311755, APm = 0.54118013, APs = 0.1708646, ARl = 0.8401173, ARm = 0.65961075, ARmax1 = 0.50875694, ARmax10 = 0.7053761, ARmax100 = 0.74297726, ARs = 0.30105802, box_loss = 0.0018693839, cls_loss = 0.22048818, global_step = 14240, loss = 0.41072914
I1011 09:58:23.195941 140235064469376 estimator.py:2063] Saving dict for global step 14240: AP = 0.40471852, AP50 = 0.50863713, AP75 = 0.4623136, APl = 0.48311755, APm = 0.54118013, APs = 0.1708646, ARl = 0.8401173, ARm = 0.65961075, ARmax1 = 0.50875694, ARmax10 = 0.7053761, ARmax100 = 0.74297726, ARs = 0.30105802, box_loss = 0.0018693839, cls_loss = 0.22048818, global_step = 14240, loss = 0.41072914
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14240: efficientdet-d0-finetune/model.ckpt-14240
I1011 09:58:24.245841 140235064469376 estimator.py:2124] Saving 'checkpoint_path' summary for global step 14240: efficientdet-d0-finetune/model.ckpt-14240
I1011 09:58:24.248375 140235064469376 utils.py:428] Ckpt 0.4047185182571411 is worse than 0.408007

   =====> Starting training, epoch: 20.

   =====> Starting evaluation, epoch: 20.
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(569600, 7)
0/569600
DONE (t=3.98s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=48.48s).
Accumulating evaluation results...
DONE (t=8.73s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840
